{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14049e05",
   "metadata": {},
   "source": [
    "# Data Processing and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79097eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d1 = pd.read_csv('weatherinfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07a876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>AvgHumidity</th>\n",
       "      <th>TotalRainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2009</td>\n",
       "      <td>26.5</td>\n",
       "      <td>64</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2010</td>\n",
       "      <td>27.8</td>\n",
       "      <td>69</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2011</td>\n",
       "      <td>26.9</td>\n",
       "      <td>66</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2012</td>\n",
       "      <td>27.5</td>\n",
       "      <td>68</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Year  AvgTemp  AvgHumidity  TotalRainfall\n",
       "0  Andhra Pradesh  2008     27.2           67            950\n",
       "1  Andhra Pradesh  2009     26.5           64            820\n",
       "2  Andhra Pradesh  2010     27.8           69           1080\n",
       "3  Andhra Pradesh  2011     26.9           66            890\n",
       "4  Andhra Pradesh  2012     27.5           68            980"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Source - Gemini \n",
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9e814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv('crop_yield.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba3ebde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Pesticide</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>73814.0</td>\n",
       "      <td>56708</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>7024878.38</td>\n",
       "      <td>22882.34</td>\n",
       "      <td>0.796087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>4685</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>631643.29</td>\n",
       "      <td>2057.47</td>\n",
       "      <td>0.710435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor seed</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>796.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>75755.32</td>\n",
       "      <td>246.76</td>\n",
       "      <td>0.238333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>126905000</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>1870661.52</td>\n",
       "      <td>6093.36</td>\n",
       "      <td>5238.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(lint)</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>794</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>165500.63</td>\n",
       "      <td>539.09</td>\n",
       "      <td>0.420909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  Crop_Year       Season  State     Area  Production  \\\n",
       "0      Arecanut       1997  Whole Year   Assam  73814.0       56708   \n",
       "1     Arhar/Tur       1997  Kharif       Assam   6637.0        4685   \n",
       "2   Castor seed       1997  Kharif       Assam    796.0          22   \n",
       "3      Coconut        1997  Whole Year   Assam  19656.0   126905000   \n",
       "4  Cotton(lint)       1997  Kharif       Assam   1739.0         794   \n",
       "\n",
       "   Annual_Rainfall  Fertilizer  Pesticide        Yield  \n",
       "0           2051.4  7024878.38   22882.34     0.796087  \n",
       "1           2051.4   631643.29    2057.47     0.710435  \n",
       "2           2051.4    75755.32     246.76     0.238333  \n",
       "3           2051.4  1870661.52    6093.36  5238.051739  \n",
       "4           2051.4   165500.63     539.09     0.420909  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Source - Kaggle\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e56ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.rename(columns = {'Crop_Year':'Year'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f21f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = d1.merge(d2, how='left', on=['State', 'Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c972a0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>AvgHumidity</th>\n",
       "      <th>TotalRainfall</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Season</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Pesticide</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "      <td>Arecanut</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>359.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>944.6</td>\n",
       "      <td>51351.36</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>439248.0</td>\n",
       "      <td>199414.0</td>\n",
       "      <td>944.6</td>\n",
       "      <td>62830033.92</td>\n",
       "      <td>39532.32</td>\n",
       "      <td>0.530909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>3466.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>944.6</td>\n",
       "      <td>495776.64</td>\n",
       "      <td>311.94</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "      <td>Bajra</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>49844.0</td>\n",
       "      <td>51316.0</td>\n",
       "      <td>944.6</td>\n",
       "      <td>7129685.76</td>\n",
       "      <td>4485.96</td>\n",
       "      <td>1.134375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2008</td>\n",
       "      <td>27.2</td>\n",
       "      <td>67</td>\n",
       "      <td>950</td>\n",
       "      <td>Bajra</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>944.6</td>\n",
       "      <td>1326552.96</td>\n",
       "      <td>834.66</td>\n",
       "      <td>1.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Year  AvgTemp  AvgHumidity  TotalRainfall       Crop  \\\n",
       "0  Andhra Pradesh  2008     27.2           67            950   Arecanut   \n",
       "1  Andhra Pradesh  2008     27.2           67            950  Arhar/Tur   \n",
       "2  Andhra Pradesh  2008     27.2           67            950  Arhar/Tur   \n",
       "3  Andhra Pradesh  2008     27.2           67            950      Bajra   \n",
       "4  Andhra Pradesh  2008     27.2           67            950      Bajra   \n",
       "\n",
       "        Season      Area  Production  Annual_Rainfall   Fertilizer  Pesticide  \\\n",
       "0  Whole Year      359.0       265.0            944.6     51351.36      32.31   \n",
       "1  Kharif       439248.0    199414.0            944.6  62830033.92   39532.32   \n",
       "2  Rabi           3466.0      1942.0            944.6    495776.64     311.94   \n",
       "3  Kharif        49844.0     51316.0            944.6   7129685.76    4485.96   \n",
       "4  Rabi           9274.0      8873.0            944.6   1326552.96     834.66   \n",
       "\n",
       "      Yield  \n",
       "0  0.915000  \n",
       "1  0.530909  \n",
       "2  0.560000  \n",
       "3  1.134375  \n",
       "4  1.187500  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bcf6309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arecanut', 'Arhar/Tur', 'Bajra', 'Banana', 'Cashewnut',\n",
       "       'Castor seed', 'Coconut ', 'Coriander', 'Cotton(lint)',\n",
       "       'Dry chillies', 'Ginger', 'Gram', 'Groundnut', 'Horse-gram',\n",
       "       'Jowar', 'Linseed', 'Maize', 'Mesta', 'Moong(Green Gram)',\n",
       "       'Niger seed', 'Onion', 'Other  Rabi pulses', 'Other Kharif pulses',\n",
       "       'Potato', 'Ragi', 'Rapeseed &Mustard', 'Rice', 'Safflower',\n",
       "       'Sesamum', 'Small millets', 'Soyabean', 'Sugarcane', 'Sunflower',\n",
       "       'Sweet potato', 'Tapioca', 'Tobacco', 'Urad', 'Wheat', 'Garlic',\n",
       "       'Cowpea(Lobia)', 'other oilseeds', 'Black pepper', 'Sannhamp',\n",
       "       'Oilseeds total', 'Guar seed', nan, 'Cardamom', 'Turmeric', 'Jute',\n",
       "       'Masoor', 'Other Cereals', 'Moth', 'Barley',\n",
       "       'Peas & beans (Pulses)', 'Khesari', 'Other Summer Pulses'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f42d6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Potato = merged_df[merged_df['Crop'] == 'Potato']\n",
    "Potato.to_csv('Potato.csv', index=False)\n",
    "\n",
    "Onion = merged_df[merged_df['Crop'] == 'Onion']\n",
    "Onion.to_csv('Onion.csv', index=False)\n",
    "\n",
    "Rice = merged_df[merged_df['Crop'] == 'Rice']\n",
    "Rice.to_csv('Rice.csv', index=False)\n",
    "\n",
    "Soyabean = merged_df[merged_df['Crop'] == 'Soyabean']\n",
    "Soyabean.to_csv('Soyabean.csv', index=False)\n",
    "\n",
    "Ragi = merged_df[merged_df['Crop'] == 'Ragi']\n",
    "Ragi.to_csv('Ragi.csv', index=False)\n",
    "\n",
    "Sugarcane = merged_df[merged_df['Crop'] == 'Tapioca']\n",
    "Sugarcane.to_csv('Tapioca.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5b8bf",
   "metadata": {},
   "source": [
    "# Initial Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c606ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\3347865955.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 1s 142ms/step - loss: 1317.1417 - val_loss: 214.6153\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1311.7454 - val_loss: 210.5796\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1306.2903 - val_loss: 206.7054\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1301.1647 - val_loss: 202.8936\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1295.8160 - val_loss: 199.0444\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1290.3739 - val_loss: 195.0792\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1284.7136 - val_loss: 190.9150\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1278.8058 - val_loss: 186.5356\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1272.5233 - val_loss: 181.9601\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1265.4401 - val_loss: 177.1484\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1258.4114 - val_loss: 172.0137\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1251.0571 - val_loss: 166.6818\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1242.4662 - val_loss: 161.2288\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1234.4928 - val_loss: 155.4954\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1225.7655 - val_loss: 149.6089\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1216.1477 - val_loss: 143.5709\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1206.1603 - val_loss: 137.3970\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1196.2531 - val_loss: 131.0029\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1184.9290 - val_loss: 124.3560\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1174.9686 - val_loss: 117.6192\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1162.7850 - val_loss: 110.9739\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1152.8610 - val_loss: 104.2717\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1140.0117 - val_loss: 98.0536\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1128.2551 - val_loss: 92.1074\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1118.4196 - val_loss: 86.4979\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1107.7601 - val_loss: 81.3336\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1095.6106 - val_loss: 76.7535\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1085.9025 - val_loss: 72.6731\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1075.9117 - val_loss: 69.1440\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1067.3038 - val_loss: 66.1811\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1058.2239 - val_loss: 63.8285\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1051.2551 - val_loss: 62.0978\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1043.9589 - val_loss: 61.0676\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1037.3594 - val_loss: 60.6670\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1031.9733 - val_loss: 60.9656\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1026.2029 - val_loss: 61.7603\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1023.3563 - val_loss: 63.0719\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1018.1430 - val_loss: 64.6013\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1015.5413 - val_loss: 67.3264\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1013.0192 - val_loss: 69.7606\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1010.8902 - val_loss: 71.5325\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1009.4548 - val_loss: 72.9974\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1008.8014 - val_loss: 74.6361\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1007.2076 - val_loss: 74.9936\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1006.4567 - val_loss: 74.6678\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1005.7257 - val_loss: 73.6763\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1004.9706 - val_loss: 72.5258\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1004.5876 - val_loss: 71.0615\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1003.9802 - val_loss: 70.1420\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1003.8983 - val_loss: 70.3749\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1003.0445 - val_loss: 70.8719\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1002.5320 - val_loss: 71.1683\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1001.9880 - val_loss: 71.1735\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1001.5621 - val_loss: 71.6758\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1001.1337 - val_loss: 73.6985\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1000.3688 - val_loss: 74.4092\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 999.9337 - val_loss: 74.8134\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 999.5422 - val_loss: 76.4017\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 999.1308 - val_loss: 79.0185\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 999.0343 - val_loss: 80.2846\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 998.6194 - val_loss: 80.5684\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 998.4302 - val_loss: 80.8334\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 998.2192 - val_loss: 80.9518\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 998.2308 - val_loss: 83.5618\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 998.5258 - val_loss: 85.3629\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 997.8885 - val_loss: 84.7184\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 997.4502 - val_loss: 82.4965\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 996.6075 - val_loss: 80.1827\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 996.6152 - val_loss: 77.0046\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 995.6741 - val_loss: 74.3831\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 995.6478 - val_loss: 71.8221\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 995.6856 - val_loss: 69.4764\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 995.3360 - val_loss: 67.8383\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 995.3564 - val_loss: 66.8853\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 995.3550 - val_loss: 66.5422\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 995.1895 - val_loss: 66.5686\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 995.0136 - val_loss: 67.0463\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 994.4246 - val_loss: 69.3308\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 993.8156 - val_loss: 70.8083\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 993.7981 - val_loss: 71.7556\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 993.6681 - val_loss: 71.6051\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 993.5231 - val_loss: 71.8542\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 993.0192 - val_loss: 73.8009\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 993.1768 - val_loss: 74.8148\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 992.6314 - val_loss: 74.7812\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 992.6265 - val_loss: 74.5407\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 992.0406 - val_loss: 76.1666\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 992.1967 - val_loss: 77.4614\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 991.8686 - val_loss: 77.5228\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 991.7797 - val_loss: 76.3717\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 991.7019 - val_loss: 74.7997\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 991.2045 - val_loss: 74.1992\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 991.0023 - val_loss: 74.3676\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 990.6060 - val_loss: 74.4279\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 990.4017 - val_loss: 74.8029\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 990.2101 - val_loss: 74.7658\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 990.0255 - val_loss: 74.9846\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 989.7596 - val_loss: 75.7818\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 990.0321 - val_loss: 76.9882\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 989.4832 - val_loss: 76.7816\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 989.5818 - val_loss: 76.1710\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 988.8865 - val_loss: 77.6234\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 988.7545 - val_loss: 78.2286\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 988.5206 - val_loss: 78.6312\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 988.3984 - val_loss: 78.7305\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 987.9737 - val_loss: 78.1262\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 987.7440 - val_loss: 77.8208\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 987.3791 - val_loss: 78.2158\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 987.4353 - val_loss: 79.0992\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 987.9426 - val_loss: 82.4531\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 987.2103 - val_loss: 83.2439\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 987.1214 - val_loss: 83.6568\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 987.1011 - val_loss: 84.9295\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 986.8002 - val_loss: 84.1754\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 986.4338 - val_loss: 82.7914\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 986.0500 - val_loss: 81.9351\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 985.3999 - val_loss: 79.8223\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 985.3878 - val_loss: 77.4379\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 984.5728 - val_loss: 76.1865\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 984.2751 - val_loss: 74.2051\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 984.2718 - val_loss: 72.8766\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 983.9485 - val_loss: 72.8635\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 983.6529 - val_loss: 72.2674\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 983.8326 - val_loss: 72.0864\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 982.7142 - val_loss: 74.4042\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 982.6302 - val_loss: 75.8698\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 982.3246 - val_loss: 77.0424\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 982.3386 - val_loss: 79.7504\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 982.4210 - val_loss: 81.3904\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 982.2536 - val_loss: 81.4368\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 981.8644 - val_loss: 80.3059\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 981.2496 - val_loss: 79.3656\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 980.6525 - val_loss: 77.5424\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 980.4230 - val_loss: 75.1232\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 979.8859 - val_loss: 73.2070\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 979.2743 - val_loss: 72.2007\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 979.0054 - val_loss: 71.3769\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 978.8223 - val_loss: 70.1177\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 978.6497 - val_loss: 69.6156\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 978.1390 - val_loss: 69.2174\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 977.8813 - val_loss: 68.4000\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 977.6382 - val_loss: 67.7381\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 977.3502 - val_loss: 67.2229\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 977.0841 - val_loss: 66.5203\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 976.8010 - val_loss: 65.4758\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 976.6974 - val_loss: 64.3654\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 976.7391 - val_loss: 63.1657\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 976.5578 - val_loss: 62.2218\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 976.7379 - val_loss: 61.5635\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 976.3647 - val_loss: 61.7583\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Mean Squared Error on Test Data: 61.76\n",
      "Prediction: 16.55, Actual: 8.55\n",
      "Prediction: 14.62, Actual: 14.46\n",
      "Prediction: 21.94, Actual: 8.50\n",
      "Prediction: 10.72, Actual: 5.00\n",
      "Prediction: 9.21, Actual: 2.79\n",
      "Prediction: 4.70, Actual: 8.01\n",
      "Prediction: 15.47, Actual: 14.75\n",
      "Prediction: 22.19, Actual: 8.03\n",
      "Prediction: 6.13, Actual: 2.21\n",
      "Prediction: 7.38, Actual: 5.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "\n",
    "df = pd.read_csv('Onion.csv')\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall','Fertilizer','Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train a simple feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=len(features)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=100, validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Test Data: {mse:.2f}\")\n",
    "\n",
    "# Display some predictions and actual values\n",
    "for i in range(10):  # Displaying first 10 predictions for illustration\n",
    "    print(f\"Prediction: {y_pred[i][0]:.2f}, Actual: {y_test[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dda1b",
   "metadata": {},
   "source": [
    "# After manual tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e13f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\698557233.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 22ms/step - loss: 1206.4897 - root_mean_squared_error: 34.7346 - val_loss: 123.5269 - val_root_mean_squared_error: 11.1143\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1201.7333 - root_mean_squared_error: 34.6660 - val_loss: 118.6592 - val_root_mean_squared_error: 10.8931\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1191.1006 - root_mean_squared_error: 34.5123 - val_loss: 108.2436 - val_root_mean_squared_error: 10.4040\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1166.4917 - root_mean_squared_error: 34.1539 - val_loss: 86.6462 - val_root_mean_squared_error: 9.3084\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1108.1594 - root_mean_squared_error: 33.2890 - val_loss: 53.7313 - val_root_mean_squared_error: 7.3302\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1016.7205 - root_mean_squared_error: 31.8861 - val_loss: 45.5432 - val_root_mean_squared_error: 6.7486\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 943.5212 - root_mean_squared_error: 30.7168 - val_loss: 71.3331 - val_root_mean_squared_error: 8.4459\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 919.7701 - root_mean_squared_error: 30.3277 - val_loss: 96.0387 - val_root_mean_squared_error: 9.7999\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 908.8322 - root_mean_squared_error: 30.1468 - val_loss: 97.1633 - val_root_mean_squared_error: 9.8571\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 902.5381 - root_mean_squared_error: 30.0423 - val_loss: 92.5120 - val_root_mean_squared_error: 9.6183\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 899.9322 - root_mean_squared_error: 29.9989 - val_loss: 93.3292 - val_root_mean_squared_error: 9.6607\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 899.8837 - root_mean_squared_error: 29.9981 - val_loss: 98.9915 - val_root_mean_squared_error: 9.9494\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 897.1961 - root_mean_squared_error: 29.9532 - val_loss: 87.4634 - val_root_mean_squared_error: 9.3522\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 895.0614 - root_mean_squared_error: 29.9176 - val_loss: 98.3669 - val_root_mean_squared_error: 9.9180\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 895.1998 - root_mean_squared_error: 29.9199 - val_loss: 99.8702 - val_root_mean_squared_error: 9.9935\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 893.0522 - root_mean_squared_error: 29.8840 - val_loss: 97.4882 - val_root_mean_squared_error: 9.8736\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 892.0572 - root_mean_squared_error: 29.8673 - val_loss: 97.2623 - val_root_mean_squared_error: 9.8622\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 891.3451 - root_mean_squared_error: 29.8554 - val_loss: 98.0413 - val_root_mean_squared_error: 9.9016\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 890.3362 - root_mean_squared_error: 29.8385 - val_loss: 96.6984 - val_root_mean_squared_error: 9.8335\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 890.3364 - root_mean_squared_error: 29.8385 - val_loss: 92.5414 - val_root_mean_squared_error: 9.6198\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 890.6509 - root_mean_squared_error: 29.8438 - val_loss: 81.2464 - val_root_mean_squared_error: 9.0137\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 890.4525 - root_mean_squared_error: 29.8404 - val_loss: 96.1610 - val_root_mean_squared_error: 9.8062\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 888.2013 - root_mean_squared_error: 29.8027 - val_loss: 99.0959 - val_root_mean_squared_error: 9.9547\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 888.2234 - root_mean_squared_error: 29.8031 - val_loss: 85.8696 - val_root_mean_squared_error: 9.2666\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 887.5762 - root_mean_squared_error: 29.7922 - val_loss: 98.3436 - val_root_mean_squared_error: 9.9168\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 885.2874 - root_mean_squared_error: 29.7538 - val_loss: 88.8992 - val_root_mean_squared_error: 9.4286\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 885.9824 - root_mean_squared_error: 29.7655 - val_loss: 96.1740 - val_root_mean_squared_error: 9.8068\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 884.1998 - root_mean_squared_error: 29.7355 - val_loss: 95.9876 - val_root_mean_squared_error: 9.7973\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 885.1380 - root_mean_squared_error: 29.7513 - val_loss: 82.6585 - val_root_mean_squared_error: 9.0917\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 882.5389 - root_mean_squared_error: 29.7076 - val_loss: 95.5707 - val_root_mean_squared_error: 9.7760\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 882.5587 - root_mean_squared_error: 29.7079 - val_loss: 93.2365 - val_root_mean_squared_error: 9.6559\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 882.1035 - root_mean_squared_error: 29.7002 - val_loss: 88.3145 - val_root_mean_squared_error: 9.3976\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 881.3676 - root_mean_squared_error: 29.6878 - val_loss: 89.3694 - val_root_mean_squared_error: 9.4535\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 880.1418 - root_mean_squared_error: 29.6672 - val_loss: 96.4220 - val_root_mean_squared_error: 9.8195\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 879.2863 - root_mean_squared_error: 29.6528 - val_loss: 85.7182 - val_root_mean_squared_error: 9.2584\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 879.2443 - root_mean_squared_error: 29.6521 - val_loss: 78.9200 - val_root_mean_squared_error: 8.8837\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 887.5931 - root_mean_squared_error: 29.7925 - val_loss: 96.5616 - val_root_mean_squared_error: 9.8266\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 877.4849 - root_mean_squared_error: 29.6224 - val_loss: 85.7018 - val_root_mean_squared_error: 9.2575\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 876.5075 - root_mean_squared_error: 29.6059 - val_loss: 88.4263 - val_root_mean_squared_error: 9.4035\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 877.0075 - root_mean_squared_error: 29.6143 - val_loss: 84.1080 - val_root_mean_squared_error: 9.1710\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 876.2372 - root_mean_squared_error: 29.6013 - val_loss: 79.8684 - val_root_mean_squared_error: 8.9369\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 874.1609 - root_mean_squared_error: 29.5662 - val_loss: 84.7771 - val_root_mean_squared_error: 9.2074\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 873.0548 - root_mean_squared_error: 29.5475 - val_loss: 95.7458 - val_root_mean_squared_error: 9.7850\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 874.1964 - root_mean_squared_error: 29.5668 - val_loss: 78.1109 - val_root_mean_squared_error: 8.8380\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 871.6887 - root_mean_squared_error: 29.5244 - val_loss: 88.6180 - val_root_mean_squared_error: 9.4137\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 871.0751 - root_mean_squared_error: 29.5140 - val_loss: 93.3484 - val_root_mean_squared_error: 9.6617\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 869.6346 - root_mean_squared_error: 29.4896 - val_loss: 87.5788 - val_root_mean_squared_error: 9.3584\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 871.3241 - root_mean_squared_error: 29.5182 - val_loss: 88.9357 - val_root_mean_squared_error: 9.4306\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 868.4846 - root_mean_squared_error: 29.4701 - val_loss: 83.9894 - val_root_mean_squared_error: 9.1646\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 868.3917 - root_mean_squared_error: 29.4685 - val_loss: 86.7899 - val_root_mean_squared_error: 9.3161\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 868.9676 - root_mean_squared_error: 29.4783 - val_loss: 73.0086 - val_root_mean_squared_error: 8.5445\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 866.9696 - root_mean_squared_error: 29.4443 - val_loss: 89.1236 - val_root_mean_squared_error: 9.4405\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 866.7929 - root_mean_squared_error: 29.4413 - val_loss: 79.9677 - val_root_mean_squared_error: 8.9425\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 863.7555 - root_mean_squared_error: 29.3897 - val_loss: 79.8934 - val_root_mean_squared_error: 8.9383\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 863.4406 - root_mean_squared_error: 29.3844 - val_loss: 87.6801 - val_root_mean_squared_error: 9.3638\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 863.9309 - root_mean_squared_error: 29.3927 - val_loss: 87.9756 - val_root_mean_squared_error: 9.3795\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 865.1029 - root_mean_squared_error: 29.4126 - val_loss: 68.0233 - val_root_mean_squared_error: 8.2476\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 860.1491 - root_mean_squared_error: 29.3283 - val_loss: 83.9475 - val_root_mean_squared_error: 9.1623\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 859.3487 - root_mean_squared_error: 29.3146 - val_loss: 88.0862 - val_root_mean_squared_error: 9.3854\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 861.9368 - root_mean_squared_error: 29.3588 - val_loss: 72.7587 - val_root_mean_squared_error: 8.5299\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 856.5956 - root_mean_squared_error: 29.2677 - val_loss: 89.4730 - val_root_mean_squared_error: 9.4590\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 860.3381 - root_mean_squared_error: 29.3315 - val_loss: 72.4749 - val_root_mean_squared_error: 8.5132\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 857.5804 - root_mean_squared_error: 29.2845 - val_loss: 94.9771 - val_root_mean_squared_error: 9.7456\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 854.9037 - root_mean_squared_error: 29.2387 - val_loss: 84.1612 - val_root_mean_squared_error: 9.1739\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 854.9372 - root_mean_squared_error: 29.2393 - val_loss: 75.7585 - val_root_mean_squared_error: 8.7039\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 853.7883 - root_mean_squared_error: 29.2197 - val_loss: 83.2547 - val_root_mean_squared_error: 9.1244\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 857.7454 - root_mean_squared_error: 29.2873 - val_loss: 64.7600 - val_root_mean_squared_error: 8.0474\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 853.6219 - root_mean_squared_error: 29.2168 - val_loss: 93.3604 - val_root_mean_squared_error: 9.6623\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 851.8136 - root_mean_squared_error: 29.1858 - val_loss: 73.0297 - val_root_mean_squared_error: 8.5457\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 850.7341 - root_mean_squared_error: 29.1673 - val_loss: 73.3522 - val_root_mean_squared_error: 8.5646\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 850.4302 - root_mean_squared_error: 29.1621 - val_loss: 90.1482 - val_root_mean_squared_error: 9.4946\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 847.8472 - root_mean_squared_error: 29.1178 - val_loss: 80.4826 - val_root_mean_squared_error: 8.9712\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 846.5405 - root_mean_squared_error: 29.0954 - val_loss: 80.1211 - val_root_mean_squared_error: 8.9510\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 847.3797 - root_mean_squared_error: 29.1098 - val_loss: 85.0111 - val_root_mean_squared_error: 9.2201\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 845.1646 - root_mean_squared_error: 29.0717 - val_loss: 76.8930 - val_root_mean_squared_error: 8.7689\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 845.8157 - root_mean_squared_error: 29.0829 - val_loss: 68.6230 - val_root_mean_squared_error: 8.2839\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 842.3096 - root_mean_squared_error: 29.0226 - val_loss: 79.4526 - val_root_mean_squared_error: 8.9136\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 842.6708 - root_mean_squared_error: 29.0288 - val_loss: 86.5388 - val_root_mean_squared_error: 9.3026\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 842.9337 - root_mean_squared_error: 29.0333 - val_loss: 78.4430 - val_root_mean_squared_error: 8.8568\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 842.1168 - root_mean_squared_error: 29.0192 - val_loss: 82.1089 - val_root_mean_squared_error: 9.0614\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 839.2303 - root_mean_squared_error: 28.9695 - val_loss: 71.1945 - val_root_mean_squared_error: 8.4377\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 839.1786 - root_mean_squared_error: 28.9686 - val_loss: 77.4767 - val_root_mean_squared_error: 8.8021\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 838.3891 - root_mean_squared_error: 28.9550 - val_loss: 80.3128 - val_root_mean_squared_error: 8.9617\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 837.8672 - root_mean_squared_error: 28.9459 - val_loss: 78.2852 - val_root_mean_squared_error: 8.8479\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 837.3797 - root_mean_squared_error: 28.9375 - val_loss: 79.6543 - val_root_mean_squared_error: 8.9249\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 834.9518 - root_mean_squared_error: 28.8955 - val_loss: 81.4561 - val_root_mean_squared_error: 9.0253\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 835.2804 - root_mean_squared_error: 28.9012 - val_loss: 70.4896 - val_root_mean_squared_error: 8.3958\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 836.7996 - root_mean_squared_error: 28.9275 - val_loss: 87.4077 - val_root_mean_squared_error: 9.3492\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 831.6536 - root_mean_squared_error: 28.8384 - val_loss: 76.1342 - val_root_mean_squared_error: 8.7255\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 830.7680 - root_mean_squared_error: 28.8230 - val_loss: 75.1409 - val_root_mean_squared_error: 8.6684\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 829.8961 - root_mean_squared_error: 28.8079 - val_loss: 82.7216 - val_root_mean_squared_error: 9.0951\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 828.9142 - root_mean_squared_error: 28.7909 - val_loss: 78.8661 - val_root_mean_squared_error: 8.8807\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 9ms/step - loss: 828.6194 - root_mean_squared_error: 28.7857 - val_loss: 80.0435 - val_root_mean_squared_error: 8.9467\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 827.4966 - root_mean_squared_error: 28.7662 - val_loss: 77.3574 - val_root_mean_squared_error: 8.7953\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 826.0162 - root_mean_squared_error: 28.7405 - val_loss: 85.3631 - val_root_mean_squared_error: 9.2392\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 824.4795 - root_mean_squared_error: 28.7137 - val_loss: 73.9567 - val_root_mean_squared_error: 8.5998\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 830.6942 - root_mean_squared_error: 28.8218 - val_loss: 60.5481 - val_root_mean_squared_error: 7.7813\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 826.4052 - root_mean_squared_error: 28.7473 - val_loss: 97.4813 - val_root_mean_squared_error: 9.8733\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 823.1225 - root_mean_squared_error: 28.6901 - val_loss: 76.8949 - val_root_mean_squared_error: 8.7690\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 822.4159 - root_mean_squared_error: 28.6778 - val_loss: 84.4946 - val_root_mean_squared_error: 9.1921\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 84.4946 - root_mean_squared_error: 9.1921\n",
      "Root Mean Squared Error on Test Data: 9.19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train a simple feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Use RootMeanSquaredError as a custom metric\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test)\n",
    "rmse_value = results[1]\n",
    "\n",
    "print(f\"Root Mean Squared Error on Test Data: {rmse_value:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7be24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\1615763674.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 17ms/step - loss: 113.0211 - root_mean_squared_error: 10.6311 - val_loss: 34.8159 - val_root_mean_squared_error: 5.9005\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 26.4869 - root_mean_squared_error: 5.1465 - val_loss: 45.2473 - val_root_mean_squared_error: 6.7266\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 24.0496 - root_mean_squared_error: 4.9040 - val_loss: 30.3760 - val_root_mean_squared_error: 5.5114\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 22.0263 - root_mean_squared_error: 4.6932 - val_loss: 30.3100 - val_root_mean_squared_error: 5.5054\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 21.6371 - root_mean_squared_error: 4.6516 - val_loss: 32.3009 - val_root_mean_squared_error: 5.6834\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 21.4416 - root_mean_squared_error: 4.6305 - val_loss: 34.1613 - val_root_mean_squared_error: 5.8448\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 20.5189 - root_mean_squared_error: 4.5298 - val_loss: 23.3670 - val_root_mean_squared_error: 4.8339\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 18.4955 - root_mean_squared_error: 4.3006 - val_loss: 31.0230 - val_root_mean_squared_error: 5.5698\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 18.3660 - root_mean_squared_error: 4.2856 - val_loss: 20.5724 - val_root_mean_squared_error: 4.5357\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 16.8276 - root_mean_squared_error: 4.1021 - val_loss: 20.6559 - val_root_mean_squared_error: 4.5449\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 16.9132 - root_mean_squared_error: 4.1126 - val_loss: 19.4978 - val_root_mean_squared_error: 4.4156\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 16.8417 - root_mean_squared_error: 4.1039 - val_loss: 17.4176 - val_root_mean_squared_error: 4.1734\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 15.8426 - root_mean_squared_error: 3.9803 - val_loss: 20.2410 - val_root_mean_squared_error: 4.4990\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 16.1213 - root_mean_squared_error: 4.0151 - val_loss: 18.3179 - val_root_mean_squared_error: 4.2799\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 15.4239 - root_mean_squared_error: 3.9273 - val_loss: 21.5238 - val_root_mean_squared_error: 4.6394\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 16.7294 - root_mean_squared_error: 4.0902 - val_loss: 18.4989 - val_root_mean_squared_error: 4.3010\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 15.3132 - root_mean_squared_error: 3.9132 - val_loss: 15.5027 - val_root_mean_squared_error: 3.9373\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 14.5957 - root_mean_squared_error: 3.8204 - val_loss: 13.0303 - val_root_mean_squared_error: 3.6097\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 14.9521 - root_mean_squared_error: 3.8668 - val_loss: 15.3936 - val_root_mean_squared_error: 3.9235\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 14.4409 - root_mean_squared_error: 3.8001 - val_loss: 15.6957 - val_root_mean_squared_error: 3.9618\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 14.6125 - root_mean_squared_error: 3.8226 - val_loss: 22.6503 - val_root_mean_squared_error: 4.7592\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 15.0665 - root_mean_squared_error: 3.8816 - val_loss: 18.7945 - val_root_mean_squared_error: 4.3353\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 14.1708 - root_mean_squared_error: 3.7644 - val_loss: 11.8070 - val_root_mean_squared_error: 3.4361\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 13.6554 - root_mean_squared_error: 3.6953 - val_loss: 18.9985 - val_root_mean_squared_error: 4.3587\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 14.1999 - root_mean_squared_error: 3.7683 - val_loss: 14.9185 - val_root_mean_squared_error: 3.8625\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.7184 - root_mean_squared_error: 3.7038 - val_loss: 13.9032 - val_root_mean_squared_error: 3.7287\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.9931 - root_mean_squared_error: 3.7407 - val_loss: 13.8696 - val_root_mean_squared_error: 3.7242\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.4421 - root_mean_squared_error: 3.6663 - val_loss: 12.3555 - val_root_mean_squared_error: 3.5150\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 14.2156 - root_mean_squared_error: 3.7704 - val_loss: 14.5631 - val_root_mean_squared_error: 3.8162\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 13.4550 - root_mean_squared_error: 3.6681 - val_loss: 16.2243 - val_root_mean_squared_error: 4.0279\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.7448 - root_mean_squared_error: 3.7074 - val_loss: 11.2512 - val_root_mean_squared_error: 3.3543\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.5282 - root_mean_squared_error: 3.6781 - val_loss: 14.9558 - val_root_mean_squared_error: 3.8673\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.6826 - root_mean_squared_error: 3.6990 - val_loss: 11.1999 - val_root_mean_squared_error: 3.3466\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.3270 - root_mean_squared_error: 3.6506 - val_loss: 12.3934 - val_root_mean_squared_error: 3.5204\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 13.0315 - root_mean_squared_error: 3.6099 - val_loss: 10.3905 - val_root_mean_squared_error: 3.2234\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.2297 - root_mean_squared_error: 3.6373 - val_loss: 14.2936 - val_root_mean_squared_error: 3.7807\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 12.3442 - root_mean_squared_error: 3.5134 - val_loss: 10.8338 - val_root_mean_squared_error: 3.2915\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.1301 - root_mean_squared_error: 3.6235 - val_loss: 10.2004 - val_root_mean_squared_error: 3.1938\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 12.7322 - root_mean_squared_error: 3.5682 - val_loss: 11.4079 - val_root_mean_squared_error: 3.3776\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 12.6778 - root_mean_squared_error: 3.5606 - val_loss: 13.4307 - val_root_mean_squared_error: 3.6648\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 12.8908 - root_mean_squared_error: 3.5904 - val_loss: 12.4172 - val_root_mean_squared_error: 3.5238\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 12.2900 - root_mean_squared_error: 3.5057 - val_loss: 12.2241 - val_root_mean_squared_error: 3.4963\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 12.0295 - root_mean_squared_error: 3.4684 - val_loss: 13.0355 - val_root_mean_squared_error: 3.6105\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 11.7953 - root_mean_squared_error: 3.4344 - val_loss: 12.8292 - val_root_mean_squared_error: 3.5818\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 11.6484 - root_mean_squared_error: 3.4130 - val_loss: 11.5430 - val_root_mean_squared_error: 3.3975\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.6051 - root_mean_squared_error: 3.4066 - val_loss: 13.2693 - val_root_mean_squared_error: 3.6427\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 12.0554 - root_mean_squared_error: 3.4721 - val_loss: 13.5667 - val_root_mean_squared_error: 3.6833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 12.5580 - root_mean_squared_error: 3.5437 - val_loss: 17.8137 - val_root_mean_squared_error: 4.2206\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 11.7523 - root_mean_squared_error: 3.4282 - val_loss: 15.6551 - val_root_mean_squared_error: 3.9567\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 13.1338 - root_mean_squared_error: 3.6241 - val_loss: 9.2907 - val_root_mean_squared_error: 3.0481\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 12.4006 - root_mean_squared_error: 3.5214 - val_loss: 10.9179 - val_root_mean_squared_error: 3.3042\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 12.3485 - root_mean_squared_error: 3.5140 - val_loss: 11.6184 - val_root_mean_squared_error: 3.4086\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.0206 - root_mean_squared_error: 3.3197 - val_loss: 12.4054 - val_root_mean_squared_error: 3.5221\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.4299 - root_mean_squared_error: 3.3808 - val_loss: 9.5747 - val_root_mean_squared_error: 3.0943\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 11.2347 - root_mean_squared_error: 3.3518 - val_loss: 10.9981 - val_root_mean_squared_error: 3.3163\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 11.6318 - root_mean_squared_error: 3.4105 - val_loss: 14.3850 - val_root_mean_squared_error: 3.7928\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.7252 - root_mean_squared_error: 3.4242 - val_loss: 16.1551 - val_root_mean_squared_error: 4.0193\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.1634 - root_mean_squared_error: 3.3412 - val_loss: 11.9924 - val_root_mean_squared_error: 3.4630\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.7011 - root_mean_squared_error: 3.4207 - val_loss: 12.7992 - val_root_mean_squared_error: 3.5776\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 10.9378 - root_mean_squared_error: 3.3072 - val_loss: 10.5198 - val_root_mean_squared_error: 3.2434\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.0731 - root_mean_squared_error: 3.3276 - val_loss: 10.9178 - val_root_mean_squared_error: 3.3042\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 10.8225 - root_mean_squared_error: 3.2898 - val_loss: 10.6699 - val_root_mean_squared_error: 3.2665\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 10.7128 - root_mean_squared_error: 3.2730 - val_loss: 12.9686 - val_root_mean_squared_error: 3.6012\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 10.1068 - root_mean_squared_error: 3.1791 - val_loss: 10.7427 - val_root_mean_squared_error: 3.2776\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.8623 - root_mean_squared_error: 3.1404 - val_loss: 11.3632 - val_root_mean_squared_error: 3.3709\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 10.3356 - root_mean_squared_error: 3.2149 - val_loss: 10.6797 - val_root_mean_squared_error: 3.2680\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 10.3822 - root_mean_squared_error: 3.2221 - val_loss: 11.5025 - val_root_mean_squared_error: 3.3915\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 10.8599 - root_mean_squared_error: 3.2954 - val_loss: 16.9659 - val_root_mean_squared_error: 4.1190\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.5668 - root_mean_squared_error: 3.0930 - val_loss: 13.6308 - val_root_mean_squared_error: 3.6920\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 10.2467 - root_mean_squared_error: 3.2010 - val_loss: 13.5513 - val_root_mean_squared_error: 3.6812\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 10.5306 - root_mean_squared_error: 3.2451 - val_loss: 13.2026 - val_root_mean_squared_error: 3.6335\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.9267 - root_mean_squared_error: 3.1507 - val_loss: 10.1672 - val_root_mean_squared_error: 3.1886\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 10.0289 - root_mean_squared_error: 3.1668 - val_loss: 13.1781 - val_root_mean_squared_error: 3.6302\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.6015 - root_mean_squared_error: 3.0986 - val_loss: 10.7941 - val_root_mean_squared_error: 3.2854\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.1926 - root_mean_squared_error: 3.0319 - val_loss: 11.0270 - val_root_mean_squared_error: 3.3207\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.2760 - root_mean_squared_error: 3.0456 - val_loss: 11.1067 - val_root_mean_squared_error: 3.3327\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.8075 - root_mean_squared_error: 3.1317 - val_loss: 11.6307 - val_root_mean_squared_error: 3.4104\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 11.1053 - root_mean_squared_error: 3.3325 - val_loss: 11.9828 - val_root_mean_squared_error: 3.4616\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.0965 - root_mean_squared_error: 3.0160 - val_loss: 11.8595 - val_root_mean_squared_error: 3.4438\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 9.3702 - root_mean_squared_error: 3.0611 - val_loss: 11.7392 - val_root_mean_squared_error: 3.4262\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.1055 - root_mean_squared_error: 3.0175 - val_loss: 15.3240 - val_root_mean_squared_error: 3.9146\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.8477 - root_mean_squared_error: 2.9745 - val_loss: 12.6819 - val_root_mean_squared_error: 3.5612\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 10.7453 - root_mean_squared_error: 3.2780 - val_loss: 12.7858 - val_root_mean_squared_error: 3.5757\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.6344 - root_mean_squared_error: 2.9384 - val_loss: 11.6276 - val_root_mean_squared_error: 3.4099\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 9.5654 - root_mean_squared_error: 3.0928 - val_loss: 14.5431 - val_root_mean_squared_error: 3.8135\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.4688 - root_mean_squared_error: 2.9101 - val_loss: 10.6058 - val_root_mean_squared_error: 3.2567\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 8.3296 - root_mean_squared_error: 2.8861 - val_loss: 10.9052 - val_root_mean_squared_error: 3.3023\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 8.0343 - root_mean_squared_error: 2.8345 - val_loss: 15.6409 - val_root_mean_squared_error: 3.9549\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 9.1140 - root_mean_squared_error: 3.0189 - val_loss: 16.0041 - val_root_mean_squared_error: 4.0005\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 8.6110 - root_mean_squared_error: 2.9344 - val_loss: 10.3490 - val_root_mean_squared_error: 3.2170\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.9243 - root_mean_squared_error: 2.8150 - val_loss: 13.2624 - val_root_mean_squared_error: 3.6418\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.7578 - root_mean_squared_error: 2.7853 - val_loss: 14.4965 - val_root_mean_squared_error: 3.8074\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 8.1767 - root_mean_squared_error: 2.8595 - val_loss: 11.9972 - val_root_mean_squared_error: 3.4637\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 7.8337 - root_mean_squared_error: 2.7989 - val_loss: 14.2949 - val_root_mean_squared_error: 3.7809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.6758 - root_mean_squared_error: 2.7705 - val_loss: 13.1043 - val_root_mean_squared_error: 3.6200\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.9141 - root_mean_squared_error: 2.8132 - val_loss: 13.2756 - val_root_mean_squared_error: 3.6436\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.7242 - root_mean_squared_error: 2.7792 - val_loss: 15.2766 - val_root_mean_squared_error: 3.9085\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.9542 - root_mean_squared_error: 2.8203 - val_loss: 12.7448 - val_root_mean_squared_error: 3.5700\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.8447 - root_mean_squared_error: 2.8008 - val_loss: 12.9326 - val_root_mean_squared_error: 3.5962\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.4953 - root_mean_squared_error: 2.7377 - val_loss: 16.0417 - val_root_mean_squared_error: 4.0052\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 8.8629 - root_mean_squared_error: 2.9771 - val_loss: 17.6238 - val_root_mean_squared_error: 4.1981\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.6843 - root_mean_squared_error: 2.7721 - val_loss: 12.1862 - val_root_mean_squared_error: 3.4909\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.1536 - root_mean_squared_error: 2.6746 - val_loss: 10.5426 - val_root_mean_squared_error: 3.2469\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.3021 - root_mean_squared_error: 2.7022 - val_loss: 13.1025 - val_root_mean_squared_error: 3.6197\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 8.0967 - root_mean_squared_error: 2.8455 - val_loss: 15.5057 - val_root_mean_squared_error: 3.9377\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.1599 - root_mean_squared_error: 2.6758 - val_loss: 12.0322 - val_root_mean_squared_error: 3.4687\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.9851 - root_mean_squared_error: 2.6429 - val_loss: 12.0367 - val_root_mean_squared_error: 3.4694\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.9454 - root_mean_squared_error: 2.6354 - val_loss: 13.0679 - val_root_mean_squared_error: 3.6150\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.5967 - root_mean_squared_error: 2.5684 - val_loss: 13.7654 - val_root_mean_squared_error: 3.7102\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.6262 - root_mean_squared_error: 2.7616 - val_loss: 13.6658 - val_root_mean_squared_error: 3.6967\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.8511 - root_mean_squared_error: 2.6175 - val_loss: 13.2542 - val_root_mean_squared_error: 3.6406\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.0946 - root_mean_squared_error: 2.6636 - val_loss: 17.0340 - val_root_mean_squared_error: 4.1272\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6977 - root_mean_squared_error: 2.5880 - val_loss: 11.1089 - val_root_mean_squared_error: 3.3330\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 7.3952 - root_mean_squared_error: 2.7194 - val_loss: 16.4979 - val_root_mean_squared_error: 4.0618\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.7679 - root_mean_squared_error: 2.7871 - val_loss: 12.9895 - val_root_mean_squared_error: 3.6041\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.4731 - root_mean_squared_error: 2.7337 - val_loss: 17.6455 - val_root_mean_squared_error: 4.2007\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.3241 - root_mean_squared_error: 2.5148 - val_loss: 11.8313 - val_root_mean_squared_error: 3.4397\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.7975 - root_mean_squared_error: 2.6072 - val_loss: 17.3180 - val_root_mean_squared_error: 4.1615\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.1106 - root_mean_squared_error: 2.6666 - val_loss: 11.6383 - val_root_mean_squared_error: 3.4115\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3553 - root_mean_squared_error: 2.7121 - val_loss: 14.1738 - val_root_mean_squared_error: 3.7648\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.3510 - root_mean_squared_error: 2.5201 - val_loss: 13.9248 - val_root_mean_squared_error: 3.7316\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.8910 - root_mean_squared_error: 2.6251 - val_loss: 16.2189 - val_root_mean_squared_error: 4.0273\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4567 - root_mean_squared_error: 2.5410 - val_loss: 12.1175 - val_root_mean_squared_error: 3.4810\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.4902 - root_mean_squared_error: 2.5476 - val_loss: 14.1512 - val_root_mean_squared_error: 3.7618\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1300 - root_mean_squared_error: 2.4759 - val_loss: 16.1442 - val_root_mean_squared_error: 4.0180\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.2656 - root_mean_squared_error: 2.5031 - val_loss: 14.0051 - val_root_mean_squared_error: 3.7423\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.0692 - root_mean_squared_error: 2.4636 - val_loss: 14.7873 - val_root_mean_squared_error: 3.8454\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.1431 - root_mean_squared_error: 2.4785 - val_loss: 11.8118 - val_root_mean_squared_error: 3.4368\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0456 - root_mean_squared_error: 2.4588 - val_loss: 11.9279 - val_root_mean_squared_error: 3.4537\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2486 - root_mean_squared_error: 2.4997 - val_loss: 11.1061 - val_root_mean_squared_error: 3.3326\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 6.0422 - root_mean_squared_error: 2.4581 - val_loss: 12.3467 - val_root_mean_squared_error: 3.5138\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6983 - root_mean_squared_error: 2.3871 - val_loss: 14.0615 - val_root_mean_squared_error: 3.7499\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7614 - root_mean_squared_error: 2.4003 - val_loss: 10.5982 - val_root_mean_squared_error: 3.2555\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9197 - root_mean_squared_error: 2.4330 - val_loss: 14.3075 - val_root_mean_squared_error: 3.7825\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.6403 - root_mean_squared_error: 2.5769 - val_loss: 19.8422 - val_root_mean_squared_error: 4.4545\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.3747 - root_mean_squared_error: 2.7156 - val_loss: 12.7131 - val_root_mean_squared_error: 3.5655\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.2692 - root_mean_squared_error: 2.5038 - val_loss: 11.6000 - val_root_mean_squared_error: 3.4059\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 7.2811 - root_mean_squared_error: 2.6983 - val_loss: 12.2985 - val_root_mean_squared_error: 3.5069\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.5867 - root_mean_squared_error: 2.5665 - val_loss: 12.9459 - val_root_mean_squared_error: 3.5980\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9644 - root_mean_squared_error: 2.4422 - val_loss: 14.2787 - val_root_mean_squared_error: 3.7787\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5069 - root_mean_squared_error: 2.3467 - val_loss: 12.8188 - val_root_mean_squared_error: 3.5803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6397 - root_mean_squared_error: 2.3748 - val_loss: 12.8420 - val_root_mean_squared_error: 3.5836\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.7947 - root_mean_squared_error: 2.4072 - val_loss: 11.8320 - val_root_mean_squared_error: 3.4398\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.6068 - root_mean_squared_error: 2.3679 - val_loss: 11.7315 - val_root_mean_squared_error: 3.4251\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4631 - root_mean_squared_error: 2.3373 - val_loss: 11.5925 - val_root_mean_squared_error: 3.4048\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 5.7881 - root_mean_squared_error: 2.4058 - val_loss: 12.7366 - val_root_mean_squared_error: 3.5688\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.3906 - root_mean_squared_error: 2.3218 - val_loss: 13.9077 - val_root_mean_squared_error: 3.7293\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5089 - root_mean_squared_error: 2.3471 - val_loss: 12.5400 - val_root_mean_squared_error: 3.5412\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 5.6360 - root_mean_squared_error: 2.3740 - val_loss: 11.9126 - val_root_mean_squared_error: 3.4515\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5434 - root_mean_squared_error: 2.3544 - val_loss: 13.0065 - val_root_mean_squared_error: 3.6065\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 5.8525 - root_mean_squared_error: 2.4192 - val_loss: 15.8638 - val_root_mean_squared_error: 3.9829\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1646 - root_mean_squared_error: 2.2726 - val_loss: 16.6202 - val_root_mean_squared_error: 4.0768\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5171 - root_mean_squared_error: 2.3489 - val_loss: 12.1377 - val_root_mean_squared_error: 3.4839\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2842 - root_mean_squared_error: 2.2987 - val_loss: 13.5133 - val_root_mean_squared_error: 3.6760\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4876 - root_mean_squared_error: 2.3426 - val_loss: 15.1250 - val_root_mean_squared_error: 3.8891\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9715 - root_mean_squared_error: 2.2297 - val_loss: 16.4907 - val_root_mean_squared_error: 4.0609\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5381 - root_mean_squared_error: 2.3533 - val_loss: 17.1132 - val_root_mean_squared_error: 4.1368\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1516 - root_mean_squared_error: 2.2697 - val_loss: 12.7248 - val_root_mean_squared_error: 3.5672\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4460 - root_mean_squared_error: 2.3337 - val_loss: 16.7775 - val_root_mean_squared_error: 4.0960\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0995 - root_mean_squared_error: 2.2582 - val_loss: 13.7364 - val_root_mean_squared_error: 3.7063\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 6.0894 - root_mean_squared_error: 2.4677 - val_loss: 16.4358 - val_root_mean_squared_error: 4.0541\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1747 - root_mean_squared_error: 2.2748 - val_loss: 15.7778 - val_root_mean_squared_error: 3.9721\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9192 - root_mean_squared_error: 2.2179 - val_loss: 17.0871 - val_root_mean_squared_error: 4.1337\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0485 - root_mean_squared_error: 2.2469 - val_loss: 12.8296 - val_root_mean_squared_error: 3.5818\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.6269 - root_mean_squared_error: 2.1510 - val_loss: 13.4416 - val_root_mean_squared_error: 3.6663\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 4.7864 - root_mean_squared_error: 2.1878 - val_loss: 12.2549 - val_root_mean_squared_error: 3.5007\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.4780 - root_mean_squared_error: 2.3405 - val_loss: 15.8158 - val_root_mean_squared_error: 3.9769\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2855 - root_mean_squared_error: 2.2990 - val_loss: 10.5828 - val_root_mean_squared_error: 3.2531\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9645 - root_mean_squared_error: 2.2281 - val_loss: 13.5787 - val_root_mean_squared_error: 3.6849\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9539 - root_mean_squared_error: 2.2257 - val_loss: 13.8349 - val_root_mean_squared_error: 3.7195\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.1652 - root_mean_squared_error: 2.2727 - val_loss: 13.7125 - val_root_mean_squared_error: 3.7030\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0952 - root_mean_squared_error: 2.2573 - val_loss: 13.6789 - val_root_mean_squared_error: 3.6985\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 5.3166 - root_mean_squared_error: 2.3058 - val_loss: 16.3558 - val_root_mean_squared_error: 4.0442\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0997 - root_mean_squared_error: 2.2583 - val_loss: 18.2553 - val_root_mean_squared_error: 4.2726\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.5512 - root_mean_squared_error: 2.3561 - val_loss: 12.4512 - val_root_mean_squared_error: 3.5286\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6756 - root_mean_squared_error: 2.1623 - val_loss: 14.7239 - val_root_mean_squared_error: 3.8372\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5512 - root_mean_squared_error: 2.1334 - val_loss: 15.5760 - val_root_mean_squared_error: 3.9466\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 5.0927 - root_mean_squared_error: 2.2567 - val_loss: 13.9254 - val_root_mean_squared_error: 3.7317\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7956 - root_mean_squared_error: 2.1899 - val_loss: 11.8011 - val_root_mean_squared_error: 3.4353\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0958 - root_mean_squared_error: 2.2574 - val_loss: 11.7428 - val_root_mean_squared_error: 3.4268\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6151 - root_mean_squared_error: 2.1483 - val_loss: 14.0465 - val_root_mean_squared_error: 3.7479\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2960 - root_mean_squared_error: 2.3013 - val_loss: 12.6531 - val_root_mean_squared_error: 3.5571\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7165 - root_mean_squared_error: 2.1718 - val_loss: 16.8226 - val_root_mean_squared_error: 4.1015\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9741 - root_mean_squared_error: 2.2303 - val_loss: 15.3904 - val_root_mean_squared_error: 3.9231\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8994 - root_mean_squared_error: 2.2135 - val_loss: 13.8736 - val_root_mean_squared_error: 3.7247\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.5020 - root_mean_squared_error: 2.1218 - val_loss: 15.6358 - val_root_mean_squared_error: 3.9542\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7700 - root_mean_squared_error: 2.1840 - val_loss: 14.3712 - val_root_mean_squared_error: 3.7909\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6138 - root_mean_squared_error: 2.1480 - val_loss: 15.3099 - val_root_mean_squared_error: 3.9128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2463 - root_mean_squared_error: 2.2905 - val_loss: 13.2017 - val_root_mean_squared_error: 3.6334\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.9862 - root_mean_squared_error: 2.4467 - val_loss: 11.1143 - val_root_mean_squared_error: 3.3338\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0791 - root_mean_squared_error: 2.2537 - val_loss: 13.3829 - val_root_mean_squared_error: 3.6583\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.2521 - root_mean_squared_error: 2.2917 - val_loss: 18.4550 - val_root_mean_squared_error: 4.2959\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8450 - root_mean_squared_error: 2.2011 - val_loss: 13.2562 - val_root_mean_squared_error: 3.6409\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6578 - root_mean_squared_error: 2.1582 - val_loss: 12.9138 - val_root_mean_squared_error: 3.5936\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.7879 - root_mean_squared_error: 2.1881 - val_loss: 13.6185 - val_root_mean_squared_error: 3.6903\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.6436 - root_mean_squared_error: 2.1549 - val_loss: 15.1776 - val_root_mean_squared_error: 3.8958\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8933 - root_mean_squared_error: 2.2121 - val_loss: 16.4657 - val_root_mean_squared_error: 4.0578\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.9519 - root_mean_squared_error: 2.2253 - val_loss: 16.5515 - val_root_mean_squared_error: 4.0684\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 5.0270 - root_mean_squared_error: 2.2421 - val_loss: 12.8914 - val_root_mean_squared_error: 3.5905\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 4.8157 - root_mean_squared_error: 2.1945 - val_loss: 15.4884 - val_root_mean_squared_error: 3.9355\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.4884 - root_mean_squared_error: 3.9355\n",
      "Root Mean Squared Error on Test Data: 3.94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "df = pd.read_csv('Potato.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train a simple feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', input_dim=len(features)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Use RootMeanSquaredError as a custom metric\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test)\n",
    "rmse_value = results[1]\n",
    "\n",
    "print(f\"Root Mean Squared Error on Test Data: {rmse_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c172f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\974696609.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 12ms/step - loss: 1.4976 - root_mean_squared_error: 1.2237 - val_loss: 0.6054 - val_root_mean_squared_error: 0.7781\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.5860 - root_mean_squared_error: 0.7655 - val_loss: 0.6007 - val_root_mean_squared_error: 0.7750\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.5391 - root_mean_squared_error: 0.7342 - val_loss: 0.5125 - val_root_mean_squared_error: 0.7159\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.5270 - root_mean_squared_error: 0.7259 - val_loss: 0.5050 - val_root_mean_squared_error: 0.7107\n",
      "Epoch 5/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4812 - root_mean_squared_error: 0.6937 - val_loss: 0.4589 - val_root_mean_squared_error: 0.6774\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4641 - root_mean_squared_error: 0.6812 - val_loss: 0.4622 - val_root_mean_squared_error: 0.6799\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4645 - root_mean_squared_error: 0.6816 - val_loss: 0.5147 - val_root_mean_squared_error: 0.7174\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4342 - val_root_mean_squared_error: 0.6589\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4519 - root_mean_squared_error: 0.6722 - val_loss: 0.4443 - val_root_mean_squared_error: 0.6665\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4540 - root_mean_squared_error: 0.6738 - val_loss: 0.4298 - val_root_mean_squared_error: 0.6556\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4261 - root_mean_squared_error: 0.6527 - val_loss: 0.4346 - val_root_mean_squared_error: 0.6593\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.4201 - root_mean_squared_error: 0.6481 - val_loss: 0.4143 - val_root_mean_squared_error: 0.6437\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.4010 - root_mean_squared_error: 0.6332 - val_loss: 0.4240 - val_root_mean_squared_error: 0.6512\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3961 - root_mean_squared_error: 0.6294 - val_loss: 0.4552 - val_root_mean_squared_error: 0.6747\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3942 - root_mean_squared_error: 0.6279 - val_loss: 0.4640 - val_root_mean_squared_error: 0.6812\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3942 - root_mean_squared_error: 0.6278 - val_loss: 0.4126 - val_root_mean_squared_error: 0.6423\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3812 - root_mean_squared_error: 0.6174 - val_loss: 0.4378 - val_root_mean_squared_error: 0.6617\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.3917 - root_mean_squared_error: 0.6258 - val_loss: 0.3965 - val_root_mean_squared_error: 0.6297\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3530 - root_mean_squared_error: 0.5941 - val_loss: 0.4328 - val_root_mean_squared_error: 0.6578\n",
      "Epoch 20/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3562 - root_mean_squared_error: 0.5969 - val_loss: 0.3973 - val_root_mean_squared_error: 0.6303\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3582 - root_mean_squared_error: 0.5985 - val_loss: 0.3888 - val_root_mean_squared_error: 0.6235\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3622 - root_mean_squared_error: 0.6019 - val_loss: 0.3541 - val_root_mean_squared_error: 0.5951\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3371 - root_mean_squared_error: 0.5806 - val_loss: 0.3897 - val_root_mean_squared_error: 0.6242\n",
      "Epoch 24/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3502 - root_mean_squared_error: 0.5918 - val_loss: 0.3630 - val_root_mean_squared_error: 0.6025\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3377 - root_mean_squared_error: 0.5811 - val_loss: 0.3635 - val_root_mean_squared_error: 0.6029\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3208 - root_mean_squared_error: 0.5664 - val_loss: 0.3692 - val_root_mean_squared_error: 0.6076\n",
      "Epoch 27/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.3280 - root_mean_squared_error: 0.5727 - val_loss: 0.3948 - val_root_mean_squared_error: 0.6284\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3221 - root_mean_squared_error: 0.5676 - val_loss: 0.4571 - val_root_mean_squared_error: 0.6761\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3476 - root_mean_squared_error: 0.5896 - val_loss: 0.3769 - val_root_mean_squared_error: 0.6140\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2961 - root_mean_squared_error: 0.5442 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5858\n",
      "Epoch 31/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2967 - root_mean_squared_error: 0.5447 - val_loss: 0.4515 - val_root_mean_squared_error: 0.6720\n",
      "Epoch 32/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.3193 - root_mean_squared_error: 0.5651 - val_loss: 0.3735 - val_root_mean_squared_error: 0.6111\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2919 - root_mean_squared_error: 0.5402 - val_loss: 0.3676 - val_root_mean_squared_error: 0.6063\n",
      "Epoch 34/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.2886 - root_mean_squared_error: 0.5372 - val_loss: 0.3476 - val_root_mean_squared_error: 0.5896\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2963 - root_mean_squared_error: 0.5443 - val_loss: 0.3473 - val_root_mean_squared_error: 0.5893\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2912 - root_mean_squared_error: 0.5396 - val_loss: 0.3869 - val_root_mean_squared_error: 0.6220\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2769 - root_mean_squared_error: 0.5262 - val_loss: 0.3861 - val_root_mean_squared_error: 0.6214\n",
      "Epoch 38/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.2823 - root_mean_squared_error: 0.5313 - val_loss: 0.3561 - val_root_mean_squared_error: 0.5967\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2648 - root_mean_squared_error: 0.5146 - val_loss: 0.3243 - val_root_mean_squared_error: 0.5695\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2600 - root_mean_squared_error: 0.5099 - val_loss: 0.3376 - val_root_mean_squared_error: 0.5811\n",
      "Epoch 41/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2607 - root_mean_squared_error: 0.5106 - val_loss: 0.4140 - val_root_mean_squared_error: 0.6435\n",
      "Epoch 42/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2686 - root_mean_squared_error: 0.5183 - val_loss: 0.3546 - val_root_mean_squared_error: 0.5955\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2669 - root_mean_squared_error: 0.5166 - val_loss: 0.3612 - val_root_mean_squared_error: 0.6010\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2895 - root_mean_squared_error: 0.5381 - val_loss: 0.3170 - val_root_mean_squared_error: 0.5631\n",
      "Epoch 45/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2533 - root_mean_squared_error: 0.5033 - val_loss: 0.3389 - val_root_mean_squared_error: 0.5821\n",
      "Epoch 46/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2509 - root_mean_squared_error: 0.5009 - val_loss: 0.3538 - val_root_mean_squared_error: 0.5948\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2421 - root_mean_squared_error: 0.4920 - val_loss: 0.3119 - val_root_mean_squared_error: 0.5585\n",
      "Epoch 48/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.2369 - root_mean_squared_error: 0.4867 - val_loss: 0.4236 - val_root_mean_squared_error: 0.6509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2413 - root_mean_squared_error: 0.4913 - val_loss: 0.3779 - val_root_mean_squared_error: 0.6148\n",
      "Epoch 50/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2291 - root_mean_squared_error: 0.4787 - val_loss: 0.3687 - val_root_mean_squared_error: 0.6072\n",
      "Epoch 51/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2295 - root_mean_squared_error: 0.4790 - val_loss: 0.3988 - val_root_mean_squared_error: 0.6315\n",
      "Epoch 52/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2697 - root_mean_squared_error: 0.5193 - val_loss: 0.3459 - val_root_mean_squared_error: 0.5881\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2563 - root_mean_squared_error: 0.5062 - val_loss: 0.4903 - val_root_mean_squared_error: 0.7002\n",
      "Epoch 54/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2479 - root_mean_squared_error: 0.4979 - val_loss: 0.4889 - val_root_mean_squared_error: 0.6992\n",
      "Epoch 55/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2402 - root_mean_squared_error: 0.4901 - val_loss: 0.3283 - val_root_mean_squared_error: 0.5730\n",
      "Epoch 56/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2105 - root_mean_squared_error: 0.4588 - val_loss: 0.3777 - val_root_mean_squared_error: 0.6146\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2438 - root_mean_squared_error: 0.4938 - val_loss: 0.3644 - val_root_mean_squared_error: 0.6036\n",
      "Epoch 58/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2256 - root_mean_squared_error: 0.4750 - val_loss: 0.3142 - val_root_mean_squared_error: 0.5606\n",
      "Epoch 59/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2029 - root_mean_squared_error: 0.4505 - val_loss: 0.3936 - val_root_mean_squared_error: 0.6274\n",
      "Epoch 60/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.2141 - root_mean_squared_error: 0.4627 - val_loss: 0.3663 - val_root_mean_squared_error: 0.6052\n",
      "Epoch 61/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2008 - root_mean_squared_error: 0.4481 - val_loss: 0.3267 - val_root_mean_squared_error: 0.5716\n",
      "Epoch 62/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2081 - root_mean_squared_error: 0.4562 - val_loss: 0.3918 - val_root_mean_squared_error: 0.6259\n",
      "Epoch 63/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1883 - root_mean_squared_error: 0.4339 - val_loss: 0.3516 - val_root_mean_squared_error: 0.5929\n",
      "Epoch 64/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1979 - root_mean_squared_error: 0.4449 - val_loss: 0.3658 - val_root_mean_squared_error: 0.6048\n",
      "Epoch 65/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1860 - root_mean_squared_error: 0.4313 - val_loss: 0.3489 - val_root_mean_squared_error: 0.5907\n",
      "Epoch 66/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1534 - root_mean_squared_error: 0.3916 - val_loss: 0.3913 - val_root_mean_squared_error: 0.6256\n",
      "Epoch 67/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1798 - root_mean_squared_error: 0.4240 - val_loss: 0.3365 - val_root_mean_squared_error: 0.5801\n",
      "Epoch 68/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1709 - root_mean_squared_error: 0.4134 - val_loss: 0.3474 - val_root_mean_squared_error: 0.5894\n",
      "Epoch 69/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1854 - root_mean_squared_error: 0.4306 - val_loss: 0.3666 - val_root_mean_squared_error: 0.6055\n",
      "Epoch 70/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1855 - root_mean_squared_error: 0.4307 - val_loss: 0.3018 - val_root_mean_squared_error: 0.5494\n",
      "Epoch 71/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1658 - root_mean_squared_error: 0.4072 - val_loss: 0.3508 - val_root_mean_squared_error: 0.5923\n",
      "Epoch 72/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1630 - root_mean_squared_error: 0.4038 - val_loss: 0.3854 - val_root_mean_squared_error: 0.6208\n",
      "Epoch 73/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1744 - root_mean_squared_error: 0.4176 - val_loss: 0.3806 - val_root_mean_squared_error: 0.6169\n",
      "Epoch 74/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1612 - root_mean_squared_error: 0.4015 - val_loss: 0.3420 - val_root_mean_squared_error: 0.5848\n",
      "Epoch 75/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1780 - root_mean_squared_error: 0.4219 - val_loss: 0.3163 - val_root_mean_squared_error: 0.5624\n",
      "Epoch 76/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1628 - root_mean_squared_error: 0.4034 - val_loss: 0.4290 - val_root_mean_squared_error: 0.6550\n",
      "Epoch 77/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1447 - root_mean_squared_error: 0.3804 - val_loss: 0.3769 - val_root_mean_squared_error: 0.6139\n",
      "Epoch 78/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.1624 - root_mean_squared_error: 0.4030 - val_loss: 0.3299 - val_root_mean_squared_error: 0.5743\n",
      "Epoch 79/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1484 - root_mean_squared_error: 0.3852 - val_loss: 0.3259 - val_root_mean_squared_error: 0.5709\n",
      "Epoch 80/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1623 - root_mean_squared_error: 0.4029 - val_loss: 0.2995 - val_root_mean_squared_error: 0.5473\n",
      "Epoch 81/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1519 - root_mean_squared_error: 0.3897 - val_loss: 0.3614 - val_root_mean_squared_error: 0.6011\n",
      "Epoch 82/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1504 - root_mean_squared_error: 0.3878 - val_loss: 0.3402 - val_root_mean_squared_error: 0.5833\n",
      "Epoch 83/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1411 - root_mean_squared_error: 0.3756 - val_loss: 0.3166 - val_root_mean_squared_error: 0.5627\n",
      "Epoch 84/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1419 - root_mean_squared_error: 0.3768 - val_loss: 0.3329 - val_root_mean_squared_error: 0.5770\n",
      "Epoch 85/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1348 - root_mean_squared_error: 0.3672 - val_loss: 0.3689 - val_root_mean_squared_error: 0.6073\n",
      "Epoch 86/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1244 - root_mean_squared_error: 0.3527 - val_loss: 0.3303 - val_root_mean_squared_error: 0.5747\n",
      "Epoch 87/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1247 - root_mean_squared_error: 0.3531 - val_loss: 0.3562 - val_root_mean_squared_error: 0.5969\n",
      "Epoch 88/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1358 - root_mean_squared_error: 0.3685 - val_loss: 0.4077 - val_root_mean_squared_error: 0.6385\n",
      "Epoch 89/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1328 - root_mean_squared_error: 0.3644 - val_loss: 0.3852 - val_root_mean_squared_error: 0.6207\n",
      "Epoch 90/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1256 - root_mean_squared_error: 0.3544 - val_loss: 0.3422 - val_root_mean_squared_error: 0.5850\n",
      "Epoch 91/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.1204 - root_mean_squared_error: 0.3470 - val_loss: 0.3812 - val_root_mean_squared_error: 0.6175\n",
      "Epoch 92/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1344 - root_mean_squared_error: 0.3666 - val_loss: 0.3667 - val_root_mean_squared_error: 0.6055\n",
      "Epoch 93/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1297 - root_mean_squared_error: 0.3602 - val_loss: 0.3573 - val_root_mean_squared_error: 0.5977\n",
      "Epoch 94/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1123 - root_mean_squared_error: 0.3351 - val_loss: 0.3138 - val_root_mean_squared_error: 0.5602\n",
      "Epoch 95/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1582 - root_mean_squared_error: 0.3977 - val_loss: 0.4849 - val_root_mean_squared_error: 0.6963\n",
      "Epoch 96/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1606 - root_mean_squared_error: 0.4007 - val_loss: 0.3194 - val_root_mean_squared_error: 0.5651\n",
      "Epoch 97/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1293 - root_mean_squared_error: 0.3596 - val_loss: 0.3766 - val_root_mean_squared_error: 0.6137\n",
      "Epoch 98/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1365 - root_mean_squared_error: 0.3694 - val_loss: 0.4264 - val_root_mean_squared_error: 0.6530\n",
      "Epoch 99/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1268 - root_mean_squared_error: 0.3561 - val_loss: 0.3518 - val_root_mean_squared_error: 0.5931\n",
      "Epoch 100/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1185 - root_mean_squared_error: 0.3443 - val_loss: 0.3749 - val_root_mean_squared_error: 0.6123\n",
      "Epoch 101/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1120 - root_mean_squared_error: 0.3347 - val_loss: 0.3385 - val_root_mean_squared_error: 0.5818\n",
      "Epoch 102/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1097 - root_mean_squared_error: 0.3312 - val_loss: 0.3919 - val_root_mean_squared_error: 0.6260\n",
      "Epoch 103/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1167 - root_mean_squared_error: 0.3416 - val_loss: 0.3723 - val_root_mean_squared_error: 0.6102\n",
      "Epoch 104/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1230 - root_mean_squared_error: 0.3507 - val_loss: 0.3697 - val_root_mean_squared_error: 0.6080\n",
      "Epoch 105/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1090 - root_mean_squared_error: 0.3302 - val_loss: 0.3659 - val_root_mean_squared_error: 0.6049\n",
      "Epoch 106/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1066 - root_mean_squared_error: 0.3265 - val_loss: 0.3396 - val_root_mean_squared_error: 0.5828\n",
      "Epoch 107/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1089 - root_mean_squared_error: 0.3300 - val_loss: 0.3365 - val_root_mean_squared_error: 0.5801\n",
      "Epoch 108/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1090 - root_mean_squared_error: 0.3301 - val_loss: 0.3734 - val_root_mean_squared_error: 0.6110\n",
      "Epoch 109/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1072 - root_mean_squared_error: 0.3273 - val_loss: 0.3330 - val_root_mean_squared_error: 0.5770\n",
      "Epoch 110/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.0977 - root_mean_squared_error: 0.3126 - val_loss: 0.3467 - val_root_mean_squared_error: 0.5888\n",
      "Epoch 111/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1108 - root_mean_squared_error: 0.3329 - val_loss: 0.4641 - val_root_mean_squared_error: 0.6813\n",
      "Epoch 112/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1373 - root_mean_squared_error: 0.3706 - val_loss: 0.3294 - val_root_mean_squared_error: 0.5739\n",
      "Epoch 113/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1106 - root_mean_squared_error: 0.3326 - val_loss: 0.3243 - val_root_mean_squared_error: 0.5695\n",
      "Epoch 114/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1271 - root_mean_squared_error: 0.3565 - val_loss: 0.2887 - val_root_mean_squared_error: 0.5373\n",
      "Epoch 115/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1285 - root_mean_squared_error: 0.3584 - val_loss: 0.3782 - val_root_mean_squared_error: 0.6150\n",
      "Epoch 116/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1111 - root_mean_squared_error: 0.3333 - val_loss: 0.3722 - val_root_mean_squared_error: 0.6101\n",
      "Epoch 117/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0935 - root_mean_squared_error: 0.3058 - val_loss: 0.3235 - val_root_mean_squared_error: 0.5687\n",
      "Epoch 118/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0953 - root_mean_squared_error: 0.3088 - val_loss: 0.3172 - val_root_mean_squared_error: 0.5632\n",
      "Epoch 119/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1015 - root_mean_squared_error: 0.3185 - val_loss: 0.3731 - val_root_mean_squared_error: 0.6108\n",
      "Epoch 120/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.1079 - root_mean_squared_error: 0.3285 - val_loss: 0.3273 - val_root_mean_squared_error: 0.5721\n",
      "Epoch 121/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0997 - root_mean_squared_error: 0.3158 - val_loss: 0.3331 - val_root_mean_squared_error: 0.5772\n",
      "Epoch 122/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0883 - root_mean_squared_error: 0.2971 - val_loss: 0.3521 - val_root_mean_squared_error: 0.5934\n",
      "Epoch 123/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0929 - root_mean_squared_error: 0.3047 - val_loss: 0.3094 - val_root_mean_squared_error: 0.5562\n",
      "Epoch 124/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0873 - root_mean_squared_error: 0.2954 - val_loss: 0.4547 - val_root_mean_squared_error: 0.6743\n",
      "Epoch 125/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1082 - root_mean_squared_error: 0.3289 - val_loss: 0.3510 - val_root_mean_squared_error: 0.5925\n",
      "Epoch 126/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0994 - root_mean_squared_error: 0.3153 - val_loss: 0.3367 - val_root_mean_squared_error: 0.5803\n",
      "Epoch 127/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0970 - root_mean_squared_error: 0.3114 - val_loss: 0.3475 - val_root_mean_squared_error: 0.5895\n",
      "Epoch 128/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0975 - root_mean_squared_error: 0.3122 - val_loss: 0.3950 - val_root_mean_squared_error: 0.6285\n",
      "Epoch 129/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0949 - root_mean_squared_error: 0.3080 - val_loss: 0.3278 - val_root_mean_squared_error: 0.5725\n",
      "Epoch 130/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0940 - root_mean_squared_error: 0.3066 - val_loss: 0.2962 - val_root_mean_squared_error: 0.5442\n",
      "Epoch 131/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0932 - root_mean_squared_error: 0.3053 - val_loss: 0.3018 - val_root_mean_squared_error: 0.5494\n",
      "Epoch 132/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0907 - root_mean_squared_error: 0.3012 - val_loss: 0.3854 - val_root_mean_squared_error: 0.6208\n",
      "Epoch 133/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0961 - root_mean_squared_error: 0.3099 - val_loss: 0.4260 - val_root_mean_squared_error: 0.6527\n",
      "Epoch 134/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0832 - root_mean_squared_error: 0.2884 - val_loss: 0.3565 - val_root_mean_squared_error: 0.5971\n",
      "Epoch 135/200\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0815 - root_mean_squared_error: 0.2856 - val_loss: 0.3410 - val_root_mean_squared_error: 0.5839\n",
      "Epoch 136/200\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0845 - root_mean_squared_error: 0.2907 - val_loss: 0.3194 - val_root_mean_squared_error: 0.5652\n",
      "Epoch 137/200\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0972 - root_mean_squared_error: 0.3118 - val_loss: 0.3991 - val_root_mean_squared_error: 0.6317\n",
      "Epoch 138/200\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0787 - root_mean_squared_error: 0.2805 - val_loss: 0.4080 - val_root_mean_squared_error: 0.6387\n",
      "Epoch 139/200\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1112 - root_mean_squared_error: 0.3335 - val_loss: 0.3096 - val_root_mean_squared_error: 0.5564\n",
      "Epoch 140/200\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1179 - root_mean_squared_error: 0.3434 - val_loss: 0.4016 - val_root_mean_squared_error: 0.6337\n",
      "Epoch 141/200\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1163 - root_mean_squared_error: 0.3411 - val_loss: 0.3298 - val_root_mean_squared_error: 0.5743\n",
      "Epoch 142/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0961 - root_mean_squared_error: 0.3100 - val_loss: 0.2959 - val_root_mean_squared_error: 0.5440\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0796 - root_mean_squared_error: 0.2822 - val_loss: 0.3487 - val_root_mean_squared_error: 0.5905\n",
      "Epoch 144/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0953 - root_mean_squared_error: 0.3088 - val_loss: 0.2999 - val_root_mean_squared_error: 0.5476\n",
      "Epoch 145/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0845 - root_mean_squared_error: 0.2906 - val_loss: 0.3711 - val_root_mean_squared_error: 0.6092\n",
      "Epoch 146/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0776 - root_mean_squared_error: 0.2785 - val_loss: 0.3151 - val_root_mean_squared_error: 0.5613\n",
      "Epoch 147/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0795 - root_mean_squared_error: 0.2819 - val_loss: 0.3368 - val_root_mean_squared_error: 0.5804\n",
      "Epoch 148/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1042 - root_mean_squared_error: 0.3228 - val_loss: 0.3010 - val_root_mean_squared_error: 0.5487\n",
      "Epoch 149/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0865 - root_mean_squared_error: 0.2941 - val_loss: 0.2896 - val_root_mean_squared_error: 0.5382\n",
      "Epoch 150/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0888 - root_mean_squared_error: 0.2979 - val_loss: 0.3520 - val_root_mean_squared_error: 0.5933\n",
      "Epoch 151/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1021 - root_mean_squared_error: 0.3195 - val_loss: 0.2899 - val_root_mean_squared_error: 0.5384\n",
      "Epoch 152/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1028 - root_mean_squared_error: 0.3206 - val_loss: 0.3221 - val_root_mean_squared_error: 0.5676\n",
      "Epoch 153/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0844 - root_mean_squared_error: 0.2905 - val_loss: 0.3536 - val_root_mean_squared_error: 0.5947\n",
      "Epoch 154/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0714 - root_mean_squared_error: 0.2672 - val_loss: 0.3250 - val_root_mean_squared_error: 0.5701\n",
      "Epoch 155/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0737 - root_mean_squared_error: 0.2714 - val_loss: 0.3339 - val_root_mean_squared_error: 0.5779\n",
      "Epoch 156/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0789 - root_mean_squared_error: 0.2808 - val_loss: 0.4091 - val_root_mean_squared_error: 0.6396\n",
      "Epoch 157/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0668 - root_mean_squared_error: 0.2584 - val_loss: 0.3078 - val_root_mean_squared_error: 0.5548\n",
      "Epoch 158/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0653 - root_mean_squared_error: 0.2556 - val_loss: 0.3617 - val_root_mean_squared_error: 0.6014\n",
      "Epoch 159/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650 - val_loss: 0.3743 - val_root_mean_squared_error: 0.6118\n",
      "Epoch 160/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0709 - root_mean_squared_error: 0.2663 - val_loss: 0.2766 - val_root_mean_squared_error: 0.5260\n",
      "Epoch 161/200\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.0765 - root_mean_squared_error: 0.2765 - val_loss: 0.3267 - val_root_mean_squared_error: 0.5716\n",
      "Epoch 162/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0823 - root_mean_squared_error: 0.2869 - val_loss: 0.3111 - val_root_mean_squared_error: 0.5577\n",
      "Epoch 163/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0949 - root_mean_squared_error: 0.3080 - val_loss: 0.2562 - val_root_mean_squared_error: 0.5061\n",
      "Epoch 164/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1337 - root_mean_squared_error: 0.3657 - val_loss: 0.2625 - val_root_mean_squared_error: 0.5123\n",
      "Epoch 165/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1096 - root_mean_squared_error: 0.3310 - val_loss: 0.3140 - val_root_mean_squared_error: 0.5604\n",
      "Epoch 166/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0925 - root_mean_squared_error: 0.3042 - val_loss: 0.3015 - val_root_mean_squared_error: 0.5491\n",
      "Epoch 167/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0859 - root_mean_squared_error: 0.2931 - val_loss: 0.3002 - val_root_mean_squared_error: 0.5479\n",
      "Epoch 168/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1296 - root_mean_squared_error: 0.3600 - val_loss: 0.2429 - val_root_mean_squared_error: 0.4928\n",
      "Epoch 169/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0886 - root_mean_squared_error: 0.2977 - val_loss: 0.2439 - val_root_mean_squared_error: 0.4939\n",
      "Epoch 170/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0745 - root_mean_squared_error: 0.2729 - val_loss: 0.2734 - val_root_mean_squared_error: 0.5229\n",
      "Epoch 171/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0730 - root_mean_squared_error: 0.2702 - val_loss: 0.2582 - val_root_mean_squared_error: 0.5082\n",
      "Epoch 172/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0679 - root_mean_squared_error: 0.2605 - val_loss: 0.2733 - val_root_mean_squared_error: 0.5227\n",
      "Epoch 173/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0780 - root_mean_squared_error: 0.2793 - val_loss: 0.3357 - val_root_mean_squared_error: 0.5794\n",
      "Epoch 174/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0682 - root_mean_squared_error: 0.2612 - val_loss: 0.3086 - val_root_mean_squared_error: 0.5555\n",
      "Epoch 175/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0610 - root_mean_squared_error: 0.2469 - val_loss: 0.2986 - val_root_mean_squared_error: 0.5464\n",
      "Epoch 176/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0710 - root_mean_squared_error: 0.2664 - val_loss: 0.3965 - val_root_mean_squared_error: 0.6297\n",
      "Epoch 177/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0756 - root_mean_squared_error: 0.2749 - val_loss: 0.2803 - val_root_mean_squared_error: 0.5295\n",
      "Epoch 178/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0677 - root_mean_squared_error: 0.2601 - val_loss: 0.3766 - val_root_mean_squared_error: 0.6136\n",
      "Epoch 179/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0612 - root_mean_squared_error: 0.2473 - val_loss: 0.3476 - val_root_mean_squared_error: 0.5895\n",
      "Epoch 180/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0628 - root_mean_squared_error: 0.2506 - val_loss: 0.3053 - val_root_mean_squared_error: 0.5526\n",
      "Epoch 181/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0579 - root_mean_squared_error: 0.2407 - val_loss: 0.2912 - val_root_mean_squared_error: 0.5396\n",
      "Epoch 182/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0630 - root_mean_squared_error: 0.2509 - val_loss: 0.3046 - val_root_mean_squared_error: 0.5519\n",
      "Epoch 183/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0662 - root_mean_squared_error: 0.2573 - val_loss: 0.3223 - val_root_mean_squared_error: 0.5678\n",
      "Epoch 184/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0651 - root_mean_squared_error: 0.2552 - val_loss: 0.2986 - val_root_mean_squared_error: 0.5464\n",
      "Epoch 185/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0813 - root_mean_squared_error: 0.2852 - val_loss: 0.3771 - val_root_mean_squared_error: 0.6141\n",
      "Epoch 186/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0691 - root_mean_squared_error: 0.2628 - val_loss: 0.3018 - val_root_mean_squared_error: 0.5494\n",
      "Epoch 187/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0787 - root_mean_squared_error: 0.2805 - val_loss: 0.4767 - val_root_mean_squared_error: 0.6905\n",
      "Epoch 188/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1012 - root_mean_squared_error: 0.3182 - val_loss: 0.2891 - val_root_mean_squared_error: 0.5377\n",
      "Epoch 189/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0722 - root_mean_squared_error: 0.2686 - val_loss: 0.2692 - val_root_mean_squared_error: 0.5188\n",
      "Epoch 190/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0675 - root_mean_squared_error: 0.2599 - val_loss: 0.3295 - val_root_mean_squared_error: 0.5740\n",
      "Epoch 191/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0589 - root_mean_squared_error: 0.2428 - val_loss: 0.3469 - val_root_mean_squared_error: 0.5890\n",
      "Epoch 192/200\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0586 - root_mean_squared_error: 0.2422 - val_loss: 0.3631 - val_root_mean_squared_error: 0.6026\n",
      "Epoch 193/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0700 - root_mean_squared_error: 0.2645 - val_loss: 0.3397 - val_root_mean_squared_error: 0.5829\n",
      "Epoch 194/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0644 - root_mean_squared_error: 0.2537 - val_loss: 0.3653 - val_root_mean_squared_error: 0.6044\n",
      "Epoch 195/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0572 - root_mean_squared_error: 0.2392 - val_loss: 0.3220 - val_root_mean_squared_error: 0.5674\n",
      "Epoch 196/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0588 - root_mean_squared_error: 0.2426 - val_loss: 0.3259 - val_root_mean_squared_error: 0.5709\n",
      "Epoch 197/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0731 - root_mean_squared_error: 0.2704 - val_loss: 0.3240 - val_root_mean_squared_error: 0.5692\n",
      "Epoch 198/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0699 - root_mean_squared_error: 0.2643 - val_loss: 0.2856 - val_root_mean_squared_error: 0.5345\n",
      "Epoch 199/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0971 - root_mean_squared_error: 0.3116 - val_loss: 0.3804 - val_root_mean_squared_error: 0.6168\n",
      "Epoch 200/200\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1079 - root_mean_squared_error: 0.3284 - val_loss: 0.3343 - val_root_mean_squared_error: 0.5782\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782\n",
      "Root Mean Squared Error on Test Data: 0.58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "df = pd.read_csv('rice.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train a simple feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', input_dim=len(features)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Use RootMeanSquaredError as a custom metric\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test)\n",
    "rmse_value = results[1]\n",
    "\n",
    "print(f\"Root Mean Squared Error on Test Data: {rmse_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2bb8f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning \n",
    "# Method 1 (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, \n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.3,random_state=21)\n",
    "def build_model(neurons=(200, 100, 50,25), learning_rate=0.01, activation= ('relu', 'relu', 'relu','relu'),init_mode=('he_uniform', 'he_uniform', 'he_uniform','he_uniform')):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], activation=activation[0], input_dim=len(features),kernel_initializer=init_mode[0]))\n",
    "    model.add(Dense(neurons[1], activation=activation[1],kernel_initializer=init_mode[1]))\n",
    "    model.add(Dense(neurons[2], activation=activation[2],kernel_initializer=init_mode[2]))\n",
    "    model.add(Dense(neurons[3],activation=activation[3],kernel_initializer=init_mode[3]))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error',metrics=[RootMeanSquaredError()])\n",
    "    return model\n",
    "# Wrap Keras model using KerasRegressor\n",
    "keras_model = KerasRegressor(build_fn=build_model, epochs=200, batch_size=16)\n",
    "activation_combinations = [\n",
    "    ('swish', 'gelu', 'relu','relu'),\n",
    "    ('gelu', 'relu', 'swish','gelu'),\n",
    "    ('relu','gelu','swish', 'relu'),\n",
    " ('relu', 'swish', 'gelu','swish'),\n",
    " ('gelu', 'swish', 'gelu','relu')]\n",
    "ini_combinations = [\n",
    "    ('he_uniform', 'he_normal', 'he_uniform','he_normal'),\n",
    "    ('he_normal', 'he_uniform', 'he_normal','he_uniform'),\n",
    "    ('he_normal','he_normal','he_normal', 'he_normal'),\n",
    " ('he_uniform', 'he_uniform', 'he_uniform','he_uniform')]\n",
    "#('gelu', 'swish', 'gelu','relu')]\n",
    "#('swish', 'tanh', 'gelu')]\n",
    "'''('relu', 'sigmoid', 'relu'),\n",
    " ('relu', 'sigmoid', 'tanh'),\n",
    " ('relu', 'sigmoid', 'sigmoid'),\n",
    " ('tanh', 'relu', 'relu'),\n",
    " ('tanh', 'relu', 'tanh'),\n",
    " ('tanh', 'relu', 'sigmoid'),\n",
    " ('tanh', 'tanh', 'relu'),\n",
    " ('tanh', 'tanh', 'tanh'),\n",
    " ('tanh', 'tanh', 'sigmoid'),\n",
    " ('tanh', 'sigmoid', 'relu'),\n",
    " ('tanh', 'sigmoid', 'tanh'),\n",
    " ('tanh', 'sigmoid', 'sigmoid'),\n",
    " ('sigmoid', 'relu', 'relu'),\n",
    " ('sigmoid', 'relu', 'tanh'),\n",
    " ('sigmoid', 'relu', 'sigmoid'),\n",
    " ('sigmoid', 'tanh', 'relu'),\n",
    " ('sigmoid', 'tanh', 'tanh'),\n",
    " ('sigmoid', 'tanh', 'sigmoid'),\n",
    " ('sigmoid', 'sigmoid', 'relu'),\n",
    " ('sigmoid', 'sigmoid', 'tanh'),\n",
    " ('sigmoid', 'sigmoid', 'sigmoid')'''\n",
    "\n",
    "                             \n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'model__neurons': [(200, 100, 50,25), (100, 50, 25,10), (50, 25, 10,5)],\n",
    "    'optimizer__learning_rate': [0.001, 0.01, 0.05],\n",
    "    'model__activation': activation_combinations,\n",
    "    'model__init_mode':ini_combinations,\n",
    "    'batch_size' :[10, 20, 40],\n",
    "    'epochs' :[100, 150, 200,250]\n",
    "}\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, scoring='neg_mean_squared_error',n_jobs=-1,cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "# Calculate RMSE\n",
    "#rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "#print(\"Root Mean Squared Error:\", rmse)\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef031854",
   "metadata": {},
   "source": [
    "# Method 2 (Genetic Algorithm Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e4099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crossover Function \n",
    "def crossover(p1,p2,cp):\n",
    "    for i in range(len(p1)):\n",
    "        r1 = round(np.random.uniform(0,0.5),2)\n",
    "        r2 = round(np.random.uniform(0.5,1),2)\n",
    "        print(r1,r2)\n",
    "        if(cp < r1):\n",
    "            p2[i] = p1[i]\n",
    "        elif(cp > r2):\n",
    "            p1[i] = p2[i]\n",
    "        else: \n",
    "            a = p1[i]\n",
    "            p1[i] = p2[i]\n",
    "            p2[i] = a\n",
    "    return p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "463efad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define initial Population \n",
    "import numpy as np\n",
    "initial_population = np.array([[200, 100,50, 0.001, 'relu','relu','relu'], \n",
    "                               [50,25,10, 0.01, 'relu','gelu','swish'], \n",
    "                               [150, 75,40, 0.1, 'relu','swish','relu'],\n",
    "                              [100,50,25,0.01,'relu','gelu','relu']])\n",
    "a = initial_population[0]\n",
    "b = initial_population[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a979ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\1994857545.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "features = 5\n",
    "df = pd.read_csv('Onion.csv')\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "def create_model(n1, n2, n3, lr, a1, a2, a3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, activation=a1, input_dim=5))\n",
    "    model.add(Dense(n2, activation=a2))\n",
    "    model.add(Dense(n3, activation=a3))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=float(lr)), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def fitness_func(solution):\n",
    "    n1, n2, n3, lr, a1, a2, a3 = solution\n",
    "    model = create_model(n1, n2, n3, lr, a1, a2, a3)\n",
    "    model.fit(X, y, epochs=200, batch_size=8)\n",
    "    results = model.evaluate(X, y)\n",
    "    rmse_value = results[1]\n",
    "    solution_fitness = rmse_value\n",
    "\n",
    "    return solution_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628cf4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 1063.5458 - root_mean_squared_error: 32.6120\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 911.6426 - root_mean_squared_error: 30.1934\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 834.9286 - root_mean_squared_error: 28.8951\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 824.0849 - root_mean_squared_error: 28.7069\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 817.9854 - root_mean_squared_error: 28.6004\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 818.6516 - root_mean_squared_error: 28.6121\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 813.6152 - root_mean_squared_error: 28.5239\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 809.8386 - root_mean_squared_error: 28.4577\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 808.4037 - root_mean_squared_error: 28.4324\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 800.8918 - root_mean_squared_error: 28.3000\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 799.5618 - root_mean_squared_error: 28.2765\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 799.7465 - root_mean_squared_error: 28.2798\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 793.2370 - root_mean_squared_error: 28.1645\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 790.1630 - root_mean_squared_error: 28.1098\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 785.9379 - root_mean_squared_error: 28.0346\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 786.6717 - root_mean_squared_error: 28.0477\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 780.4716 - root_mean_squared_error: 27.9369\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 775.3143 - root_mean_squared_error: 27.8445\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 774.2581 - root_mean_squared_error: 27.8255\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 767.1566 - root_mean_squared_error: 27.6976\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 767.1578 - root_mean_squared_error: 27.6976\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 772.4809 - root_mean_squared_error: 27.7935\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 753.2527 - root_mean_squared_error: 27.4454\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 755.0558 - root_mean_squared_error: 27.4783\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 748.4492 - root_mean_squared_error: 27.3578\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 745.2597 - root_mean_squared_error: 27.2994\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 739.0554 - root_mean_squared_error: 27.1856\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 733.7159 - root_mean_squared_error: 27.0872\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 730.7070 - root_mean_squared_error: 27.0316\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 725.1482 - root_mean_squared_error: 26.9286\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 729.4705 - root_mean_squared_error: 27.0087\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 719.9374 - root_mean_squared_error: 26.8316\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 707.9600 - root_mean_squared_error: 26.6075\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 705.6447 - root_mean_squared_error: 26.5640\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 718.0602 - root_mean_squared_error: 26.7966\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 699.3654 - root_mean_squared_error: 26.4455\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 692.5202 - root_mean_squared_error: 26.3158\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 689.4471 - root_mean_squared_error: 26.2573\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 687.6166 - root_mean_squared_error: 26.2224\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 664.8759 - root_mean_squared_error: 25.7852\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 669.9812 - root_mean_squared_error: 25.8840\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 656.1471 - root_mean_squared_error: 25.6154\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 666.1057 - root_mean_squared_error: 25.8090\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 659.8896 - root_mean_squared_error: 25.6883\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 629.9589 - root_mean_squared_error: 25.0990\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 631.2916 - root_mean_squared_error: 25.1255\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 636.4656 - root_mean_squared_error: 25.2283\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 612.5287 - root_mean_squared_error: 24.7493\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 599.4247 - root_mean_squared_error: 24.4832\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 586.9149 - root_mean_squared_error: 24.2263\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 600.7784 - root_mean_squared_error: 24.5108\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 595.0507 - root_mean_squared_error: 24.3937\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 574.9866 - root_mean_squared_error: 23.9789\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 563.3777 - root_mean_squared_error: 23.7356\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 541.8773 - root_mean_squared_error: 23.2783\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 550.2764 - root_mean_squared_error: 23.4580\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 534.8138 - root_mean_squared_error: 23.1260\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 522.0574 - root_mean_squared_error: 22.8486\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 520.4529 - root_mean_squared_error: 22.8134\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 514.7951 - root_mean_squared_error: 22.6891\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 495.6404 - root_mean_squared_error: 22.2630\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 483.7548 - root_mean_squared_error: 21.9944\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 504.1097 - root_mean_squared_error: 22.4524\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 467.5399 - root_mean_squared_error: 21.6227\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 460.8690 - root_mean_squared_error: 21.4679\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 448.9305 - root_mean_squared_error: 21.1880\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 450.7771 - root_mean_squared_error: 21.2315\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 464.8877 - root_mean_squared_error: 21.5613\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 402.3351 - root_mean_squared_error: 20.0583\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 385.1109 - root_mean_squared_error: 19.6242\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 423.4287 - root_mean_squared_error: 20.5774\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 410.3993 - root_mean_squared_error: 20.2583\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 385.5132 - root_mean_squared_error: 19.6345\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 407.3589 - root_mean_squared_error: 20.1831\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 368.1664 - root_mean_squared_error: 19.1877\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 370.6752 - root_mean_squared_error: 19.2529\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 368.6935 - root_mean_squared_error: 19.2014\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 345.1796 - root_mean_squared_error: 18.5790\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 316.2653 - root_mean_squared_error: 17.7838\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 340.8626 - root_mean_squared_error: 18.4625\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 320.4421 - root_mean_squared_error: 17.9009\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 290.5793 - root_mean_squared_error: 17.0464\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 310.6560 - root_mean_squared_error: 17.6254\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 294.2874 - root_mean_squared_error: 17.1548\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 299.8197 - root_mean_squared_error: 17.3153\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 290.1417 - root_mean_squared_error: 17.0335\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 292.2906 - root_mean_squared_error: 17.0965\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 256.9808 - root_mean_squared_error: 16.0306\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 288.2851 - root_mean_squared_error: 16.9790\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 238.1400 - root_mean_squared_error: 15.4318\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 245.0470 - root_mean_squared_error: 15.6540\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 215.6040 - root_mean_squared_error: 14.6835\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 243.6894 - root_mean_squared_error: 15.6106\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 238.8721 - root_mean_squared_error: 15.4555\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 224.1974 - root_mean_squared_error: 14.9732\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 225.5776 - root_mean_squared_error: 15.0192\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 180.1268 - root_mean_squared_error: 13.4211\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 226.4695 - root_mean_squared_error: 15.0489\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 192.4431 - root_mean_squared_error: 13.8724\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 157.1965 - root_mean_squared_error: 12.5378\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 165.4210 - root_mean_squared_error: 12.8616\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 178.9770 - root_mean_squared_error: 13.3782\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 173.0042 - root_mean_squared_error: 13.1531\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 165.6634 - root_mean_squared_error: 12.8710\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 157.3610 - root_mean_squared_error: 12.5444\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 122.5607 - root_mean_squared_error: 11.0707\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 124.2296 - root_mean_squared_error: 11.1458\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 138.0550 - root_mean_squared_error: 11.7497\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 110.4057 - root_mean_squared_error: 10.5074\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 118.8394 - root_mean_squared_error: 10.9014\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 118.1952 - root_mean_squared_error: 10.8718\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 124.7449 - root_mean_squared_error: 11.1689\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 121.2773 - root_mean_squared_error: 11.0126\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 133.7898 - root_mean_squared_error: 11.5668\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 87.8400 - root_mean_squared_error: 9.3723\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 73.2541 - root_mean_squared_error: 8.5589\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 70.4756 - root_mean_squared_error: 8.3950\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 91.3072 - root_mean_squared_error: 9.5555\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 68.7984 - root_mean_squared_error: 8.2945\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 70.3076 - root_mean_squared_error: 8.3850\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 69.0879 - root_mean_squared_error: 8.3119\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 61.4966 - root_mean_squared_error: 7.8420\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 61.7825 - root_mean_squared_error: 7.8602\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 66.5251 - root_mean_squared_error: 8.1563\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 48.1790 - root_mean_squared_error: 6.9411\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 50.5612 - root_mean_squared_error: 7.1106\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 59.7477 - root_mean_squared_error: 7.7297\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 80.6560 - root_mean_squared_error: 8.9809\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 77.6364 - root_mean_squared_error: 8.8112\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 40.5153 - root_mean_squared_error: 6.3652\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 37.0253 - root_mean_squared_error: 6.0848\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 48.4940 - root_mean_squared_error: 6.9638\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 46.5741 - root_mean_squared_error: 6.8245\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 79.9809 - root_mean_squared_error: 8.9432\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 56.9975 - root_mean_squared_error: 7.5497\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.6813 - root_mean_squared_error: 5.7168\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.2754 - root_mean_squared_error: 5.3175\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 25.8004 - root_mean_squared_error: 5.0794\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9772 - root_mean_squared_error: 5.2893\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.8539 - root_mean_squared_error: 4.9854\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.1660 - root_mean_squared_error: 5.0166\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 23.9767 - root_mean_squared_error: 4.8966\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7140 - root_mean_squared_error: 4.9713\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.8765 - root_mean_squared_error: 5.2798\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.4610 - root_mean_squared_error: 5.5191\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.1888 - root_mean_squared_error: 5.5847\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 24.4636 - root_mean_squared_error: 4.9461\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 23.0805 - root_mean_squared_error: 4.8042\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 22.6317 - root_mean_squared_error: 4.7573\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.9001 - root_mean_squared_error: 4.7854\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.4256 - root_mean_squared_error: 5.0424\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.0093 - root_mean_squared_error: 5.4781\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 29.8129 - root_mean_squared_error: 5.4601\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 46.7247 - root_mean_squared_error: 6.8355\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 56.2011 - root_mean_squared_error: 7.4967\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 52.8595 - root_mean_squared_error: 7.2705\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 57.0417 - root_mean_squared_error: 7.5526\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 90.8319 - root_mean_squared_error: 9.5306\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 70.0604 - root_mean_squared_error: 8.3702\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 79.9260 - root_mean_squared_error: 8.9401\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 31.0370 - root_mean_squared_error: 5.5711\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.2411 - root_mean_squared_error: 4.7160\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7170 - root_mean_squared_error: 4.5516\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.0543 - root_mean_squared_error: 4.5885\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 19.6866 - root_mean_squared_error: 4.4370\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.2508 - root_mean_squared_error: 4.5001\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.9146 - root_mean_squared_error: 4.5732\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.5221 - root_mean_squared_error: 4.5301\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6671 - root_mean_squared_error: 4.5461\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 21.3518 - root_mean_squared_error: 4.6208\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 19.8309 - root_mean_squared_error: 4.4532\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7079 - root_mean_squared_error: 4.5506\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 21.4218 - root_mean_squared_error: 4.6284\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.0300 - root_mean_squared_error: 4.4755\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 20.7063 - root_mean_squared_error: 4.5504\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 20.6498 - root_mean_squared_error: 4.5442\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 22.6154 - root_mean_squared_error: 4.7556\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 26.3038 - root_mean_squared_error: 5.1287\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 30.0623 - root_mean_squared_error: 5.4829\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 33.2556 - root_mean_squared_error: 5.7668\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 41.9069 - root_mean_squared_error: 6.4736\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 40.1585 - root_mean_squared_error: 6.3371\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 66.0993 - root_mean_squared_error: 8.1301\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 87.4763 - root_mean_squared_error: 9.3529\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 341.6303 - root_mean_squared_error: 18.4832\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 212.2410 - root_mean_squared_error: 14.5685\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 89.7142 - root_mean_squared_error: 9.4718\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 112.0554 - root_mean_squared_error: 10.5856\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 202.5059 - root_mean_squared_error: 14.2305\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 184.7394 - root_mean_squared_error: 13.5919\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 117.1037 - root_mean_squared_error: 10.8214\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 106.9871 - root_mean_squared_error: 10.3435\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 103.3933 - root_mean_squared_error: 10.1682\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 102.8401 - root_mean_squared_error: 10.1410\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 98.0126 - root_mean_squared_error: 9.9001\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 83.3664 - root_mean_squared_error: 9.1305\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 56.3728 - root_mean_squared_error: 7.5082\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 37.5129 - root_mean_squared_error: 6.1248\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.5158 - root_mean_squared_error: 5.2456\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 23.4846 - root_mean_squared_error: 4.8461\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.5257 - root_mean_squared_error: 4.6396\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 2s 9ms/step - loss: 917.3555 - root_mean_squared_error: 30.2879\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 841.5007 - root_mean_squared_error: 29.0086\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 824.4735 - root_mean_squared_error: 28.7136\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 812.4920 - root_mean_squared_error: 28.5042\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 826.3769 - root_mean_squared_error: 28.7468\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 812.7056 - root_mean_squared_error: 28.5080\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 818.8846 - root_mean_squared_error: 28.6162\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 822.6052 - root_mean_squared_error: 28.6811\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 813.7237 - root_mean_squared_error: 28.5258\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 801.9540 - root_mean_squared_error: 28.3188\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 789.2625 - root_mean_squared_error: 28.0938\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 791.6995 - root_mean_squared_error: 28.1372\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 791.6171 - root_mean_squared_error: 28.1357\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 784.0068 - root_mean_squared_error: 28.0001\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 793.0492 - root_mean_squared_error: 28.1611\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 768.2034 - root_mean_squared_error: 27.7165\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 781.9536 - root_mean_squared_error: 27.9634\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 755.9549 - root_mean_squared_error: 27.4946\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 735.9528 - root_mean_squared_error: 27.1284\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 728.0811 - root_mean_squared_error: 26.9830\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 744.3186 - root_mean_squared_error: 27.2822\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 699.0380 - root_mean_squared_error: 26.4393\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 700.7676 - root_mean_squared_error: 26.4720\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 670.9691 - root_mean_squared_error: 25.9031\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 663.1325 - root_mean_squared_error: 25.7514\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 674.0739 - root_mean_squared_error: 25.9629\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 658.8889 - root_mean_squared_error: 25.6688\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 611.1174 - root_mean_squared_error: 24.7208\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 612.0269 - root_mean_squared_error: 24.7392\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 565.4207 - root_mean_squared_error: 23.7786\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 585.4865 - root_mean_squared_error: 24.1968\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 505.1072 - root_mean_squared_error: 22.4746\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 522.0693 - root_mean_squared_error: 22.8488\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 574.4814 - root_mean_squared_error: 23.9683\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 523.8362 - root_mean_squared_error: 22.8875\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 465.3138 - root_mean_squared_error: 21.5711\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 560.6963 - root_mean_squared_error: 23.6790\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 403.7351 - root_mean_squared_error: 20.0932\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 375.1785 - root_mean_squared_error: 19.3695\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 389.3843 - root_mean_squared_error: 19.7328\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 548.2709 - root_mean_squared_error: 23.4152\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 361.9928 - root_mean_squared_error: 19.0261\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 303.8470 - root_mean_squared_error: 17.4312\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 280.8203 - root_mean_squared_error: 16.7577\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 706.5620 - root_mean_squared_error: 26.5812\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 548.7160 - root_mean_squared_error: 23.4247\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 356.8072 - root_mean_squared_error: 18.8893\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 305.5998 - root_mean_squared_error: 17.4814\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 305.7072 - root_mean_squared_error: 17.4845\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 264.3879 - root_mean_squared_error: 16.2600\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 267.7031 - root_mean_squared_error: 16.3616\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 278.9894 - root_mean_squared_error: 16.7030\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 371.4077 - root_mean_squared_error: 19.2719\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 202.9617 - root_mean_squared_error: 14.2465\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 210.6529 - root_mean_squared_error: 14.5139\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 322.6469 - root_mean_squared_error: 17.9624\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 289.4933 - root_mean_squared_error: 17.0145\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 167.9495 - root_mean_squared_error: 12.9595\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 128.8498 - root_mean_squared_error: 11.3512\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 103.7581 - root_mean_squared_error: 10.1862\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 90.2825 - root_mean_squared_error: 9.5017\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 138.0297 - root_mean_squared_error: 11.7486\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 249.3688 - root_mean_squared_error: 15.7914\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 309.4358 - root_mean_squared_error: 17.5908\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 134.2094 - root_mean_squared_error: 11.5849\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 108.9343 - root_mean_squared_error: 10.4372\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 86.5996 - root_mean_squared_error: 9.3059\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 85.2533 - root_mean_squared_error: 9.2333\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 69.9696 - root_mean_squared_error: 8.3648\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 66.9565 - root_mean_squared_error: 8.1827\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 65.0488 - root_mean_squared_error: 8.0653\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 68.2309 - root_mean_squared_error: 8.2602\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 63.3574 - root_mean_squared_error: 7.9597\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 83.2264 - root_mean_squared_error: 9.1228\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 87.3285 - root_mean_squared_error: 9.3450\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 114.9134 - root_mean_squared_error: 10.7198\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 139.7878 - root_mean_squared_error: 11.8232\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 97.2988 - root_mean_squared_error: 9.8640\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 70.1736 - root_mean_squared_error: 8.3770\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 62.6231 - root_mean_squared_error: 7.9135\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 66.8825 - root_mean_squared_error: 8.1782\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 76.1585 - root_mean_squared_error: 8.7269\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 89.6968 - root_mean_squared_error: 9.4708\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 93.4505 - root_mean_squared_error: 9.6670\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 146.9730 - root_mean_squared_error: 12.1232\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 171.9541 - root_mean_squared_error: 13.1131\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 143.1504 - root_mean_squared_error: 11.9645\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 159.0538 - root_mean_squared_error: 12.6117\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 232.0049 - root_mean_squared_error: 15.2317\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 158.7573 - root_mean_squared_error: 12.5999\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 72.6469 - root_mean_squared_error: 8.5233\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 104.1788 - root_mean_squared_error: 10.2068\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 82.2359 - root_mean_squared_error: 9.0684\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 56.8593 - root_mean_squared_error: 7.5405\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 53.7704 - root_mean_squared_error: 7.3328\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 57.4237 - root_mean_squared_error: 7.5778\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 38.0109 - root_mean_squared_error: 6.1653\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 44.5827 - root_mean_squared_error: 6.6770\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 44.7472 - root_mean_squared_error: 6.6893\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 46.8520 - root_mean_squared_error: 6.8449\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 38.1305 - root_mean_squared_error: 6.1750\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 58.6516 - root_mean_squared_error: 7.6584\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 53.4383 - root_mean_squared_error: 7.3102\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 61.4518 - root_mean_squared_error: 7.8391\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.1221 - root_mean_squared_error: 5.9264\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.8049 - root_mean_squared_error: 5.7276\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 35.6699 - root_mean_squared_error: 5.9724\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 34.9962 - root_mean_squared_error: 5.9158\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 44.8687 - root_mean_squared_error: 6.6984\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.8704 - root_mean_squared_error: 6.0721\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 35.2655 - root_mean_squared_error: 5.9385\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 50.5486 - root_mean_squared_error: 7.1098\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 62.8986 - root_mean_squared_error: 7.9309\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 80.2163 - root_mean_squared_error: 8.9564\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 111.5193 - root_mean_squared_error: 10.5603\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 53.7168 - root_mean_squared_error: 7.3292\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 59.3677 - root_mean_squared_error: 7.7050\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 49.6599 - root_mean_squared_error: 7.0470\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 59.1407 - root_mean_squared_error: 7.6903\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 67.0212 - root_mean_squared_error: 8.1866\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 72.0891 - root_mean_squared_error: 8.4905\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 71.9264 - root_mean_squared_error: 8.4809\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 53.9307 - root_mean_squared_error: 7.3438\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.5331 - root_mean_squared_error: 6.2875\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.7715 - root_mean_squared_error: 5.9809\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 40.2362 - root_mean_squared_error: 6.3432\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 41.9390 - root_mean_squared_error: 6.4760\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 45.5963 - root_mean_squared_error: 6.7525\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.4135 - root_mean_squared_error: 5.7804\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 30.2973 - root_mean_squared_error: 5.5043\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 31.8825 - root_mean_squared_error: 5.6465\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.7341 - root_mean_squared_error: 5.3604\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.7248 - root_mean_squared_error: 5.1696\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.1367 - root_mean_squared_error: 5.1124\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.9325 - root_mean_squared_error: 5.1897\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.8995 - root_mean_squared_error: 5.4680\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.6617 - root_mean_squared_error: 5.8019\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.6217 - root_mean_squared_error: 6.0516\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 57.2348 - root_mean_squared_error: 7.5654\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 69.6979 - root_mean_squared_error: 8.3485\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 97.7070 - root_mean_squared_error: 9.8847\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.0641 - root_mean_squared_error: 6.0053\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 25.6024 - root_mean_squared_error: 5.0599\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.5907 - root_mean_squared_error: 5.0587\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 28.8927 - root_mean_squared_error: 5.3752\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.5416 - root_mean_squared_error: 5.4352\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 30.7239 - root_mean_squared_error: 5.5429\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.8369 - root_mean_squared_error: 5.7304\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.6739 - root_mean_squared_error: 6.2987\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 43.0583 - root_mean_squared_error: 6.5619\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 71.9150 - root_mean_squared_error: 8.4803\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 99.3319 - root_mean_squared_error: 9.9665\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 380.5449 - root_mean_squared_error: 19.5076\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 595.5958 - root_mean_squared_error: 24.4048\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 550.6858 - root_mean_squared_error: 23.4667\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 675.2543 - root_mean_squared_error: 25.9857\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 577.1667 - root_mean_squared_error: 24.0243\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 440.2065 - root_mean_squared_error: 20.9811\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 536.4614 - root_mean_squared_error: 23.1616\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 329.8969 - root_mean_squared_error: 18.1631\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 298.5643 - root_mean_squared_error: 17.2790\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 226.5826 - root_mean_squared_error: 15.0527\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 175.2827 - root_mean_squared_error: 13.2394\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 140.4604 - root_mean_squared_error: 11.8516\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 125.5385 - root_mean_squared_error: 11.2044\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 154.0963 - root_mean_squared_error: 12.4136\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 248.0086 - root_mean_squared_error: 15.7483\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 117.1017 - root_mean_squared_error: 10.8214\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 507.8338 - root_mean_squared_error: 22.5352\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 108.8454 - root_mean_squared_error: 10.4329\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 52.9495 - root_mean_squared_error: 7.2766\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 93.9353 - root_mean_squared_error: 9.6920\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 71.4330 - root_mean_squared_error: 8.4518\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 90.5855 - root_mean_squared_error: 9.5176\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 55.2433 - root_mean_squared_error: 7.4326\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 53.8887 - root_mean_squared_error: 7.3409\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 44.7018 - root_mean_squared_error: 6.6859\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 38.8016 - root_mean_squared_error: 6.2291\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 37.2791 - root_mean_squared_error: 6.1057\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.7410 - root_mean_squared_error: 6.0614\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 34.4633 - root_mean_squared_error: 5.8705\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 33.3184 - root_mean_squared_error: 5.7722\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 32.2324 - root_mean_squared_error: 5.6774\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 32.7542 - root_mean_squared_error: 5.7231\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 35.1876 - root_mean_squared_error: 5.9319\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 37.1504 - root_mean_squared_error: 6.0951\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.3833 - root_mean_squared_error: 6.2756\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 37.2357 - root_mean_squared_error: 6.1021\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 38.2349 - root_mean_squared_error: 6.1834\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 39.5005 - root_mean_squared_error: 6.2849\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 39.3893 - root_mean_squared_error: 6.2761\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 35.1874 - root_mean_squared_error: 5.9319\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 49.5402 - root_mean_squared_error: 7.0385\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 52.0811 - root_mean_squared_error: 7.2167\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 47.4638 - root_mean_squared_error: 6.8894\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 37.3137 - root_mean_squared_error: 6.1085\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 34.5483 - root_mean_squared_error: 5.8778\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 30.9062 - root_mean_squared_error: 5.5593\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.9122 - root_mean_squared_error: 5.4692\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 29.1234 - root_mean_squared_error: 5.3966\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 31.5930 - root_mean_squared_error: 5.6208\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 9ms/step - loss: 1066.2506 - root_mean_squared_error: 32.6535\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 909.5086 - root_mean_squared_error: 30.1581\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 861.1433 - root_mean_squared_error: 29.3452\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 842.5102 - root_mean_squared_error: 29.0260\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 952.7731 - root_mean_squared_error: 30.8670\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 852.5627 - root_mean_squared_error: 29.1987\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 866.7032 - root_mean_squared_error: 29.4398\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 863.5226 - root_mean_squared_error: 29.3858\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 855.3151 - root_mean_squared_error: 29.2458\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 854.8839 - root_mean_squared_error: 29.2384\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 845.9828 - root_mean_squared_error: 29.0858\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 862.2770 - root_mean_squared_error: 29.3646\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 861.0221 - root_mean_squared_error: 29.3432\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 893.4457 - root_mean_squared_error: 29.8906\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 853.8803 - root_mean_squared_error: 29.2212\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 874.3904 - root_mean_squared_error: 29.5701\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 886.4497 - root_mean_squared_error: 29.7733\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0986 - root_mean_squared_error: 29.4974\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 812.3861 - root_mean_squared_error: 28.5024\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 876.2906 - root_mean_squared_error: 29.6022\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 872.9785 - root_mean_squared_error: 29.5462\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 871.2277 - root_mean_squared_error: 29.5166\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3686 - root_mean_squared_error: 29.5020\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.8505 - root_mean_squared_error: 29.4932\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7560 - root_mean_squared_error: 29.4916\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5237 - root_mean_squared_error: 29.4877\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 871.0112 - root_mean_squared_error: 29.5129\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5772 - root_mean_squared_error: 29.4886\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3360 - root_mean_squared_error: 29.5015\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.4219 - root_mean_squared_error: 29.5029\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0587 - root_mean_squared_error: 29.4968\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0039 - root_mean_squared_error: 29.4958\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.8125 - root_mean_squared_error: 29.4926\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.5499 - root_mean_squared_error: 29.5051\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.7987 - root_mean_squared_error: 29.5093\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7285 - root_mean_squared_error: 29.4912\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5417 - root_mean_squared_error: 29.4880\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9727 - root_mean_squared_error: 29.4953\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6422 - root_mean_squared_error: 29.4897\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.9527 - root_mean_squared_error: 29.5119\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.3461 - root_mean_squared_error: 29.4847\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6231 - root_mean_squared_error: 29.4894\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6229 - root_mean_squared_error: 29.4894\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7180 - root_mean_squared_error: 29.4910\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9119 - root_mean_squared_error: 29.4943\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9346 - root_mean_squared_error: 29.4947\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.2314 - root_mean_squared_error: 29.4997\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.8121 - root_mean_squared_error: 29.5095\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.5645 - root_mean_squared_error: 29.4884\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.8256 - root_mean_squared_error: 29.4928\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7953 - root_mean_squared_error: 29.4923\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.6309 - root_mean_squared_error: 29.4895\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5612 - root_mean_squared_error: 29.4883\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6151 - root_mean_squared_error: 29.4892\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5571 - root_mean_squared_error: 29.4883\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.5900 - root_mean_squared_error: 29.4888\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.8377 - root_mean_squared_error: 29.4930\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1900 - root_mean_squared_error: 29.4990\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.7807 - root_mean_squared_error: 29.4920\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8448 - root_mean_squared_error: 29.4931\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.6760 - root_mean_squared_error: 29.5072\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0089 - root_mean_squared_error: 29.4959\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9908 - root_mean_squared_error: 29.4956\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.5512 - root_mean_squared_error: 29.4882\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.7955 - root_mean_squared_error: 29.4923\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.3369 - root_mean_squared_error: 29.5015\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8103 - root_mean_squared_error: 29.4925\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5822 - root_mean_squared_error: 29.4887\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.2859 - root_mean_squared_error: 29.5006\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8089 - root_mean_squared_error: 29.4925\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8436 - root_mean_squared_error: 29.4931\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8384 - root_mean_squared_error: 29.4930\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.9756 - root_mean_squared_error: 29.4953\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.0314 - root_mean_squared_error: 29.4963\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.7285 - root_mean_squared_error: 29.4912\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.8990 - root_mean_squared_error: 29.4941\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1173 - root_mean_squared_error: 29.4978\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.4951 - root_mean_squared_error: 29.4872\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7415 - root_mean_squared_error: 29.4914\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5814 - root_mean_squared_error: 29.4887\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1644 - root_mean_squared_error: 29.4986\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.1506 - root_mean_squared_error: 29.4983\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.5508 - root_mean_squared_error: 29.5051\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0168 - root_mean_squared_error: 29.4960\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 870.2563 - root_mean_squared_error: 29.5001\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7501 - root_mean_squared_error: 29.4915\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1236 - root_mean_squared_error: 29.4979\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9249 - root_mean_squared_error: 29.4945\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 869.4876 - root_mean_squared_error: 29.4871\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.6186 - root_mean_squared_error: 29.5062\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6898 - root_mean_squared_error: 29.4905\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.9674 - root_mean_squared_error: 29.5122\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8218 - root_mean_squared_error: 29.4927\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7344 - root_mean_squared_error: 29.4913\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.6797 - root_mean_squared_error: 29.4903\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7617 - root_mean_squared_error: 29.4917\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 870.4785 - root_mean_squared_error: 29.5039\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 869.7861 - root_mean_squared_error: 29.4921\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 869.8073 - root_mean_squared_error: 29.4925\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1514 - root_mean_squared_error: 29.4983\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7532 - root_mean_squared_error: 29.4916\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3533 - root_mean_squared_error: 29.5018\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.2292 - root_mean_squared_error: 29.4996\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6794 - root_mean_squared_error: 29.4903\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1072 - root_mean_squared_error: 29.4976\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6537 - root_mean_squared_error: 29.4899\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7857 - root_mean_squared_error: 29.4921\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1636 - root_mean_squared_error: 29.4985\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.9990 - root_mean_squared_error: 29.4957\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5924 - root_mean_squared_error: 29.4889\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.2452 - root_mean_squared_error: 29.4999\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.9488 - root_mean_squared_error: 29.4949\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.4674 - root_mean_squared_error: 29.4867\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7750 - root_mean_squared_error: 29.4919\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1876 - root_mean_squared_error: 29.4989\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5932 - root_mean_squared_error: 29.4889\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7244 - root_mean_squared_error: 29.4911\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7008 - root_mean_squared_error: 29.4907\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5885 - root_mean_squared_error: 29.4888\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0982 - root_mean_squared_error: 29.4974\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5012 - root_mean_squared_error: 29.4873\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7160 - root_mean_squared_error: 29.4909\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3732 - root_mean_squared_error: 29.5021\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1680 - root_mean_squared_error: 29.4986\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1412 - root_mean_squared_error: 29.4982\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7283 - root_mean_squared_error: 29.4912\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8311 - root_mean_squared_error: 29.4929\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.9572 - root_mean_squared_error: 29.4950\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5924 - root_mean_squared_error: 29.4889\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7064 - root_mean_squared_error: 29.4908\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7549 - root_mean_squared_error: 29.4916\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.4655 - root_mean_squared_error: 29.4867\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8465 - root_mean_squared_error: 29.4932\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.4695 - root_mean_squared_error: 29.4868\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8448 - root_mean_squared_error: 29.4931\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1021 - root_mean_squared_error: 29.4975\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7228 - root_mean_squared_error: 29.4911\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.0179 - root_mean_squared_error: 29.4961\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 869.9556 - root_mean_squared_error: 29.4950\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5839 - root_mean_squared_error: 29.4887\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5051 - root_mean_squared_error: 29.4874\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.0984 - root_mean_squared_error: 29.4974\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8114 - root_mean_squared_error: 29.4926\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3451 - root_mean_squared_error: 29.5016\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7076 - root_mean_squared_error: 29.4908\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.9123 - root_mean_squared_error: 29.4943\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7012 - root_mean_squared_error: 29.4907\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7518 - root_mean_squared_error: 29.4916\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.4628 - root_mean_squared_error: 29.5036\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1852 - root_mean_squared_error: 29.4989\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6521 - root_mean_squared_error: 29.4899\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 871.3274 - root_mean_squared_error: 29.5183\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6599 - root_mean_squared_error: 29.4900\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.0056 - root_mean_squared_error: 29.4959\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7507 - root_mean_squared_error: 29.4915\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6989 - root_mean_squared_error: 29.4907\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.3377 - root_mean_squared_error: 29.5015\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5231 - root_mean_squared_error: 29.4877\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.3506 - root_mean_squared_error: 29.5017\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.6960 - root_mean_squared_error: 29.4906\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.2126 - root_mean_squared_error: 29.4994\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7255 - root_mean_squared_error: 29.4911\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6602 - root_mean_squared_error: 29.4900\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.2292 - root_mean_squared_error: 29.4996\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8682 - root_mean_squared_error: 29.4935\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8022 - root_mean_squared_error: 29.4924\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5464 - root_mean_squared_error: 29.4881\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5087 - root_mean_squared_error: 29.4874\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.6152 - root_mean_squared_error: 29.4892\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.2608 - root_mean_squared_error: 29.5002\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8400 - root_mean_squared_error: 29.4930\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.4075 - root_mean_squared_error: 29.5027\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.6078 - root_mean_squared_error: 29.4891\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1121 - root_mean_squared_error: 29.4977\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.3359 - root_mean_squared_error: 29.5015\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.6445 - root_mean_squared_error: 29.4897\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7654 - root_mean_squared_error: 29.4918\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.5983 - root_mean_squared_error: 29.5059\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0701 - root_mean_squared_error: 29.4970\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.8909 - root_mean_squared_error: 29.4939\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0945 - root_mean_squared_error: 29.4974\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8970 - root_mean_squared_error: 29.4940\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5444 - root_mean_squared_error: 29.4880\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.5688 - root_mean_squared_error: 29.4885\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.0479 - root_mean_squared_error: 29.4966\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0582 - root_mean_squared_error: 29.4967\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.1019 - root_mean_squared_error: 29.4975\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1897 - root_mean_squared_error: 29.4990\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.5272 - root_mean_squared_error: 29.4877\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.7081 - root_mean_squared_error: 29.4908\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.7822 - root_mean_squared_error: 29.4921\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.2264 - root_mean_squared_error: 29.4996\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 870.1634 - root_mean_squared_error: 29.4985\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 869.4844 - root_mean_squared_error: 29.4870\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.8436 - root_mean_squared_error: 29.4931\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.6616 - root_mean_squared_error: 29.5070\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 869.3828 - root_mean_squared_error: 29.4853\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.9120 - root_mean_squared_error: 29.4943\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 870.0175 - root_mean_squared_error: 29.4961\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 869.6359 - root_mean_squared_error: 29.4896\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 869.2692 - root_mean_squared_error: 29.4834\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 9ms/step - loss: 880.8430 - root_mean_squared_error: 29.6790\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 839.2613 - root_mean_squared_error: 28.9700\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 830.4758 - root_mean_squared_error: 28.8180\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 815.7860 - root_mean_squared_error: 28.5620\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 834.4223 - root_mean_squared_error: 28.8864\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 819.7106 - root_mean_squared_error: 28.6306\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 799.6839 - root_mean_squared_error: 28.2787\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 799.4968 - root_mean_squared_error: 28.2754\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 825.0811 - root_mean_squared_error: 28.7242\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 812.9572 - root_mean_squared_error: 28.5124\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 804.3752 - root_mean_squared_error: 28.3615\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 793.0060 - root_mean_squared_error: 28.1604\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 758.7206 - root_mean_squared_error: 27.5449\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 777.8201 - root_mean_squared_error: 27.8894\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 749.1952 - root_mean_squared_error: 27.3714\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 810.1505 - root_mean_squared_error: 28.4631\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 733.0330 - root_mean_squared_error: 27.0746\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 785.3441 - root_mean_squared_error: 28.0240\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 671.4903 - root_mean_squared_error: 25.9131\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 684.3371 - root_mean_squared_error: 26.1598\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 609.6387 - root_mean_squared_error: 24.6909\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 693.7525 - root_mean_squared_error: 26.3392\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 797.2714 - root_mean_squared_error: 28.2360\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 589.3234 - root_mean_squared_error: 24.2760\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 631.5682 - root_mean_squared_error: 25.1310\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 549.4190 - root_mean_squared_error: 23.4397\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 478.2339 - root_mean_squared_error: 21.8686\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 500.9392 - root_mean_squared_error: 22.3817\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 697.9329 - root_mean_squared_error: 26.4184\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 540.3478 - root_mean_squared_error: 23.2454\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 701.6406 - root_mean_squared_error: 26.4885\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 526.4548 - root_mean_squared_error: 22.9446\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 844.6302 - root_mean_squared_error: 29.0625\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 739.2466 - root_mean_squared_error: 27.1891\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 703.2756 - root_mean_squared_error: 26.5193\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 528.9528 - root_mean_squared_error: 22.9990\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 489.2780 - root_mean_squared_error: 22.1196\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 609.1847 - root_mean_squared_error: 24.6817\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 637.4219 - root_mean_squared_error: 25.2472\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 542.8070 - root_mean_squared_error: 23.2982\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 500.5610 - root_mean_squared_error: 22.3732\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 492.6669 - root_mean_squared_error: 22.1961\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 445.1862 - root_mean_squared_error: 21.0994\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 347.8384 - root_mean_squared_error: 18.6504\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 279.8347 - root_mean_squared_error: 16.7283\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 583.4163 - root_mean_squared_error: 24.1540\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 638.7063 - root_mean_squared_error: 25.2726\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 601.7817 - root_mean_squared_error: 24.5312\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 639.1507 - root_mean_squared_error: 25.2814\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 718.4398 - root_mean_squared_error: 26.8037\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 651.7836 - root_mean_squared_error: 25.5301\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 397.3187 - root_mean_squared_error: 19.9329\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 305.1969 - root_mean_squared_error: 17.4699\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 363.9466 - root_mean_squared_error: 19.0774\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 351.6538 - root_mean_squared_error: 18.7524\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 120.6312 - root_mean_squared_error: 10.9832\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 170.9664 - root_mean_squared_error: 13.0754\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 195.7256 - root_mean_squared_error: 13.9902\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 303.8076 - root_mean_squared_error: 17.4301\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 274.7536 - root_mean_squared_error: 16.5757\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 308.6420 - root_mean_squared_error: 17.5682\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 423.4314 - root_mean_squared_error: 20.5774\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 191.6657 - root_mean_squared_error: 13.8443\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 243.0488 - root_mean_squared_error: 15.5900\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 129.4304 - root_mean_squared_error: 11.3767\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 152.4840 - root_mean_squared_error: 12.3484\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 166.4082 - root_mean_squared_error: 12.8999\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 96.6537 - root_mean_squared_error: 9.8313\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 95.9265 - root_mean_squared_error: 9.7942\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 77.9020 - root_mean_squared_error: 8.8262\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 69.9401 - root_mean_squared_error: 8.3630\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 95.6698 - root_mean_squared_error: 9.7811\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 66.9165 - root_mean_squared_error: 8.1803\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 47.0275 - root_mean_squared_error: 6.8577\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 42.8149 - root_mean_squared_error: 6.5433\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 58.2186 - root_mean_squared_error: 7.6301\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.6806 - root_mean_squared_error: 6.2993\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.7886 - root_mean_squared_error: 6.0654\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 49.0014 - root_mean_squared_error: 7.0001\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 79.2740 - root_mean_squared_error: 8.9036\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 64.8228 - root_mean_squared_error: 8.0513\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 95.6329 - root_mean_squared_error: 9.7792\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.1013 - root_mean_squared_error: 5.8396\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 50.9571 - root_mean_squared_error: 7.1384\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 46.3802 - root_mean_squared_error: 6.8103\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 56.8405 - root_mean_squared_error: 7.5393\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 67.1471 - root_mean_squared_error: 8.1943\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 63.3583 - root_mean_squared_error: 7.9598\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 39.2088 - root_mean_squared_error: 6.2617\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 29.3928 - root_mean_squared_error: 5.4215\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 26.8095 - root_mean_squared_error: 5.1778\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 24.7505 - root_mean_squared_error: 4.9750\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.1622 - root_mean_squared_error: 5.2117\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.7344 - root_mean_squared_error: 5.3604\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.1570 - root_mean_squared_error: 5.6707\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 25.3990 - root_mean_squared_error: 5.0397\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.5053 - root_mean_squared_error: 5.3390\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 33.5014 - root_mean_squared_error: 5.7880\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 43.5894 - root_mean_squared_error: 6.6022\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.2050 - root_mean_squared_error: 5.8485\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 48.4888 - root_mean_squared_error: 6.9634\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 53.3814 - root_mean_squared_error: 7.3063\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 137.5265 - root_mean_squared_error: 11.7272\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 135.5824 - root_mean_squared_error: 11.6440\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 511.4056 - root_mean_squared_error: 22.6143\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 792.8907 - root_mean_squared_error: 28.1583\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 766.5533 - root_mean_squared_error: 27.6867\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 785.1095 - root_mean_squared_error: 28.0198\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 760.1876 - root_mean_squared_error: 27.5715\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 709.7096 - root_mean_squared_error: 26.6404\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 656.5452 - root_mean_squared_error: 25.6231\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 624.0146 - root_mean_squared_error: 24.9803\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 597.8148 - root_mean_squared_error: 24.4503\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 493.6203 - root_mean_squared_error: 22.2176\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 465.8439 - root_mean_squared_error: 21.5834\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 442.7346 - root_mean_squared_error: 21.0413\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 368.9670 - root_mean_squared_error: 19.2085\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 306.4241 - root_mean_squared_error: 17.5050\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 423.2516 - root_mean_squared_error: 20.5731\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 551.0359 - root_mean_squared_error: 23.4742\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 327.1917 - root_mean_squared_error: 18.0884\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 268.4011 - root_mean_squared_error: 16.3829\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 285.3768 - root_mean_squared_error: 16.8931\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 252.0114 - root_mean_squared_error: 15.8749\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 210.9136 - root_mean_squared_error: 14.5229\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 150.5533 - root_mean_squared_error: 12.2700\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 143.9666 - root_mean_squared_error: 11.9986\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 144.0228 - root_mean_squared_error: 12.0009\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 127.8036 - root_mean_squared_error: 11.3050\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 117.2160 - root_mean_squared_error: 10.8266\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 121.8364 - root_mean_squared_error: 11.0380\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 102.6507 - root_mean_squared_error: 10.1317\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 97.9821 - root_mean_squared_error: 9.8986\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 90.3129 - root_mean_squared_error: 9.5033\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 88.5270 - root_mean_squared_error: 9.4089\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 136.6916 - root_mean_squared_error: 11.6915\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 142.8731 - root_mean_squared_error: 11.9530\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 92.3712 - root_mean_squared_error: 9.6110\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 76.4297 - root_mean_squared_error: 8.7424\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 76.4064 - root_mean_squared_error: 8.7411\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 91.5534 - root_mean_squared_error: 9.5684\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 66.2343 - root_mean_squared_error: 8.1384\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 58.0622 - root_mean_squared_error: 7.6199\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 66.4332 - root_mean_squared_error: 8.1507\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 56.7070 - root_mean_squared_error: 7.5304\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 56.8279 - root_mean_squared_error: 7.5384\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 60.6523 - root_mean_squared_error: 7.7880\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 61.7770 - root_mean_squared_error: 7.8598\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 67.3744 - root_mean_squared_error: 8.2082\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 80.3203 - root_mean_squared_error: 8.9622\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 52.9979 - root_mean_squared_error: 7.2800\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 48.2288 - root_mean_squared_error: 6.9447\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 44.6198 - root_mean_squared_error: 6.6798\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 46.2496 - root_mean_squared_error: 6.8007\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 47.1726 - root_mean_squared_error: 6.8682\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.6399 - root_mean_squared_error: 6.0531\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 39.3220 - root_mean_squared_error: 6.2707\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 46.2226 - root_mean_squared_error: 6.7987\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 44.4546 - root_mean_squared_error: 6.6674\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 35.8768 - root_mean_squared_error: 5.9897\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.2325 - root_mean_squared_error: 5.8509\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 36.5092 - root_mean_squared_error: 6.0423\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 47.4969 - root_mean_squared_error: 6.8918\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 50.5732 - root_mean_squared_error: 7.1115\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 43.8995 - root_mean_squared_error: 6.6257\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 88.5049 - root_mean_squared_error: 9.4077\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 458.2925 - root_mean_squared_error: 21.4078\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 893.5626 - root_mean_squared_error: 29.8925\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 692.1932 - root_mean_squared_error: 26.3096\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 408.1156 - root_mean_squared_error: 20.2019\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 325.4701 - root_mean_squared_error: 18.0408\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 206.4412 - root_mean_squared_error: 14.3681\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 156.1348 - root_mean_squared_error: 12.4954\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 54.6906 - root_mean_squared_error: 7.3953\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 49.1236 - root_mean_squared_error: 7.0088\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 36.7290 - root_mean_squared_error: 6.0604\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 34.6437 - root_mean_squared_error: 5.8859\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.3039 - root_mean_squared_error: 5.4133\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 29.1028 - root_mean_squared_error: 5.3947\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.8623 - root_mean_squared_error: 5.4646\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.8140 - root_mean_squared_error: 5.3679\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.5642 - root_mean_squared_error: 5.3445\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.9014 - root_mean_squared_error: 5.3760\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.9652 - root_mean_squared_error: 5.2882\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.1093 - root_mean_squared_error: 5.3018\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.5473 - root_mean_squared_error: 5.4357\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.4854 - root_mean_squared_error: 5.2427\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.0899 - root_mean_squared_error: 5.3000\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 30.4857 - root_mean_squared_error: 5.5214\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 35.6349 - root_mean_squared_error: 5.9695\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 32.7681 - root_mean_squared_error: 5.7243\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.4913 - root_mean_squared_error: 5.3377\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.2405 - root_mean_squared_error: 5.3142\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 28.5826 - root_mean_squared_error: 5.3463\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.4526 - root_mean_squared_error: 5.2395\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.6770 - root_mean_squared_error: 5.2609\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 27.0998 - root_mean_squared_error: 5.2057\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 29.8004 - root_mean_squared_error: 5.4590\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.2105 - root_mean_squared_error: 5.3114\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 42.1448 - root_mean_squared_error: 6.4919\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 27.9972 - root_mean_squared_error: 5.2912\n"
     ]
    }
   ],
   "source": [
    "rlist = []\n",
    "for i in range(len(initial_population)):\n",
    "    a = fitness_func(initial_population[i])\n",
    "    rlist.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0421ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.639584064483643, 5.620761394500732, 29.48337173461914, 5.291234493255615]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pick min2 values and add to inital population and repeat process \n",
    "rlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04 0.57\n",
      "0.41 0.56\n",
      "0.48 0.62\n",
      "0.06 0.54\n",
      "0.19 0.99\n",
      "0.01 0.95\n",
      "0.15 0.94\n"
     ]
    }
   ],
   "source": [
    "#Perform Crossover\n",
    "c1,c2 = crossover(initial_population[0],initial_population[3],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "543125df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100', '50', '25', '0.01', 'relu', 'gelu', 'relu'], dtype='<U32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bd92994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100', '50', '25', '0.01', 'relu', 'relu', 'relu'], dtype='<U32')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f83e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to initial population and then repeat this process \n",
    "initial_population = np.vstack([initial_population,c1])\n",
    "initial_population = np.vstack([initial_population,c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdfa5289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['100', '50', '25', '0.01', 'relu', 'gelu', 'relu'],\n",
       "       ['50', '25', '10', '0.01', 'relu', 'gelu', 'swish'],\n",
       "       ['150', '75', '40', '0.1', 'relu', 'swish', 'relu'],\n",
       "       ['100', '50', '25', '0.01', 'relu', 'relu', 'relu'],\n",
       "       ['100', '50', '25', '0.01', 'relu', 'gelu', 'relu'],\n",
       "       ['100', '50', '25', '0.01', 'relu', 'relu', 'relu']], dtype='<U32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444855e",
   "metadata": {},
   "source": [
    "# Method 3 ( Bayesian Optimization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d254bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\2160756511.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n",
      "[I 2024-02-23 23:02:40,953] A new study created in memory with name: no-name-82a44e86-097d-4466-8f5a-08de74e94919\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "[I 2024-02-23 23:02:49,617] Trial 0 finished with value: 5.378365516662598 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 75, 'num_neurons_layer_2': 18, 'num_neurons_layer_3': 60, 'num_neurons_layer_4': 88}. Best is trial 0 with value: 5.378365516662598.\n",
      "[I 2024-02-23 23:02:57,953] Trial 1 finished with value: 5.008517265319824 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 27, 'num_neurons_layer_1': 18, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 96}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:06,848] Trial 2 finished with value: 6.4658203125 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 98, 'num_neurons_layer_2': 22, 'num_neurons_layer_3': 86, 'num_neurons_layer_4': 17}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:13,535] Trial 3 finished with value: 9.812101364135742 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 6}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:21,265] Trial 4 finished with value: 9.369338035583496 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 38, 'num_neurons_layer_2': 82}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:28,594] Trial 5 finished with value: 9.267233848571777 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 100}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:35,835] Trial 6 finished with value: 9.46486759185791 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 27, 'num_neurons_layer_1': 44}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:43,710] Trial 7 finished with value: 7.432469844818115 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 57}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:51,853] Trial 8 finished with value: 6.0517473220825195 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 55, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 80, 'num_neurons_layer_3': 88}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:03:59,644] Trial 9 finished with value: 9.040226936340332 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 78, 'num_neurons_layer_1': 30, 'num_neurons_layer_2': 7}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:08,071] Trial 10 finished with value: 9.324469566345215 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 9, 'num_neurons_layer_1': 6, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 10}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:16,833] Trial 11 finished with value: 7.758561134338379 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 66, 'num_neurons_layer_2': 51, 'num_neurons_layer_3': 53, 'num_neurons_layer_4': 92}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:24,867] Trial 12 finished with value: 12.430273056030273 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 25, 'num_neurons_layer_1': 5, 'num_neurons_layer_2': 24, 'num_neurons_layer_3': 58}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:33,558] Trial 13 finished with value: 5.59214973449707 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 22, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 98, 'num_neurons_layer_3': 100, 'num_neurons_layer_4': 98}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:41,788] Trial 14 finished with value: 5.208722114562988 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 24}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:50,014] Trial 15 finished with value: 5.276899337768555 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 66, 'num_neurons_layer_1': 22, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 18}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:04:58,195] Trial 16 finished with value: 9.867791175842285 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 42, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 30}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:05,573] Trial 17 finished with value: 9.373785972595215 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 19, 'num_neurons_layer_1': 17}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:13,591] Trial 18 finished with value: 10.927528381347656 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 33, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 42}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:22,030] Trial 19 finished with value: 5.905689239501953 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 69, 'num_neurons_layer_1': 33, 'num_neurons_layer_2': 87, 'num_neurons_layer_3': 33}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:28,633] Trial 20 finished with value: 9.039762496948242 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 49}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:36,892] Trial 21 finished with value: 5.380967140197754 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 65, 'num_neurons_layer_1': 22, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 8}. Best is trial 1 with value: 5.008517265319824.\n",
      "[I 2024-02-23 23:05:45,280] Trial 22 finished with value: 4.840633869171143 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 74, 'num_neurons_layer_1': 14, 'num_neurons_layer_2': 69, 'num_neurons_layer_3': 26}. Best is trial 22 with value: 4.840633869171143.\n",
      "[I 2024-02-23 23:05:54,057] Trial 23 finished with value: 5.708494186401367 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 93, 'num_neurons_layer_1': 12, 'num_neurons_layer_2': 62, 'num_neurons_layer_3': 39, 'num_neurons_layer_4': 10}. Best is trial 22 with value: 4.840633869171143.\n",
      "[I 2024-02-23 23:06:02,203] Trial 24 finished with value: 4.644064426422119 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 75, 'num_neurons_layer_3': 70}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:06:10,062] Trial 25 finished with value: 7.922703266143799 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 83, 'num_neurons_layer_1': 30, 'num_neurons_layer_2': 79}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:06:18,788] Trial 26 finished with value: 5.976426124572754 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 99, 'num_neurons_layer_1': 39, 'num_neurons_layer_2': 39, 'num_neurons_layer_3': 72}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:06:27,616] Trial 27 finished with value: 6.030781269073486 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 74, 'num_neurons_layer_1': 11, 'num_neurons_layer_2': 91, 'num_neurons_layer_3': 75, 'num_neurons_layer_4': 47}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:06:35,357] Trial 28 finished with value: 6.098461151123047 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 86, 'num_neurons_layer_1': 53, 'num_neurons_layer_2': 75}. Best is trial 24 with value: 4.644064426422119.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:06:44,128] Trial 29 finished with value: 5.4995436668396 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 98, 'num_neurons_layer_1': 27, 'num_neurons_layer_2': 56, 'num_neurons_layer_3': 43, 'num_neurons_layer_4': 51}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:06:52,442] Trial 30 finished with value: 14.110395431518555 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 13, 'num_neurons_layer_1': 13, 'num_neurons_layer_2': 99, 'num_neurons_layer_3': 73}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:00,786] Trial 31 finished with value: 7.311892032623291 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 74, 'num_neurons_layer_3': 25}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:09,058] Trial 32 finished with value: 5.095291614532471 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 53, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 62, 'num_neurons_layer_3': 100}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:17,639] Trial 33 finished with value: 5.2916436195373535 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 55, 'num_neurons_layer_1': 12, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 99, 'num_neurons_layer_4': 68}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:25,765] Trial 34 finished with value: 7.427987098693848 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 73, 'num_neurons_layer_1': 35, 'num_neurons_layer_2': 45}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:34,078] Trial 35 finished with value: 6.706064701080322 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 88, 'num_neurons_layer_1': 5, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 91}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:41,895] Trial 36 finished with value: 7.60890531539917 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 74}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:50,645] Trial 37 finished with value: 5.264495849609375 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 79, 'num_neurons_layer_1': 41, 'num_neurons_layer_2': 62, 'num_neurons_layer_3': 81, 'num_neurons_layer_4': 32}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:07:58,914] Trial 38 finished with value: 5.820178985595703 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 51, 'num_neurons_layer_1': 26, 'num_neurons_layer_2': 87, 'num_neurons_layer_3': 96}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:06,841] Trial 39 finished with value: 9.675986289978027 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 31, 'num_neurons_layer_1': 9, 'num_neurons_layer_2': 55}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:14,018] Trial 40 finished with value: 8.80469036102295 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 93, 'num_neurons_layer_1': 34}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:22,417] Trial 41 finished with value: 6.680539608001709 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 45, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 17}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:31,334] Trial 42 finished with value: 10.570024490356445 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 41, 'num_neurons_layer_1': 17, 'num_neurons_layer_2': 72, 'num_neurons_layer_3': 47}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:39,731] Trial 43 finished with value: 5.339229583740234 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 61, 'num_neurons_layer_1': 27, 'num_neurons_layer_2': 81, 'num_neurons_layer_3': 66}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:47,919] Trial 44 finished with value: 4.722866535186768 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 38, 'num_neurons_layer_1': 21, 'num_neurons_layer_2': 64, 'num_neurons_layer_3': 25}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:08:56,674] Trial 45 finished with value: 4.954707145690918 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 45, 'num_neurons_layer_2': 62, 'num_neurons_layer_3': 93, 'num_neurons_layer_4': 66}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:05,274] Trial 46 finished with value: 5.847632884979248 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 9, 'num_neurons_layer_1': 50, 'num_neurons_layer_2': 50, 'num_neurons_layer_3': 81, 'num_neurons_layer_4': 69}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:14,054] Trial 47 finished with value: 6.744749546051025 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 19, 'num_neurons_layer_1': 71, 'num_neurons_layer_2': 77, 'num_neurons_layer_3': 65, 'num_neurons_layer_4': 71}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:22,619] Trial 48 finished with value: 5.4447784423828125 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 30, 'num_neurons_layer_2': 84, 'num_neurons_layer_3': 93, 'num_neurons_layer_4': 35}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:31,797] Trial 49 finished with value: 6.77285623550415 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 89, 'num_neurons_layer_2': 59, 'num_neurons_layer_3': 85, 'num_neurons_layer_4': 82}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:39,582] Trial 50 finished with value: 9.588037490844727 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 37, 'num_neurons_layer_1': 58, 'num_neurons_layer_2': 72}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:47,900] Trial 51 finished with value: 5.5103607177734375 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 26, 'num_neurons_layer_1': 21, 'num_neurons_layer_2': 62, 'num_neurons_layer_3': 89}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:09:55,930] Trial 52 finished with value: 7.871185779571533 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 22, 'num_neurons_layer_1': 8, 'num_neurons_layer_2': 65, 'num_neurons_layer_3': 94}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:04,440] Trial 53 finished with value: 5.471826076507568 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 70, 'num_neurons_layer_3': 83}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:12,811] Trial 54 finished with value: 10.691431045532227 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 6, 'num_neurons_layer_1': 14, 'num_neurons_layer_2': 54, 'num_neurons_layer_3': 97}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:20,090] Trial 55 finished with value: 8.788293838500977 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 39, 'num_neurons_layer_1': 24}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:28,298] Trial 56 finished with value: 5.696773052215576 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 46, 'num_neurons_layer_1': 29, 'num_neurons_layer_2': 65, 'num_neurons_layer_3': 15}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:37,117] Trial 57 finished with value: 5.967349052429199 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 22, 'num_neurons_layer_1': 37, 'num_neurons_layer_2': 57, 'num_neurons_layer_3': 59, 'num_neurons_layer_4': 60}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:10:45,840] Trial 58 finished with value: 8.309395790100098 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 15, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 52}. Best is trial 24 with value: 4.644064426422119.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:10:53,621] Trial 59 finished with value: 9.686415672302246 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 55, 'num_neurons_layer_1': 22, 'num_neurons_layer_2': 64}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:01,754] Trial 60 finished with value: 6.5521039962768555 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 71, 'num_neurons_layer_1': 9, 'num_neurons_layer_2': 10, 'num_neurons_layer_3': 100}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:09,873] Trial 61 finished with value: 6.148844242095947 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 47, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 24}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:18,319] Trial 62 finished with value: 6.207408905029297 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 41, 'num_neurons_layer_1': 14, 'num_neurons_layer_2': 71, 'num_neurons_layer_3': 32}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:26,753] Trial 63 finished with value: 5.609389305114746 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 30, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 77, 'num_neurons_layer_3': 23}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:33,432] Trial 64 finished with value: 8.876797676086426 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 35}. Best is trial 24 with value: 4.644064426422119.\n",
      "[I 2024-02-23 23:11:42,585] Trial 65 finished with value: 4.5967936515808105 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 83, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 58, 'num_neurons_layer_3': 21, 'num_neurons_layer_4': 40}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:11:51,289] Trial 66 finished with value: 5.41040563583374 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 82, 'num_neurons_layer_1': 63, 'num_neurons_layer_2': 52, 'num_neurons_layer_3': 11, 'num_neurons_layer_4': 37}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:11:59,932] Trial 67 finished with value: 5.781692028045654 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 89, 'num_neurons_layer_1': 10, 'num_neurons_layer_2': 59, 'num_neurons_layer_3': 27, 'num_neurons_layer_4': 21}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:08,637] Trial 68 finished with value: 5.280869483947754 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 33, 'num_neurons_layer_2': 33, 'num_neurons_layer_3': 37, 'num_neurons_layer_4': 43}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:17,734] Trial 69 finished with value: 5.491720676422119 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 42, 'num_neurons_layer_2': 94, 'num_neurons_layer_3': 87, 'num_neurons_layer_4': 58}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:26,283] Trial 70 finished with value: 5.980520248413086 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 85, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 63, 'num_neurons_layer_3': 19, 'num_neurons_layer_4': 24}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:34,854] Trial 71 finished with value: 6.2333664894104 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 63, 'num_neurons_layer_1': 21, 'num_neurons_layer_2': 70, 'num_neurons_layer_3': 29}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:43,639] Trial 72 finished with value: 5.647223472595215 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 57, 'num_neurons_layer_1': 14, 'num_neurons_layer_2': 59, 'num_neurons_layer_3': 11}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:12:54,168] Trial 73 finished with value: 6.151130199432373 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 51, 'num_neurons_layer_1': 26, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 34}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:02,245] Trial 74 finished with value: 7.068746089935303 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 69, 'num_neurons_layer_1': 17, 'num_neurons_layer_2': 76}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:10,537] Trial 75 finished with value: 4.920851707458496 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 30, 'num_neurons_layer_2': 55, 'num_neurons_layer_3': 20}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:18,252] Trial 76 finished with value: 6.889326572418213 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 95, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 44}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:26,613] Trial 77 finished with value: 5.431183338165283 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 99, 'num_neurons_layer_1': 38, 'num_neurons_layer_2': 53, 'num_neurons_layer_3': 21}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:35,155] Trial 78 finished with value: 5.333796977996826 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 49, 'num_neurons_layer_3': 5, 'num_neurons_layer_4': 75}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:43,492] Trial 79 finished with value: 5.420486927032471 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 90, 'num_neurons_layer_1': 54, 'num_neurons_layer_2': 58, 'num_neurons_layer_3': 16}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:13:52,192] Trial 80 finished with value: 6.541509628295898 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 7, 'num_neurons_layer_2': 61, 'num_neurons_layer_3': 77, 'num_neurons_layer_4': 59}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:01,012] Trial 81 finished with value: 7.227824687957764 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 82, 'num_neurons_layer_1': 27, 'num_neurons_layer_2': 65, 'num_neurons_layer_3': 28}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:09,186] Trial 82 finished with value: 4.698604583740234 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 95, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 55, 'num_neurons_layer_3': 14}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:17,718] Trial 83 finished with value: 11.177298545837402 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 30, 'num_neurons_layer_2': 55, 'num_neurons_layer_3': 13}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:25,985] Trial 84 finished with value: 5.711307525634766 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 91, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 46, 'num_neurons_layer_3': 93}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:34,324] Trial 85 finished with value: 7.239442348480225 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 95, 'num_neurons_layer_1': 20, 'num_neurons_layer_2': 57, 'num_neurons_layer_3': 20}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:42,709] Trial 86 finished with value: 5.545835971832275 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 87, 'num_neurons_layer_1': 12, 'num_neurons_layer_2': 61, 'num_neurons_layer_3': 97}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:50,916] Trial 87 finished with value: 5.938910484313965 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 97, 'num_neurons_layer_1': 17, 'num_neurons_layer_2': 52, 'num_neurons_layer_3': 66}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:14:59,091] Trial 88 finished with value: 8.34893798828125 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 94, 'num_neurons_layer_1': 36, 'num_neurons_layer_2': 72}. Best is trial 65 with value: 4.5967936515808105.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:15:07,999] Trial 89 finished with value: 5.153791904449463 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 77, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 66, 'num_neurons_layer_3': 90, 'num_neurons_layer_4': 28}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:15:16,388] Trial 90 finished with value: 5.46891450881958 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 18, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 79, 'num_neurons_layer_3': 55}. Best is trial 65 with value: 4.5967936515808105.\n",
      "[I 2024-02-23 23:15:25,149] Trial 91 finished with value: 4.526848316192627 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 66, 'num_neurons_layer_3': 90, 'num_neurons_layer_4': 42}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:15:33,692] Trial 92 finished with value: 5.635772705078125 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 85, 'num_neurons_layer_1': 31, 'num_neurons_layer_2': 74, 'num_neurons_layer_3': 95, 'num_neurons_layer_4': 42}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:15:42,061] Trial 93 finished with value: 5.841083526611328 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 15, 'num_neurons_layer_2': 69, 'num_neurons_layer_3': 92, 'num_neurons_layer_4': 54}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:15:50,637] Trial 94 finished with value: 5.797362327575684 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 22, 'num_neurons_layer_2': 84, 'num_neurons_layer_3': 100, 'num_neurons_layer_4': 47}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:15:59,755] Trial 95 finished with value: 10.235629081726074 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 11, 'num_neurons_layer_1': 26, 'num_neurons_layer_2': 63, 'num_neurons_layer_3': 22, 'num_neurons_layer_4': 64}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:16:08,373] Trial 96 finished with value: 5.608015060424805 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 67, 'num_neurons_layer_1': 19, 'num_neurons_layer_2': 57, 'num_neurons_layer_3': 45}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:16:16,600] Trial 97 finished with value: 10.791352272033691 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 29, 'num_neurons_layer_1': 12, 'num_neurons_layer_2': 61, 'num_neurons_layer_3': 8}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:16:25,560] Trial 98 finished with value: 5.183457374572754 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 74, 'num_neurons_layer_1': 35, 'num_neurons_layer_2': 64, 'num_neurons_layer_3': 70, 'num_neurons_layer_4': 81}. Best is trial 91 with value: 4.526848316192627.\n",
      "[I 2024-02-23 23:16:33,860] Trial 99 finished with value: 7.010329723358154 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 98, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 67, 'num_neurons_layer_3': 79}. Best is trial 91 with value: 4.526848316192627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 66, 'num_neurons_layer_3': 90, 'num_neurons_layer_4': 42}\n",
      "Best RMSE: 4.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
    "    num_neurons = [trial.suggest_int(f'num_neurons_layer_{i}', 5, 100) for i in range(num_hidden_layers)]\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons[0], activation='relu', input_dim=len(features)))\n",
    "    \n",
    "    for i in range(1, num_hidden_layers):\n",
    "        model.add(Dense(num_neurons[i], activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    rmse_value = results[1]\n",
    "\n",
    "    return rmse_value\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_rmse = study.best_value\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96400b9",
   "metadata": {},
   "source": [
    "# Method 4 ( Ensemble - Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b737d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\1887619081.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 33ms/step - loss: 1210.5544 - val_loss: 125.0142\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1203.1278 - val_loss: 121.4756\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1198.6256 - val_loss: 118.4155\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1193.5603 - val_loss: 114.1994\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1186.1549 - val_loss: 107.8436\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1173.6879 - val_loss: 99.1161\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1156.0092 - val_loss: 86.7195\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1130.3604 - val_loss: 71.7893\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1095.5071 - val_loss: 56.9312\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1049.8518 - val_loss: 48.0602\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1008.4662 - val_loss: 50.4847\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 963.6644 - val_loss: 61.4656\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 940.1501 - val_loss: 78.2940\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 922.1824 - val_loss: 83.2937\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 912.7326 - val_loss: 95.1767\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 907.5896 - val_loss: 100.6449\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 904.4424 - val_loss: 105.2912\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 902.3369 - val_loss: 103.0556\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 902.4697 - val_loss: 91.3208\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 898.1002 - val_loss: 96.5330\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 896.6990 - val_loss: 105.2556\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 895.6638 - val_loss: 106.1835\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 895.0897 - val_loss: 104.5847\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 893.0499 - val_loss: 100.7811\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 892.0948 - val_loss: 94.9515\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 891.7938 - val_loss: 95.3179\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 891.1135 - val_loss: 91.1028\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 890.2620 - val_loss: 93.1641\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 890.0809 - val_loss: 100.5506\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 889.9454 - val_loss: 103.2683\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 890.7159 - val_loss: 88.0315\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 888.5994 - val_loss: 98.0115\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 887.4670 - val_loss: 96.2204\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 887.5409 - val_loss: 99.1760\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 886.2297 - val_loss: 92.7337\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 885.9196 - val_loss: 94.9502\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 886.1033 - val_loss: 88.6629\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 884.3098 - val_loss: 88.7385\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 883.9059 - val_loss: 95.8337\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 883.6424 - val_loss: 92.3588\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 882.4717 - val_loss: 94.8273\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 882.4081 - val_loss: 95.7537\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 882.2616 - val_loss: 89.0119\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 881.3821 - val_loss: 86.6772\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 881.0410 - val_loss: 93.5942\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 881.2213 - val_loss: 89.6551\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 880.8284 - val_loss: 93.4396\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 880.5197 - val_loss: 92.7083\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 879.2368 - val_loss: 86.2673\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 878.8887 - val_loss: 90.2643\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 877.8896 - val_loss: 88.5785\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 877.7836 - val_loss: 91.2912\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 877.4286 - val_loss: 84.9539\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 876.7283 - val_loss: 90.3071\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 877.3541 - val_loss: 82.2367\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 875.1541 - val_loss: 88.9984\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 875.3848 - val_loss: 87.9460\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 875.2621 - val_loss: 87.0134\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 874.0007 - val_loss: 85.9454\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 874.0188 - val_loss: 90.7847\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 873.6575 - val_loss: 86.7637\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 874.0858 - val_loss: 93.5694\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 871.9479 - val_loss: 89.6108\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 872.0709 - val_loss: 87.2052\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 870.9311 - val_loss: 84.9209\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 871.3346 - val_loss: 84.4936\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 870.6416 - val_loss: 89.5020\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 870.5119 - val_loss: 83.9776\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 869.8296 - val_loss: 82.1151\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 869.2912 - val_loss: 86.9294\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 870.6386 - val_loss: 79.4545\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 869.6719 - val_loss: 88.6463\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 868.2060 - val_loss: 88.6971\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 868.3305 - val_loss: 80.0695\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 867.6718 - val_loss: 87.2564\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 867.4438 - val_loss: 78.5128\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 865.4301 - val_loss: 81.6457\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 865.3900 - val_loss: 84.0523\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 865.1708 - val_loss: 87.2013\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 864.6511 - val_loss: 82.8886\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 864.1210 - val_loss: 85.5660\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 863.3776 - val_loss: 83.5920\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 863.0633 - val_loss: 85.4033\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 861.7006 - val_loss: 80.9315\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 861.5022 - val_loss: 82.0366\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 861.6260 - val_loss: 77.4363\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 863.1650 - val_loss: 91.8978\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 860.4675 - val_loss: 89.0315\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 859.6544 - val_loss: 85.5889\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 860.5539 - val_loss: 76.3321\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 858.6111 - val_loss: 77.7327\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 858.0057 - val_loss: 82.1067\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 857.8236 - val_loss: 85.5526\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 857.5461 - val_loss: 80.0254\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 856.4380 - val_loss: 82.1346\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 857.0362 - val_loss: 76.6636\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 855.4189 - val_loss: 84.8217\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 854.9830 - val_loss: 84.8521\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 853.8856 - val_loss: 81.6858\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 853.2507 - val_loss: 81.6861\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 854.3782 - val_loss: 71.8235\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 852.4869 - val_loss: 75.1743\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 855.7145 - val_loss: 88.9389\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 852.9770 - val_loss: 77.1036\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 850.3445 - val_loss: 78.1039\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 850.0929 - val_loss: 83.0270\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 851.4008 - val_loss: 72.7526\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 852.1664 - val_loss: 92.3337\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 848.0382 - val_loss: 84.6951\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 847.7246 - val_loss: 78.2700\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 846.7004 - val_loss: 81.6539\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 845.7742 - val_loss: 79.3397\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 845.7369 - val_loss: 84.5958\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 845.4177 - val_loss: 82.7130\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 845.0945 - val_loss: 71.7809\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 844.8492 - val_loss: 82.0498\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 842.6937 - val_loss: 80.0392\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 843.8877 - val_loss: 71.6082\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 841.7473 - val_loss: 74.0521\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 844.2949 - val_loss: 86.2171\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 839.8180 - val_loss: 80.0837\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 839.0973 - val_loss: 76.9825\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 839.2700 - val_loss: 77.7407\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 838.6263 - val_loss: 78.6720\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 837.4053 - val_loss: 77.2799\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 837.2495 - val_loss: 76.4663\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 836.4335 - val_loss: 76.2400\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 834.8157 - val_loss: 76.0603\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 834.9189 - val_loss: 70.9796\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 833.3864 - val_loss: 78.6554\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 833.3696 - val_loss: 78.4677\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 832.3784 - val_loss: 78.9430\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 833.3699 - val_loss: 72.3378\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 830.7563 - val_loss: 72.5224\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 830.6098 - val_loss: 78.2501\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 830.7595 - val_loss: 81.6753\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 829.3387 - val_loss: 80.8954\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 829.1704 - val_loss: 68.7486\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 827.1151 - val_loss: 71.8196\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 825.7971 - val_loss: 77.4605\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 826.8827 - val_loss: 80.6514\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 824.6470 - val_loss: 76.2036\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 824.1473 - val_loss: 75.0086\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 823.0289 - val_loss: 73.8706\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 823.7089 - val_loss: 71.5473\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 820.9835 - val_loss: 76.6698\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 822.8313 - val_loss: 78.5461\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 821.3840 - val_loss: 80.1093\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 821.7940 - val_loss: 70.0044\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 819.8233 - val_loss: 80.7304\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 818.2524 - val_loss: 76.3134\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 817.9323 - val_loss: 82.1354\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 816.9472 - val_loss: 75.0575\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 814.8510 - val_loss: 77.0404\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 816.4222 - val_loss: 74.1764\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 814.6601 - val_loss: 77.8427\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 814.9808 - val_loss: 84.3455\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 814.8770 - val_loss: 72.2362\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 810.7137 - val_loss: 75.0879\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 814.6574 - val_loss: 66.1898\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 810.5178 - val_loss: 91.6164\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 810.3470 - val_loss: 87.1300\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 807.2333 - val_loss: 83.5422\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 805.9641 - val_loss: 75.9640\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 805.8336 - val_loss: 72.8664\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 805.0479 - val_loss: 79.9857\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 806.2445 - val_loss: 70.4428\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 804.4503 - val_loss: 85.4650\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 804.9847 - val_loss: 74.6119\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 800.3268 - val_loss: 83.0958\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 799.8773 - val_loss: 89.2471\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 800.3195 - val_loss: 90.7757\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 799.2868 - val_loss: 80.6011\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 797.6945 - val_loss: 83.8132\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 798.3447 - val_loss: 77.8376\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 796.8154 - val_loss: 76.6611\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 795.2070 - val_loss: 79.5778\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 794.5276 - val_loss: 86.7514\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 797.0596 - val_loss: 73.0769\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 793.1856 - val_loss: 80.8005\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 792.1144 - val_loss: 74.9757\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 791.6046 - val_loss: 76.0203\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 793.5601 - val_loss: 84.7580\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 794.4985 - val_loss: 73.1617\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 788.9986 - val_loss: 82.2887\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 788.5596 - val_loss: 77.9900\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 790.6150 - val_loss: 88.6166\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 786.0308 - val_loss: 85.5578\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 785.4907 - val_loss: 78.3863\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 784.7343 - val_loss: 77.9072\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 783.0593 - val_loss: 79.8412\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 782.2906 - val_loss: 82.0140\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 782.1437 - val_loss: 78.8897\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 779.7875 - val_loss: 79.4536\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 779.7880 - val_loss: 81.9636\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 780.0683 - val_loss: 84.5455\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 778.2165 - val_loss: 79.4931\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 777.1995 - val_loss: 82.8039\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 776.2761 - val_loss: 80.7280\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 774.3100 - val_loss: 79.2850\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 1198.7426 - val_loss: 120.4886\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1197.4139 - val_loss: 119.9453\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1196.1722 - val_loss: 119.4075\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1194.9075 - val_loss: 118.8766\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1193.6558 - val_loss: 118.3211\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1192.3878 - val_loss: 117.7565\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1191.1458 - val_loss: 117.2896\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1189.9727 - val_loss: 116.6895\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1188.7583 - val_loss: 116.1694\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1187.5151 - val_loss: 115.6698\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1186.3469 - val_loss: 115.1951\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1185.2437 - val_loss: 114.6604\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1183.9774 - val_loss: 114.1638\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1182.8163 - val_loss: 113.6809\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1181.6255 - val_loss: 113.2035\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1180.4520 - val_loss: 112.6995\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1179.2209 - val_loss: 112.2213\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1178.0922 - val_loss: 111.7391\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1176.8992 - val_loss: 111.2915\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1175.7206 - val_loss: 110.8276\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1174.6295 - val_loss: 110.3318\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1173.4121 - val_loss: 109.9136\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1172.3286 - val_loss: 109.4600\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1171.2085 - val_loss: 109.0124\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1170.0352 - val_loss: 108.6129\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1168.9385 - val_loss: 108.1083\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1167.5199 - val_loss: 107.6164\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1166.4132 - val_loss: 107.2162\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1165.4045 - val_loss: 106.8311\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1164.4011 - val_loss: 106.4216\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1163.4120 - val_loss: 106.0527\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1162.3977 - val_loss: 105.6929\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1161.4519 - val_loss: 105.2812\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1160.3911 - val_loss: 104.9061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1159.3807 - val_loss: 104.5552\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1158.4233 - val_loss: 104.1480\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1157.3860 - val_loss: 103.7991\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1156.4464 - val_loss: 103.4210\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1155.3591 - val_loss: 103.0604\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1154.4384 - val_loss: 102.6990\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1153.4135 - val_loss: 102.3356\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1152.4520 - val_loss: 101.9834\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1151.4948 - val_loss: 101.6369\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1150.5066 - val_loss: 101.3050\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1149.5305 - val_loss: 100.9404\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1148.5461 - val_loss: 100.5983\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1147.5890 - val_loss: 100.2665\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1146.6128 - val_loss: 99.9361\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1145.6506 - val_loss: 99.6053\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1144.6709 - val_loss: 99.2851\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1143.7146 - val_loss: 98.9749\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1142.7832 - val_loss: 98.6282\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1141.8726 - val_loss: 98.2981\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1140.8883 - val_loss: 97.9873\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1139.9744 - val_loss: 97.6539\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1139.0349 - val_loss: 97.3483\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1138.0491 - val_loss: 97.0390\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1137.1315 - val_loss: 96.7343\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1136.1750 - val_loss: 96.4276\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1135.1208 - val_loss: 96.0597\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1134.1660 - val_loss: 95.7645\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1133.2825 - val_loss: 95.4668\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1132.3661 - val_loss: 95.1716\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1131.4884 - val_loss: 94.8782\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1130.5798 - val_loss: 94.5950\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1129.6986 - val_loss: 94.3143\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1128.7804 - val_loss: 94.0415\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1127.9323 - val_loss: 93.7598\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1127.0428 - val_loss: 93.4751\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1126.1567 - val_loss: 93.2087\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1125.2681 - val_loss: 92.9326\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1124.3965 - val_loss: 92.6649\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1123.5194 - val_loss: 92.3941\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1122.6349 - val_loss: 92.1320\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1121.7443 - val_loss: 91.8799\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1120.9127 - val_loss: 91.6104\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1120.0795 - val_loss: 91.3508\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1119.1865 - val_loss: 91.0819\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1118.3795 - val_loss: 90.8304\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1117.4811 - val_loss: 90.5721\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1116.6309 - val_loss: 90.3203\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1115.7845 - val_loss: 90.0656\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1114.9402 - val_loss: 89.8159\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1114.1121 - val_loss: 89.5693\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1113.2729 - val_loss: 89.3143\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1112.4467 - val_loss: 89.0676\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1111.6088 - val_loss: 88.8340\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1110.7812 - val_loss: 88.5698\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1109.9634 - val_loss: 88.3411\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1109.1592 - val_loss: 88.0990\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1108.2883 - val_loss: 87.8780\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1107.4985 - val_loss: 87.6163\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1106.6980 - val_loss: 87.3702\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1105.8589 - val_loss: 87.1530\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1105.0709 - val_loss: 86.9239\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1104.2543 - val_loss: 86.7001\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1103.4144 - val_loss: 86.4680\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1102.6283 - val_loss: 86.2579\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1101.8282 - val_loss: 86.0262\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1101.0106 - val_loss: 85.8197\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1100.1932 - val_loss: 85.5938\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1099.4261 - val_loss: 85.3948\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1098.6375 - val_loss: 85.1679\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1097.8976 - val_loss: 84.9416\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1097.0551 - val_loss: 84.7527\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1096.2926 - val_loss: 84.5163\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1095.4652 - val_loss: 84.3114\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1094.7107 - val_loss: 84.1038\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1093.9252 - val_loss: 83.8867\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1093.1887 - val_loss: 83.7052\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1092.4442 - val_loss: 83.5002\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1091.6387 - val_loss: 83.3203\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1090.8701 - val_loss: 83.1088\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1090.0988 - val_loss: 82.9045\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1089.3466 - val_loss: 82.7166\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1088.6007 - val_loss: 82.5247\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1087.8740 - val_loss: 82.3236\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1087.1169 - val_loss: 82.1425\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1086.3987 - val_loss: 81.9413\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1085.6478 - val_loss: 81.7841\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1084.9285 - val_loss: 81.5793\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1084.1796 - val_loss: 81.3907\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1083.4484 - val_loss: 81.2056\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1082.7722 - val_loss: 81.0197\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1082.0160 - val_loss: 80.8498\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1081.3082 - val_loss: 80.6581\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1080.5592 - val_loss: 80.4943\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1079.8634 - val_loss: 80.3252\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1079.1387 - val_loss: 80.1421\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1078.4113 - val_loss: 79.9659\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1077.6565 - val_loss: 79.7885\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1076.9130 - val_loss: 79.5895\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1076.2147 - val_loss: 79.4031\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1075.5300 - val_loss: 79.2171\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1074.8621 - val_loss: 79.0690\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1074.1481 - val_loss: 78.8976\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1073.5477 - val_loss: 78.7140\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1072.8149 - val_loss: 78.5315\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1072.1434 - val_loss: 78.3815\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1071.4607 - val_loss: 78.2227\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1070.7910 - val_loss: 78.0541\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1070.1576 - val_loss: 77.9217\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1069.4600 - val_loss: 77.7257\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1068.8239 - val_loss: 77.5891\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1068.1724 - val_loss: 77.4567\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1067.4655 - val_loss: 77.2800\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1066.8092 - val_loss: 77.1231\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1066.1675 - val_loss: 76.9753\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1065.3838 - val_loss: 76.8061\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1064.7383 - val_loss: 76.6544\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1064.1168 - val_loss: 76.5275\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1063.4778 - val_loss: 76.3638\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1062.8503 - val_loss: 76.1580\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1062.1982 - val_loss: 76.0279\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1061.5981 - val_loss: 75.8798\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1060.9507 - val_loss: 75.7353\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1060.3093 - val_loss: 75.6102\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1059.5726 - val_loss: 75.4246\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1059.0044 - val_loss: 75.2971\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1058.3295 - val_loss: 75.1631\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1057.7244 - val_loss: 74.9969\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1057.1447 - val_loss: 74.8763\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1056.5005 - val_loss: 74.7508\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1055.8705 - val_loss: 74.6097\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1055.3007 - val_loss: 74.4483\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1054.6718 - val_loss: 74.3353\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1054.0898 - val_loss: 74.1659\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1053.4769 - val_loss: 74.0586\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1052.8691 - val_loss: 73.9181\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1052.3049 - val_loss: 73.7912\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1051.7025 - val_loss: 73.6616\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1051.1057 - val_loss: 73.5156\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1050.5891 - val_loss: 73.4023\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1049.9397 - val_loss: 73.2760\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1049.3424 - val_loss: 73.1330\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1048.7677 - val_loss: 73.0129\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1048.1600 - val_loss: 72.8932\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1047.5986 - val_loss: 72.7729\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1047.0074 - val_loss: 72.5981\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1046.4462 - val_loss: 72.4780\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1045.8596 - val_loss: 72.3692\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1045.2832 - val_loss: 72.2368\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1044.7081 - val_loss: 72.1170\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1044.1669 - val_loss: 72.0122\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1043.5466 - val_loss: 71.9068\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1042.8600 - val_loss: 71.8989\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1042.2036 - val_loss: 71.7812\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1041.6615 - val_loss: 71.6840\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1041.1216 - val_loss: 71.5825\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1040.5847 - val_loss: 71.4731\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 1040.0654 - val_loss: 71.3662\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1039.5344 - val_loss: 71.2574\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1039.0153 - val_loss: 71.1508\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1038.4877 - val_loss: 71.0109\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1037.9952 - val_loss: 70.9526\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1037.4080 - val_loss: 70.8381\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1036.8844 - val_loss: 70.7498\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1036.3646 - val_loss: 70.6520\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1035.8666 - val_loss: 70.5850\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1035.3119 - val_loss: 70.4856\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Mean Squared Error on Test Data (Stacking with Random Forest): 3.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual file)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "# Columns: State, Year, Avg Temp, Avg Humidity, Total Rainfall, Crop, Season, Area, Production, Annual_Rainfall, Fertilizer, Pesticide, Yield\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train the first neural network (base model 1)\n",
    "model_nn_base_1 = Sequential()\n",
    "model_nn_base_1.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_1.add(Dense(20, activation='relu'))\n",
    "model_nn_base_1.add(Dense(10, activation='relu'))\n",
    "model_nn_base_1.add(Dense(1, activation='linear'))\n",
    "model_nn_base_1.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_1.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the first base neural network model\n",
    "y_pred_nn_base_1 = model_nn_base_1.predict(X_test)\n",
    "\n",
    "# Build and train the second neural network (base model 2)\n",
    "model_nn_base_2 = Sequential()\n",
    "model_nn_base_1.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_1.add(Dense(25, activation='relu'))\n",
    "model_nn_base_1.add(Dense(10, activation='relu'))\n",
    "model_nn_base_1.add(Dense(5, activation='relu'))\n",
    "model_nn_base_2.add(Dense(1, activation='linear'))\n",
    "model_nn_base_2.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_2.fit(X_train, y_train, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the second base neural network model\n",
    "y_pred_nn_base_2 = model_nn_base_2.predict(X_test)\n",
    "\n",
    "# Combine predictions from both base models\n",
    "X_meta_train = np.concatenate((y_pred_nn_base_1, y_pred_nn_base_2), axis=1)\n",
    "\n",
    "# Build and train a Random Forest Regressor as a meta-learner\n",
    "model_rf_meta = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf_meta.fit(X_meta_train, y_test)\n",
    "\n",
    "# Make predictions using the base models and meta-learner\n",
    "X_meta_test = np.concatenate((model_nn_base_1.predict(X_test), model_nn_base_2.predict(X_test)), axis=1)\n",
    "y_pred_stacking_rf = model_rf_meta.predict(X_meta_test)\n",
    "\n",
    "# Evaluate the stacking model with Random Forest as meta-learner\n",
    "mse_stacking_rf = mean_squared_error(y_test, y_pred_stacking_rf)\n",
    "print(f\"Mean Squared Error on Test Data (Stacking with Random Forest): {mse_stacking_rf:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cffbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\3156370774.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 24ms/step - loss: 1201.3926 - val_loss: 117.8040\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1190.8168 - val_loss: 109.4003\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1177.1654 - val_loss: 99.1588\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1157.2921 - val_loss: 85.5275\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1130.7939 - val_loss: 69.7504\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1093.6935 - val_loss: 55.6887\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1050.2024 - val_loss: 47.3948\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1005.5881 - val_loss: 47.1268\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 963.6078 - val_loss: 54.8508\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 930.5067 - val_loss: 62.7983\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 913.9341 - val_loss: 84.3873\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 908.4141 - val_loss: 94.1094\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 901.0526 - val_loss: 91.4671\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 898.3648 - val_loss: 94.3946\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 896.6531 - val_loss: 86.9076\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 895.2713 - val_loss: 96.3026\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 893.8705 - val_loss: 91.0106\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 893.5441 - val_loss: 99.4363\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 891.5048 - val_loss: 98.6430\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 890.1924 - val_loss: 90.5089\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 889.5950 - val_loss: 91.9571\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 891.1689 - val_loss: 81.9264\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 887.5157 - val_loss: 92.2139\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 886.8511 - val_loss: 95.8929\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 885.6996 - val_loss: 97.7587\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 885.8748 - val_loss: 99.2663\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 884.8129 - val_loss: 85.2506\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 883.1888 - val_loss: 90.7017\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 882.5526 - val_loss: 90.4376\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 881.9387 - val_loss: 89.5575\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 880.7094 - val_loss: 89.2219\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 880.2945 - val_loss: 86.1163\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 879.8438 - val_loss: 82.0452\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 878.1447 - val_loss: 91.7528\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 877.4355 - val_loss: 95.0599\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 877.0921 - val_loss: 94.3718\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 875.0529 - val_loss: 89.1106\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 874.1285 - val_loss: 84.4229\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 873.8878 - val_loss: 80.1695\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 873.5183 - val_loss: 90.7017\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 872.0208 - val_loss: 85.5978\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 870.9116 - val_loss: 87.6844\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 869.7913 - val_loss: 85.3480\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 869.9459 - val_loss: 83.5286\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 868.2913 - val_loss: 80.9568\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 869.1896 - val_loss: 74.1673\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 868.2835 - val_loss: 88.2129\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 866.5284 - val_loss: 78.0208\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 864.7309 - val_loss: 84.0588\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 863.8500 - val_loss: 82.4915\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 861.7083 - val_loss: 79.5332\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 861.4877 - val_loss: 75.3927\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 859.1598 - val_loss: 81.0105\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 858.5235 - val_loss: 82.2441\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 858.7078 - val_loss: 88.5372\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 858.7079 - val_loss: 78.9750\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 855.7254 - val_loss: 74.9124\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 852.7886 - val_loss: 81.8667\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 853.4800 - val_loss: 88.1644\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 853.4417 - val_loss: 76.6740\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 849.6667 - val_loss: 88.2292\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 851.1844 - val_loss: 89.2466\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 847.9124 - val_loss: 83.5335\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 848.5619 - val_loss: 78.3389\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 846.5001 - val_loss: 78.7221\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 844.6735 - val_loss: 80.3116\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 844.0883 - val_loss: 82.9211\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 844.4000 - val_loss: 72.1805\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 845.2066 - val_loss: 82.7258\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 842.1700 - val_loss: 73.7053\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 842.5767 - val_loss: 83.9420\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 838.8669 - val_loss: 73.2670\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 838.8016 - val_loss: 72.4495\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 837.6486 - val_loss: 89.9615\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 836.0525 - val_loss: 84.4767\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 835.2354 - val_loss: 73.0452\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 832.3075 - val_loss: 90.0617\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 830.9997 - val_loss: 81.3331\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 831.3090 - val_loss: 85.6644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 829.4324 - val_loss: 74.9429\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 827.9431 - val_loss: 80.7091\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 827.1153 - val_loss: 83.3669\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 825.2661 - val_loss: 80.3855\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 825.5442 - val_loss: 70.1621\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 823.4767 - val_loss: 77.8321\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 823.5929 - val_loss: 69.1535\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 826.0481 - val_loss: 93.4748\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 824.7724 - val_loss: 72.0557\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 818.7413 - val_loss: 75.0187\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 817.8298 - val_loss: 85.5988\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 816.0739 - val_loss: 81.2291\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 814.5191 - val_loss: 77.2018\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 813.7335 - val_loss: 77.5161\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 811.6905 - val_loss: 77.2066\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 812.0695 - val_loss: 76.9838\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 811.2739 - val_loss: 81.8765\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 808.5189 - val_loss: 72.0283\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 807.3663 - val_loss: 71.9683\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 806.4072 - val_loss: 87.7668\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 804.9576 - val_loss: 88.1354\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 807.2467 - val_loss: 78.2367\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 801.6252 - val_loss: 84.0439\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 802.1725 - val_loss: 79.4029\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 804.8965 - val_loss: 72.3803\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 798.8693 - val_loss: 83.7250\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 798.3714 - val_loss: 85.8227\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 798.5216 - val_loss: 78.7839\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 794.1304 - val_loss: 84.1385\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 794.8413 - val_loss: 78.8964\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 796.4603 - val_loss: 89.8999\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 801.1304 - val_loss: 69.2955\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 789.0406 - val_loss: 92.5869\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 791.2721 - val_loss: 90.9112\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 789.9863 - val_loss: 85.3685\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 791.5682 - val_loss: 94.6531\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 785.6246 - val_loss: 81.2471\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 784.9245 - val_loss: 78.1430\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 783.2839 - val_loss: 89.4176\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 782.3301 - val_loss: 81.2289\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 779.6633 - val_loss: 92.2632\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 778.9900 - val_loss: 96.0244\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 777.8317 - val_loss: 84.4081\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 776.9003 - val_loss: 83.2087\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 776.3616 - val_loss: 83.6796\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 772.2848 - val_loss: 88.0400\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 772.0240 - val_loss: 84.9175\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 771.1542 - val_loss: 92.2056\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 771.4442 - val_loss: 99.1493\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 771.3853 - val_loss: 87.5288\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 766.2814 - val_loss: 88.9222\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 766.3409 - val_loss: 87.7417\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 765.7216 - val_loss: 99.1762\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 765.4482 - val_loss: 90.6589\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 761.2898 - val_loss: 88.1418\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 761.8672 - val_loss: 86.4254\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 759.9080 - val_loss: 88.3484\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 757.9932 - val_loss: 95.5336\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 758.1481 - val_loss: 94.2779\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 754.1531 - val_loss: 100.6354\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 753.4767 - val_loss: 99.5126\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 754.8499 - val_loss: 89.1135\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 750.4183 - val_loss: 93.9854\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 749.4447 - val_loss: 102.9734\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 749.2807 - val_loss: 94.0170\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 746.8698 - val_loss: 101.5595\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 745.0403 - val_loss: 91.3062\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 744.2060 - val_loss: 98.6609\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 741.2021 - val_loss: 94.9552\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 741.8320 - val_loss: 91.7128\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 740.4233 - val_loss: 103.3727\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 740.1005 - val_loss: 99.4813\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 736.1052 - val_loss: 104.7676\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 733.8333 - val_loss: 104.2063\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 732.4090 - val_loss: 103.3146\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 742.4069 - val_loss: 90.3176\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 733.0484 - val_loss: 111.2596\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 727.8819 - val_loss: 102.6284\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 729.1163 - val_loss: 106.6820\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 732.1615 - val_loss: 94.8986\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 722.9324 - val_loss: 107.7181\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 725.1441 - val_loss: 106.4144\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 721.5187 - val_loss: 110.9521\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 720.8656 - val_loss: 114.5775\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 718.7025 - val_loss: 111.7351\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 720.3539 - val_loss: 109.8553\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 723.0513 - val_loss: 99.3075\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 714.9124 - val_loss: 109.5895\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 715.4296 - val_loss: 117.2491\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 714.4238 - val_loss: 104.2914\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 713.0136 - val_loss: 119.6820\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 709.6241 - val_loss: 118.4266\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 715.9764 - val_loss: 95.7480\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 703.7160 - val_loss: 108.1605\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 712.3288 - val_loss: 134.5871\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 703.6207 - val_loss: 119.9966\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 705.1798 - val_loss: 121.4838\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 699.9468 - val_loss: 116.8486\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 698.2300 - val_loss: 115.4568\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 700.0662 - val_loss: 112.9021\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 696.4667 - val_loss: 106.1006\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 696.5979 - val_loss: 119.5919\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 690.9186 - val_loss: 114.9871\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 691.9728 - val_loss: 121.3831\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 693.1011 - val_loss: 110.6051\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 687.9468 - val_loss: 115.7178\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 685.4653 - val_loss: 119.2167\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 684.4453 - val_loss: 122.2685\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 682.4719 - val_loss: 125.5205\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 690.5588 - val_loss: 99.0081\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 676.3679 - val_loss: 134.2400\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 679.1633 - val_loss: 130.2303\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 684.8611 - val_loss: 109.7433\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 673.3900 - val_loss: 147.3612\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 683.9199 - val_loss: 130.2031\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 672.4522 - val_loss: 128.5196\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 675.7012 - val_loss: 117.8992\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 671.0815 - val_loss: 113.3922\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 663.9489 - val_loss: 127.1441\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 672.1285 - val_loss: 138.1253\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 663.2161 - val_loss: 128.7508\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 15ms/step - loss: 1088.5526 - val_loss: 112.0436\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 1065.1536 - val_loss: 90.3817\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 1017.3058 - val_loss: 55.9267\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 932.9539 - val_loss: 43.6556\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 866.7505 - val_loss: 62.1515\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 834.6204 - val_loss: 74.8767\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 826.5569 - val_loss: 77.6421\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 822.2400 - val_loss: 75.0215\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 818.1780 - val_loss: 79.0611\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 814.0020 - val_loss: 74.3453\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 813.7673 - val_loss: 63.1326\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 810.2327 - val_loss: 85.0371\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 809.7283 - val_loss: 88.2154\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 810.1473 - val_loss: 74.3368\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 808.1695 - val_loss: 86.0247\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 806.8096 - val_loss: 76.4304\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 805.0616 - val_loss: 79.7709\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 805.2231 - val_loss: 76.4312\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 805.5638 - val_loss: 78.0241\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 803.1019 - val_loss: 65.5443\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 800.5138 - val_loss: 82.4420\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 800.7580 - val_loss: 81.4611\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 802.2917 - val_loss: 73.7505\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 802.2642 - val_loss: 79.7171\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 797.3370 - val_loss: 73.9534\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 797.8306 - val_loss: 68.4914\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 796.5435 - val_loss: 76.5348\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 795.7024 - val_loss: 64.2485\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 794.5210 - val_loss: 79.7848\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 793.0143 - val_loss: 74.0771\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 791.5831 - val_loss: 72.5493\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 791.0842 - val_loss: 67.7037\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 790.2662 - val_loss: 72.5556\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 788.2618 - val_loss: 66.1095\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 789.0386 - val_loss: 71.7302\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 790.3220 - val_loss: 60.6598\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 787.5405 - val_loss: 76.5938\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 784.0702 - val_loss: 72.4400\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 784.7120 - val_loss: 66.1583\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 782.3664 - val_loss: 68.6043\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 783.8153 - val_loss: 69.7345\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 780.6460 - val_loss: 68.5618\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 780.2470 - val_loss: 65.1842\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 777.0737 - val_loss: 66.8965\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 777.3328 - val_loss: 53.6191\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 780.1505 - val_loss: 63.8004\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 774.9532 - val_loss: 57.8522\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 770.9170 - val_loss: 64.7612\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 770.5884 - val_loss: 71.8436\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 770.3954 - val_loss: 60.0954\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 767.6302 - val_loss: 61.9412\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 767.3256 - val_loss: 59.8923\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 765.2661 - val_loss: 57.4053\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 763.1755 - val_loss: 51.8658\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 760.1729 - val_loss: 67.5081\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 761.1246 - val_loss: 53.4923\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 758.3523 - val_loss: 67.7523\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 757.5316 - val_loss: 62.4530\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 754.0747 - val_loss: 54.4020\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 752.5732 - val_loss: 62.0714\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 753.4362 - val_loss: 57.3464\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 754.6879 - val_loss: 54.8260\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 748.9562 - val_loss: 52.0877\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 749.3464 - val_loss: 50.3726\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 746.1068 - val_loss: 69.0224\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 742.1975 - val_loss: 60.3879\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 741.7318 - val_loss: 64.3969\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 739.9789 - val_loss: 61.3208\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 738.9993 - val_loss: 59.8820\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 737.0262 - val_loss: 45.7231\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 731.7065 - val_loss: 66.5514\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 735.1057 - val_loss: 68.3407\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 730.7665 - val_loss: 55.7236\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 730.0385 - val_loss: 52.0000\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 728.4370 - val_loss: 62.4338\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 729.5736 - val_loss: 67.8231\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 726.1324 - val_loss: 53.5266\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 730.8583 - val_loss: 64.9935\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 727.2972 - val_loss: 54.7662\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 721.0889 - val_loss: 64.1723\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 715.9457 - val_loss: 56.1018\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 716.6130 - val_loss: 58.1197\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 715.1080 - val_loss: 65.0621\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 715.2320 - val_loss: 68.6457\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 710.5805 - val_loss: 67.4507\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 712.4754 - val_loss: 55.9157\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 706.6182 - val_loss: 69.7011\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 710.3549 - val_loss: 64.0254\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 709.9440 - val_loss: 54.3095\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 705.3010 - val_loss: 61.6346\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 701.5151 - val_loss: 54.5970\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 698.9289 - val_loss: 54.7057\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 697.8012 - val_loss: 60.6872\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 696.4274 - val_loss: 60.7822\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 693.6714 - val_loss: 62.0062\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 692.6516 - val_loss: 53.2610\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 686.3624 - val_loss: 55.0461\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 686.1161 - val_loss: 65.6733\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 684.6110 - val_loss: 59.3654\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 677.2449 - val_loss: 65.7894\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 682.0029 - val_loss: 72.8130\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 676.1540 - val_loss: 56.2404\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 671.6478 - val_loss: 58.9797\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 678.3444 - val_loss: 66.2819\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 666.0494 - val_loss: 54.0103\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 667.8616 - val_loss: 57.4004\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 662.0867 - val_loss: 59.4839\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 663.8641 - val_loss: 46.0030\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 663.3150 - val_loss: 62.0275\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 663.5004 - val_loss: 66.3153\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 653.7244 - val_loss: 67.9411\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 645.6537 - val_loss: 56.7524\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 647.5486 - val_loss: 65.3751\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 646.4829 - val_loss: 53.2262\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 639.9758 - val_loss: 69.7228\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 641.0948 - val_loss: 62.1456\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 639.9944 - val_loss: 57.4146\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 636.1053 - val_loss: 50.4174\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 630.0912 - val_loss: 53.9458\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 622.7021 - val_loss: 67.0777\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 623.8124 - val_loss: 69.4960\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 622.9496 - val_loss: 64.2449\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 614.3282 - val_loss: 48.1126\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 612.8322 - val_loss: 59.8893\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 616.7580 - val_loss: 54.0970\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 604.5503 - val_loss: 65.9530\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 601.2795 - val_loss: 63.9160\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 599.6555 - val_loss: 68.3686\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 590.4623 - val_loss: 58.8472\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 587.0577 - val_loss: 44.6586\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 582.4183 - val_loss: 49.3534\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 580.8802 - val_loss: 52.3249\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 575.7433 - val_loss: 40.2456\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 566.6731 - val_loss: 53.9180\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 572.5231 - val_loss: 47.5542\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 562.8765 - val_loss: 41.2709\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 563.2763 - val_loss: 43.4316\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 560.8718 - val_loss: 43.3647\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 543.2916 - val_loss: 31.4050\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 545.5677 - val_loss: 53.0669\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 541.1226 - val_loss: 51.1758\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 531.2222 - val_loss: 42.9535\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 527.0018 - val_loss: 42.5451\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 523.7838 - val_loss: 37.7708\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 513.4402 - val_loss: 41.4457\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 517.4832 - val_loss: 35.4736\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 505.5212 - val_loss: 30.7042\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 499.4227 - val_loss: 36.1656\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 496.1510 - val_loss: 40.5274\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 497.3126 - val_loss: 35.6822\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 481.0952 - val_loss: 29.4964\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 480.6448 - val_loss: 31.5632\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 472.8726 - val_loss: 27.8318\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 470.8503 - val_loss: 24.3770\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 467.8624 - val_loss: 36.5103\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 454.9943 - val_loss: 24.0390\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 448.0475 - val_loss: 30.9698\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 447.7109 - val_loss: 25.2310\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 454.1756 - val_loss: 35.7457\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 441.4443 - val_loss: 29.1805\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 426.5275 - val_loss: 25.0452\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 430.4378 - val_loss: 24.6653\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 423.3003 - val_loss: 26.4709\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 416.5272 - val_loss: 30.4082\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 415.7257 - val_loss: 29.2297\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 403.5694 - val_loss: 27.5504\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 403.7253 - val_loss: 24.0507\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 391.0212 - val_loss: 27.9453\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 400.8596 - val_loss: 26.0706\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 379.7155 - val_loss: 26.7019\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 380.8904 - val_loss: 30.1859\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 369.1451 - val_loss: 26.4807\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 365.0280 - val_loss: 25.3765\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 362.6009 - val_loss: 27.4990\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 348.4855 - val_loss: 24.6923\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 348.4727 - val_loss: 22.8990\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 348.1901 - val_loss: 26.6390\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 344.7904 - val_loss: 29.2997\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 325.7571 - val_loss: 22.9331\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 324.9482 - val_loss: 24.2578\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 337.2005 - val_loss: 26.3681\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 326.5319 - val_loss: 24.8881\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 308.7240 - val_loss: 25.8430\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 319.7892 - val_loss: 29.3672\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 315.8407 - val_loss: 24.1609\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 301.9465 - val_loss: 24.6150\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 297.1022 - val_loss: 23.5501\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 280.6727 - val_loss: 27.2241\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 275.7012 - val_loss: 24.6007\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 277.6893 - val_loss: 30.7562\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 294.2949 - val_loss: 31.4961\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 277.7852 - val_loss: 32.9002\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 268.7772 - val_loss: 32.5946\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 267.6241 - val_loss: 25.5883\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 250.4355 - val_loss: 27.7492\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 260.9572 - val_loss: 24.7728\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 254.8593 - val_loss: 22.5158\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 255.1603 - val_loss: 24.3303\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 244.4086 - val_loss: 24.5019\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 244.0135 - val_loss: 27.8927\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 7ms/step - loss: 572.2690\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 284.2482\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 234.6753\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 210.9115\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 181.3773\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 221.2324\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 200.4331\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 191.1093\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 229.5116\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 230.8365\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 180.5210\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 213.7595\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 205.7997\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.9197\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 176.2649\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 209.2942\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 179.6461\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 151.6735\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 188.6180\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 207.8609\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.5589\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.8452\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 189.6876\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 218.2731\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 194.6938\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 214.3651\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 174.0692\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 157.7870\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 175.7070\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 169.2333\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 143.8941\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.2518\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 187.0946\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 190.3930\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 142.1814\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 135.0459\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.6323\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 189.3458\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 226.6419\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 227.7559\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 227.2440\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 157.9656\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 165.1642\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 155.5200\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 142.4843\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 177.2901\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 170.3495\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 167.9665\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 160.6893\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 166.9494\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 231.3121\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 255.3486\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 170.4946\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 212.7508\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.9654\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 168.3360\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 147.6034\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 137.2175\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 181.6719\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 198.6839\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 142.5981\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 154.0627\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 135.7415\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 179.8987\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 164.9094\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 193.0257\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 231.4490\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 148.7425\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 154.9808\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 152.1735\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.4719\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 141.9865\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 176.8395\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 140.7078\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.8317\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 168.3993\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 147.7373\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 143.0762\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 151.4345\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.3962\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 139.2984\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 178.1946\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 150.9513\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 171.1249\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 171.7616\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 144.5063\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 133.3163\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 142.9107\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 150.1051\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 128.9679\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 212.7072\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 168.7925\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 152.1504\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 198.6002\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 154.5961\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 138.7377\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.0842\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 159.4521\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 142.2685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 157.6641\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 144.0323\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 137.8695\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 162.1824\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 129.3731\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 162.1195\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 147.7434\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 175.8675\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 193.8720\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 160.3114\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 136.6902\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 131.8927\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 156.5439\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.9001\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 162.1429\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 144.8348\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 163.4535\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 210.5244\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 157.1421\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 134.9631\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 138.1709\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 160.8880\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 140.6215\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 181.1259\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 200.3500\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 282.2604\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 156.7995\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 133.0010\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 164.4712\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 165.5274\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 145.8146\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 159.9972\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 148.9097\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 164.8488\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 152.5978\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 168.8545\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 130.9193\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 134.9258\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 173.0464\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 163.2574\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 177.2220\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 146.7795\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 177.7959\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 155.6838\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 171.2359\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 175.8356\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 139.9970\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 147.3206\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 215.5945\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 171.2139\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 177.0728\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.0332\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 129.7274\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 142.2741\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 139.7968\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 147.1620\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 178.0594\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.3893\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 132.7304\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 140.8982\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 206.2207\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 197.6996\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 181.5476\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 137.8535\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.1058\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 148.9563\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 181.3025\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 132.7642\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.6072\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 174.0275\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 142.8817\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 140.3076\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.2938\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 143.6631\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 164.4210\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 130.3583\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 129.6902\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 149.5132\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 136.6045\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 147.2404\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 179.8334\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 155.7042\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 152.3511\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 134.9223\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 138.5298\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 163.0029\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 151.9629\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 129.6351\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 143.6644\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 152.7180\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 144.2142\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 128.1017\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 139.6593\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 148.2773\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 140.6135\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 124.1428\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 155.1715\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 153.9563\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 158.4978\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 147.5323\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 161.3622\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "Root Mean Squared Error on Entire Data (Stacking with Neural Network): 11.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train the first neural network (base model 1)\n",
    "model_nn_base_1 = Sequential()\n",
    "model_nn_base_1.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_1.add(Dense(20, activation='relu'))\n",
    "model_nn_base_1.add(Dense(10, activation='relu'))\n",
    "model_nn_base_1.add(Dense(1, activation='linear'))\n",
    "model_nn_base_1.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_1.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the first base neural network model\n",
    "y_pred_nn_base_1 = model_nn_base_1.predict(X)\n",
    "\n",
    "# Build and train the second neural network (base model 2)\n",
    "model_nn_base_2 = Sequential()\n",
    "model_nn_base_2.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_2.add(Dense(25, activation='relu'))\n",
    "model_nn_base_2.add(Dense(10, activation='relu'))\n",
    "model_nn_base_2.add(Dense(5, activation='relu'))\n",
    "model_nn_base_2.add(Dense(1, activation='linear'))\n",
    "model_nn_base_2.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_2.fit(X, y, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the second base neural network model\n",
    "y_pred_nn_base_2 = model_nn_base_2.predict(X)\n",
    "\n",
    "# Combine predictions from both base models\n",
    "X_meta_train = np.concatenate((y_pred_nn_base_1, y_pred_nn_base_2), axis=1)\n",
    "\n",
    "# Build and train the meta neural network\n",
    "model_nn_meta = Sequential()\n",
    "model_nn_meta.add(Dense(200, activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "model_nn_meta.add(Dense(100, activation='relu'))\n",
    "model_nn_meta.add(Dense(50, activation='relu'))\n",
    "model_nn_meta.add(Dense(1, activation='linear'))\n",
    "model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_meta.fit(X_meta_train, y, epochs=200, batch_size=10)\n",
    "\n",
    "# Make predictions using the base models and meta-learner on the entire dataset\n",
    "X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "# Evaluate the stacking model with Neural Network as meta-learner on the entire dataset\n",
    "rmse_stacking_nn = np.sqrt(mean_squared_error(y, y_pred_stacking_nn))\n",
    "print(f\"Root Mean Squared Error on Entire Data (Stacking with Neural Network): {rmse_stacking_nn:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140b9f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:05,569] A new study created in memory with name: no-name-9ce6287f-3303-4257-b29b-f7b4212ef5ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:19,740] Trial 0 finished with value: 8.46342292661361 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 35, 'num_neurons_layer_1': 62, 'num_neurons_layer_2': 7, 'num_neurons_layer_3': 153, 'num_neurons_layer_4': 161, 'num_epochs': 463, 'batch_size': 27}. Best is trial 0 with value: 8.46342292661361.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:22,020] Trial 1 finished with value: 11.445823649867089 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 145, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 50, 'num_neurons_layer_3': 74, 'num_neurons_layer_4': 103, 'num_epochs': 65, 'batch_size': 33}. Best is trial 0 with value: 8.46342292661361.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:26,215] Trial 2 finished with value: 11.582808309803147 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 67, 'num_neurons_layer_1': 26, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 83, 'num_epochs': 127, 'batch_size': 25}. Best is trial 0 with value: 8.46342292661361.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:29,328] Trial 3 finished with value: 11.255419571887638 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 59, 'num_neurons_layer_1': 160, 'num_epochs': 154, 'batch_size': 35}. Best is trial 0 with value: 8.46342292661361.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:41,127] Trial 4 finished with value: 7.753837115778348 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 57, 'num_neurons_layer_1': 150, 'num_neurons_layer_2': 49, 'num_neurons_layer_3': 168, 'num_epochs': 464, 'batch_size': 32}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:49,932] Trial 5 finished with value: 10.261833277516624 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 184, 'num_neurons_layer_1': 85, 'num_neurons_layer_2': 38, 'num_neurons_layer_3': 191, 'num_epochs': 410, 'batch_size': 36}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:52,013] Trial 6 finished with value: 11.464633619436498 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 143, 'num_neurons_layer_2': 105, 'num_epochs': 91, 'batch_size': 40}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:56,176] Trial 7 finished with value: 10.850531056038667 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 144, 'num_neurons_layer_1': 87, 'num_epochs': 283, 'batch_size': 48}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:46:58,790] Trial 8 finished with value: 12.060581302330071 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 63, 'num_epochs': 137, 'batch_size': 39}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:47:07,480] Trial 9 finished with value: 11.209065651477674 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 174, 'num_neurons_layer_2': 123, 'num_neurons_layer_3': 97, 'num_epochs': 138, 'batch_size': 12}. Best is trial 4 with value: 7.753837115778348.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 810us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:47:22,505] Trial 10 finished with value: 6.3925477531499855 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 7, 'num_neurons_layer_1': 127, 'num_neurons_layer_2': 154, 'num_epochs': 346, 'batch_size': 15}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 967us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:47:37,870] Trial 11 finished with value: 10.586370513961427 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 8, 'num_neurons_layer_1': 135, 'num_neurons_layer_2': 191, 'num_epochs': 360, 'batch_size': 15}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:48:13,888] Trial 12 finished with value: 10.876984616595491 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 198, 'num_neurons_layer_2': 158, 'num_epochs': 327, 'batch_size': 6}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:48:29,136] Trial 13 finished with value: 11.192368107885883 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 99, 'num_neurons_layer_1': 118, 'num_epochs': 480, 'batch_size': 20}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:48:43,770] Trial 14 finished with value: 11.007426200341587 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 8, 'num_neurons_layer_1': 115, 'num_neurons_layer_2': 141, 'num_neurons_layer_3': 160, 'num_epochs': 402, 'batch_size': 21}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:49:12,473] Trial 15 finished with value: 10.527774079639542 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 179, 'num_neurons_layer_2': 85, 'num_neurons_layer_3': 5, 'num_neurons_layer_4': 12, 'num_epochs': 227, 'batch_size': 6}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:49:18,789] Trial 16 finished with value: 11.404371213529814 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 104, 'num_epochs': 430, 'batch_size': 46}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:49:25,081] Trial 17 finished with value: 11.065447696726876 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 43, 'num_neurons_layer_1': 144, 'num_neurons_layer_2': 188, 'num_neurons_layer_3': 138, 'num_epochs': 236, 'batch_size': 30}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:49:42,631] Trial 18 finished with value: 11.036776792369793 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 87, 'num_neurons_layer_1': 41, 'num_neurons_layer_2': 5, 'num_epochs': 355, 'batch_size': 14}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:49:58,747] Trial 19 finished with value: 10.98617465169325 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 23, 'num_neurons_layer_1': 110, 'num_epochs': 493, 'batch_size': 21}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:50:18,710] Trial 20 finished with value: 10.71152419274944 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 130, 'num_neurons_layer_1': 132, 'num_neurons_layer_2': 150, 'num_epochs': 297, 'batch_size': 10}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:50:31,554] Trial 21 finished with value: 10.748263121084063 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 30, 'num_neurons_layer_1': 61, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 147, 'num_neurons_layer_4': 200, 'num_epochs': 458, 'batch_size': 28}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:50:46,609] Trial 22 finished with value: 10.164605248347454 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 46, 'num_neurons_layer_2': 28, 'num_neurons_layer_3': 199, 'num_neurons_layer_4': 170, 'num_epochs': 447, 'batch_size': 25}. Best is trial 10 with value: 6.3925477531499855.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:50:57,182] Trial 23 finished with value: 5.757719775211403 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 18, 'num_neurons_layer_1': 97, 'num_neurons_layer_2': 53, 'num_neurons_layer_3': 128, 'num_neurons_layer_4': 128, 'num_epochs': 379, 'batch_size': 30}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:06,277] Trial 24 finished with value: 10.867797252129058 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 5, 'num_neurons_layer_1': 95, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 121, 'num_epochs': 383, 'batch_size': 31}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:12,787] Trial 25 finished with value: 10.798025651439627 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 162, 'num_neurons_layer_2': 86, 'num_neurons_layer_3': 171, 'num_epochs': 328, 'batch_size': 43}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:25,041] Trial 26 finished with value: 10.941814340028461 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 86, 'num_neurons_layer_1': 103, 'num_neurons_layer_2': 78, 'num_neurons_layer_3': 118, 'num_neurons_layer_4': 100, 'num_epochs': 240, 'batch_size': 17}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:33,328] Trial 27 finished with value: 10.885759890500001 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 51, 'num_neurons_layer_1': 127, 'num_neurons_layer_2': 104, 'num_neurons_layer_3': 51, 'num_epochs': 379, 'batch_size': 38}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:44,161] Trial 28 finished with value: 9.08678592745513 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 197, 'num_neurons_layer_1': 154, 'num_neurons_layer_2': 45, 'num_neurons_layer_3': 171, 'num_neurons_layer_4': 98, 'num_epochs': 328, 'batch_size': 24}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:51:55,960] Trial 29 finished with value: 10.562607733026544 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 34, 'num_neurons_layer_1': 192, 'num_neurons_layer_2': 171, 'num_neurons_layer_3': 123, 'num_neurons_layer_4': 44, 'num_epochs': 421, 'batch_size': 28}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:06,416] Trial 30 finished with value: 7.611286707648195 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 126, 'num_neurons_layer_2': 126, 'num_epochs': 462, 'batch_size': 32}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:16,692] Trial 31 finished with value: 6.994926740512227 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 72, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 129, 'num_epochs': 458, 'batch_size': 32}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:27,541] Trial 32 finished with value: 10.040225973325152 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 86, 'num_neurons_layer_1': 122, 'num_neurons_layer_2': 126, 'num_epochs': 500, 'batch_size': 33}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:34,561] Trial 33 finished with value: 11.072868153952342 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 98, 'num_epochs': 384, 'batch_size': 35}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:45,654] Trial 34 finished with value: 10.571943546137748 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 74, 'num_neurons_layer_2': 127, 'num_epochs': 426, 'batch_size': 27}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:52:53,472] Trial 35 finished with value: 10.85229352919929 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 113, 'num_neurons_layer_2': 172, 'num_epochs': 448, 'batch_size': 42}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:01,145] Trial 36 finished with value: 12.92724179717875 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 158, 'num_neurons_layer_1': 134, 'num_epochs': 351, 'batch_size': 30}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:12,142] Trial 37 finished with value: 10.307196359210872 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 5, 'num_neurons_layer_2': 139, 'num_epochs': 402, 'batch_size': 24}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:15,859] Trial 38 finished with value: 11.216528971022505 and parameters: {'num_hidden_layers': 2, 'num_neurons_layer_0': 54, 'num_neurons_layer_1': 82, 'num_epochs': 189, 'batch_size': 35}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:22,448] Trial 39 finished with value: 10.825338026114114 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 129, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 119, 'num_epochs': 305, 'batch_size': 37}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:32,650] Trial 40 finished with value: 9.744211807115422 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 70, 'num_neurons_layer_1': 166, 'num_neurons_layer_2': 112, 'num_epochs': 474, 'batch_size': 33}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:43,094] Trial 41 finished with value: 7.547443453673386 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 62, 'num_neurons_layer_1': 148, 'num_neurons_layer_2': 94, 'num_neurons_layer_3': 54, 'num_epochs': 465, 'batch_size': 32}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:53:53,500] Trial 42 finished with value: 10.790581031903988 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 144, 'num_neurons_layer_2': 96, 'num_neurons_layer_3': 37, 'num_epochs': 439, 'batch_size': 33}. Best is trial 23 with value: 5.757719775211403.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:05,294] Trial 43 finished with value: 5.487567173415717 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 123, 'num_neurons_layer_2': 141, 'num_neurons_layer_3': 54, 'num_epochs': 468, 'batch_size': 28}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:18,768] Trial 44 finished with value: 10.338014238210281 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 150, 'num_neurons_layer_2': 156, 'num_neurons_layer_3': 54, 'num_epochs': 480, 'batch_size': 26}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:28,864] Trial 45 finished with value: 10.968496650535034 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 93, 'num_neurons_layer_2': 139, 'num_neurons_layer_3': 18, 'num_epochs': 403, 'batch_size': 29}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:31,341] Trial 46 finished with value: 11.599994104873945 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 134, 'num_neurons_layer_2': 170, 'num_neurons_layer_3': 72, 'num_epochs': 55, 'batch_size': 23}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:48,003] Trial 47 finished with value: 10.630724818354004 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 39, 'num_neurons_layer_1': 107, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 98, 'num_neurons_layer_4': 135, 'num_epochs': 372, 'batch_size': 18}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:54:56,886] Trial 48 finished with value: 10.754781825458656 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 59, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 149, 'num_neurons_layer_3': 35, 'num_epochs': 417, 'batch_size': 39}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:55:35,791] Trial 49 finished with value: 8.701648625867993 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 12, 'num_neurons_layer_1': 170, 'num_neurons_layer_2': 95, 'num_neurons_layer_3': 60, 'num_neurons_layer_4': 58, 'num_epochs': 476, 'batch_size': 9}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:55:50,533] Trial 50 finished with value: 5.839745438279439 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 26, 'num_neurons_layer_1': 156, 'num_neurons_layer_2': 70, 'num_neurons_layer_3': 33, 'num_epochs': 440, 'batch_size': 22}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:56:06,935] Trial 51 finished with value: 10.49903252529271 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 26, 'num_neurons_layer_1': 156, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 33, 'num_epochs': 440, 'batch_size': 19}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:56:19,970] Trial 52 finished with value: 10.810600391704071 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 43, 'num_neurons_layer_1': 138, 'num_neurons_layer_2': 72, 'num_neurons_layer_3': 16, 'num_epochs': 453, 'batch_size': 26}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:56:35,101] Trial 53 finished with value: 8.151080340852566 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 26, 'num_neurons_layer_1': 146, 'num_neurons_layer_2': 37, 'num_epochs': 491, 'batch_size': 22}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:56:51,840] Trial 54 finished with value: 10.176374126900194 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 13, 'num_neurons_layer_1': 183, 'num_neurons_layer_2': 58, 'num_epochs': 401, 'batch_size': 16}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:56:56,374] Trial 55 finished with value: 11.30454260583926 and parameters: {'num_hidden_layers': 4, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 115, 'num_neurons_layer_2': 113, 'num_neurons_layer_3': 45, 'num_epochs': 83, 'batch_size': 14}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:05,053] Trial 56 finished with value: 10.364756188878628 and parameters: {'num_hidden_layers': 3, 'num_neurons_layer_0': 5, 'num_neurons_layer_1': 126, 'num_neurons_layer_2': 90, 'num_epochs': 344, 'batch_size': 30}. Best is trial 43 with value: 5.487567173415717.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:15,799] Trial 57 finished with value: 5.318341076451306 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 141, 'num_neurons_layer_2': 137, 'num_neurons_layer_3': 65, 'num_neurons_layer_4': 130, 'num_epochs': 466, 'batch_size': 36}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:24,560] Trial 58 finished with value: 5.319555435948101 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 139, 'num_neurons_layer_2': 135, 'num_neurons_layer_3': 80, 'num_neurons_layer_4': 132, 'num_epochs': 429, 'batch_size': 41}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:30,414] Trial 59 finished with value: 11.453939491945663 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 21, 'num_neurons_layer_1': 177, 'num_neurons_layer_2': 163, 'num_neurons_layer_3': 82, 'num_neurons_layer_4': 136, 'num_epochs': 266, 'batch_size': 45}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:38,617] Trial 60 finished with value: 5.561822978670749 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 34, 'num_neurons_layer_1': 139, 'num_neurons_layer_2': 135, 'num_neurons_layer_3': 66, 'num_neurons_layer_4': 129, 'num_epochs': 392, 'batch_size': 42}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:46,595] Trial 61 finished with value: 6.839004563640728 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 138, 'num_neurons_layer_2': 149, 'num_neurons_layer_3': 77, 'num_neurons_layer_4': 125, 'num_epochs': 391, 'batch_size': 41}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:53,395] Trial 62 finished with value: 5.554394342382477 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 159, 'num_neurons_layer_2': 136, 'num_neurons_layer_3': 67, 'num_neurons_layer_4': 122, 'num_epochs': 365, 'batch_size': 48}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:57:59,982] Trial 63 finished with value: 10.766908640870348 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 31, 'num_neurons_layer_1': 158, 'num_neurons_layer_2': 143, 'num_neurons_layer_3': 68, 'num_neurons_layer_4': 129, 'num_epochs': 364, 'batch_size': 48}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:08,955] Trial 64 finished with value: 10.17246962548267 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 47, 'num_neurons_layer_1': 163, 'num_neurons_layer_2': 135, 'num_neurons_layer_3': 88, 'num_neurons_layer_4': 154, 'num_epochs': 430, 'batch_size': 44}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:16,497] Trial 65 finished with value: 10.986134742772618 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 26, 'num_neurons_layer_1': 141, 'num_neurons_layer_2': 114, 'num_neurons_layer_3': 60, 'num_neurons_layer_4': 117, 'num_epochs': 415, 'batch_size': 48}. Best is trial 57 with value: 5.318341076451306.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:24,473] Trial 66 finished with value: 5.296311320317001 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 38, 'num_neurons_layer_1': 155, 'num_neurons_layer_2': 131, 'num_neurons_layer_3': 67, 'num_neurons_layer_4': 148, 'num_epochs': 436, 'batch_size': 50}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:31,733] Trial 67 finished with value: 6.209349194166231 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 41, 'num_neurons_layer_1': 131, 'num_neurons_layer_2': 131, 'num_neurons_layer_3': 66, 'num_neurons_layer_4': 145, 'num_epochs': 388, 'batch_size': 50}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:37,411] Trial 68 finished with value: 5.700606929950681 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 149, 'num_neurons_layer_2': 118, 'num_neurons_layer_3': 86, 'num_neurons_layer_4': 113, 'num_epochs': 308, 'batch_size': 50}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:44,433] Trial 69 finished with value: 9.781373874359941 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 55, 'num_neurons_layer_1': 172, 'num_neurons_layer_2': 119, 'num_neurons_layer_3': 88, 'num_neurons_layer_4': 111, 'num_epochs': 333, 'batch_size': 46}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:50,347] Trial 70 finished with value: 10.984587568261986 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 152, 'num_neurons_layer_2': 146, 'num_neurons_layer_3': 104, 'num_neurons_layer_4': 86, 'num_epochs': 303, 'batch_size': 50}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:58:55,965] Trial 71 finished with value: 10.5788217712603 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 183, 'num_neurons_layer_2': 134, 'num_neurons_layer_3': 76, 'num_neurons_layer_4': 120, 'num_epochs': 271, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:03,796] Trial 72 finished with value: 11.147913963286658 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 12, 'num_neurons_layer_1': 145, 'num_neurons_layer_2': 105, 'num_neurons_layer_3': 65, 'num_neurons_layer_4': 142, 'num_epochs': 366, 'batch_size': 43}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:09,686] Trial 73 finished with value: 10.900080461161659 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 17, 'num_neurons_layer_1': 162, 'num_neurons_layer_2': 161, 'num_neurons_layer_3': 91, 'num_neurons_layer_4': 126, 'num_epochs': 313, 'batch_size': 49}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:15,862] Trial 74 finished with value: 11.050498171408561 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 131, 'num_neurons_layer_2': 121, 'num_neurons_layer_3': 105, 'num_neurons_layer_4': 147, 'num_epochs': 285, 'batch_size': 40}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:23,298] Trial 75 finished with value: 10.660430396657624 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 168, 'num_neurons_layer_2': 134, 'num_neurons_layer_3': 78, 'num_neurons_layer_4': 168, 'num_epochs': 341, 'batch_size': 45}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:31,689] Trial 76 finished with value: 9.917421710671247 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 10, 'num_neurons_layer_1': 139, 'num_neurons_layer_2': 143, 'num_neurons_layer_3': 45, 'num_neurons_layer_4': 115, 'num_epochs': 410, 'batch_size': 42}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:40,640] Trial 77 finished with value: 11.58170078981228 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 29, 'num_neurons_layer_1': 90, 'num_neurons_layer_2': 109, 'num_neurons_layer_3': 133, 'num_neurons_layer_4': 134, 'num_epochs': 431, 'batch_size': 46}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:50,113] Trial 78 finished with value: 10.830651818191551 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 38, 'num_neurons_layer_1': 150, 'num_neurons_layer_2': 124, 'num_neurons_layer_3': 112, 'num_neurons_layer_4': 85, 'num_epochs': 377, 'batch_size': 38}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 22:59:56,952] Trial 79 finished with value: 10.962108751167165 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 22, 'num_neurons_layer_1': 83, 'num_neurons_layer_2': 137, 'num_neurons_layer_3': 59, 'num_neurons_layer_4': 155, 'num_epochs': 254, 'batch_size': 36}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 917us/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:01,245] Trial 80 finished with value: 11.096628324078205 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 18, 'num_neurons_layer_1': 111, 'num_neurons_layer_2': 18, 'num_neurons_layer_3': 69, 'num_neurons_layer_4': 113, 'num_epochs': 211, 'batch_size': 49}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:09,147] Trial 81 finished with value: 5.356485552494163 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 27, 'num_neurons_layer_1': 155, 'num_neurons_layer_2': 130, 'num_neurons_layer_3': 81, 'num_neurons_layer_4': 160, 'num_epochs': 440, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:17,688] Trial 82 finished with value: 10.901134875352838 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 33, 'num_neurons_layer_1': 153, 'num_neurons_layer_2': 153, 'num_neurons_layer_3': 85, 'num_neurons_layer_4': 175, 'num_epochs': 465, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:27,899] Trial 83 finished with value: 10.790160272858115 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 49, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 130, 'num_neurons_layer_3': 94, 'num_neurons_layer_4': 152, 'num_epochs': 490, 'batch_size': 44}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 815us/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:35,190] Trial 84 finished with value: 10.859327341719533 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 29, 'num_neurons_layer_1': 142, 'num_neurons_layer_2': 119, 'num_neurons_layer_3': 47, 'num_neurons_layer_4': 137, 'num_epochs': 398, 'batch_size': 50}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:44,366] Trial 85 finished with value: 9.42392703757974 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 22, 'num_neurons_layer_1': 160, 'num_neurons_layer_2': 141, 'num_neurons_layer_3': 75, 'num_neurons_layer_4': 126, 'num_epochs': 447, 'batch_size': 41}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:52,017] Trial 86 finished with value: 5.363951009758861 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 15, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 64, 'num_neurons_layer_4': 180, 'num_epochs': 422, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:00:59,772] Trial 87 finished with value: 10.16705561323822 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 9, 'num_neurons_layer_1': 117, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 62, 'num_neurons_layer_4': 182, 'num_epochs': 423, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:07,750] Trial 88 finished with value: 9.31145635205966 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 122, 'num_neurons_layer_2': 116, 'num_neurons_layer_3': 83, 'num_neurons_layer_4': 178, 'num_epochs': 464, 'batch_size': 49}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:15,928] Trial 89 finished with value: 11.12250206261366 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 52, 'num_neurons_layer_1': 131, 'num_neurons_layer_2': 101, 'num_neurons_layer_3': 54, 'num_neurons_layer_4': 191, 'num_epochs': 413, 'batch_size': 45}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:25,348] Trial 90 finished with value: 11.341371061757997 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 14, 'num_neurons_layer_1': 137, 'num_neurons_layer_2': 124, 'num_neurons_layer_3': 73, 'num_neurons_layer_4': 158, 'num_epochs': 434, 'batch_size': 43}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:31,840] Trial 91 finished with value: 9.309652791105536 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 167, 'num_neurons_layer_1': 147, 'num_neurons_layer_2': 132, 'num_neurons_layer_3': 70, 'num_neurons_layer_4': 102, 'num_epochs': 357, 'batch_size': 48}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:43,512] Trial 92 finished with value: 5.8638407263862655 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 108, 'num_neurons_layer_2': 148, 'num_neurons_layer_3': 156, 'num_neurons_layer_4': 141, 'num_epochs': 449, 'batch_size': 34}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:51,908] Trial 93 finished with value: 6.176181102210358 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 18, 'num_neurons_layer_1': 165, 'num_neurons_layer_2': 139, 'num_neurons_layer_3': 55, 'num_neurons_layer_4': 168, 'num_epochs': 474, 'batch_size': 47}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:01:59,059] Trial 94 finished with value: 6.113183830687607 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 156, 'num_neurons_layer_2': 200, 'num_neurons_layer_3': 65, 'num_neurons_layer_4': 106, 'num_epochs': 318, 'batch_size': 46}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:02:07,217] Trial 95 finished with value: 10.364646942812655 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 127, 'num_neurons_layer_2': 155, 'num_neurons_layer_3': 81, 'num_neurons_layer_4': 128, 'num_epochs': 390, 'batch_size': 44}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:02:13,392] Trial 96 finished with value: 12.345646703683638 and parameters: {'num_hidden_layers': 1, 'num_neurons_layer_0': 8, 'num_epochs': 371, 'batch_size': 37}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:02:21,145] Trial 97 finished with value: 6.022180616570494 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 45, 'num_neurons_layer_1': 73, 'num_neurons_layer_2': 145, 'num_neurons_layer_3': 98, 'num_neurons_layer_4': 135, 'num_epochs': 423, 'batch_size': 49}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:02:30,577] Trial 98 finished with value: 5.439236409678726 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 143, 'num_neurons_layer_2': 110, 'num_neurons_layer_3': 144, 'num_neurons_layer_4': 161, 'num_epochs': 456, 'batch_size': 40}. Best is trial 66 with value: 5.296311320317001.\n",
      "C:\\Users\\ishan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-23 23:02:40,914] Trial 99 finished with value: 5.491363312984225 and parameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 30, 'num_neurons_layer_1': 135, 'num_neurons_layer_2': 110, 'num_neurons_layer_3': 41, 'num_neurons_layer_4': 164, 'num_epochs': 487, 'batch_size': 40}. Best is trial 66 with value: 5.296311320317001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'num_hidden_layers': 5, 'num_neurons_layer_0': 38, 'num_neurons_layer_1': 155, 'num_neurons_layer_2': 131, 'num_neurons_layer_3': 67, 'num_neurons_layer_4': 148, 'num_epochs': 436, 'batch_size': 50}\n",
      "Best RMSE: 5.30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
    "    num_neurons = [trial.suggest_int(f'num_neurons_layer_{i}', 5, 200) for i in range(num_hidden_layers)]\n",
    "    num_epochs = trial.suggest_int('num_epochs', 50, 500)\n",
    "    batch_size = trial.suggest_int('batch_size', 5, 50)\n",
    "\n",
    "    # Build the model\n",
    "    model_nn_meta = Sequential()\n",
    "    model_nn_meta.add(Dense(num_neurons[0], activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "    \n",
    "    for i in range(1, num_hidden_layers):\n",
    "        model_nn_meta.add(Dense(num_neurons[i], activation='relu'))\n",
    "    \n",
    "    model_nn_meta.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model_nn_meta.fit(X_meta_train, y, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "    y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse_stacking_nn = mean_squared_error(y, y_pred_stacking_nn)\n",
    "    rmse_stacking_nn = np.sqrt(mse_stacking_nn)\n",
    "\n",
    "    return rmse_stacking_nn\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_rmse = study.best_value\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f479e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Potato.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train the first neural network (base model 1)\n",
    "model_nn_base_1 = Sequential()\n",
    "model_nn_base_1.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_1.add(Dense(20, activation='relu'))\n",
    "model_nn_base_1.add(Dense(10, activation='relu'))\n",
    "model_nn_base_1.add(Dense(1, activation='linear'))\n",
    "model_nn_base_1.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_1.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the first base neural network model\n",
    "y_pred_nn_base_1 = model_nn_base_1.predict(X)\n",
    "\n",
    "# Build and train the second neural network (base model 2)\n",
    "model_nn_base_2 = Sequential()\n",
    "model_nn_base_2.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_2.add(Dense(25, activation='relu'))\n",
    "model_nn_base_2.add(Dense(10, activation='relu'))\n",
    "model_nn_base_2.add(Dense(5, activation='relu'))\n",
    "model_nn_base_2.add(Dense(1, activation='linear'))\n",
    "model_nn_base_2.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_2.fit(X, y, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the second base neural network model\n",
    "y_pred_nn_base_2 = model_nn_base_2.predict(X)\n",
    "\n",
    "# Combine predictions from both base models\n",
    "X_meta_train = np.concatenate((y_pred_nn_base_1, y_pred_nn_base_2), axis=1)\n",
    "\n",
    "# Build and train the meta neural network\n",
    "model_nn_meta = Sequential()\n",
    "model_nn_meta.add(Dense(200, activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "model_nn_meta.add(Dense(100, activation='relu'))\n",
    "model_nn_meta.add(Dense(50, activation='relu'))\n",
    "model_nn_meta.add(Dense(1, activation='linear'))\n",
    "model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_meta.fit(X_meta_train, y, epochs=200, batch_size=10)\n",
    "\n",
    "# Make predictions using the base models and meta-learner on the entire dataset\n",
    "X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "# Evaluate the stacking model with Neural Network as meta-learner on the entire dataset\n",
    "rmse_stacking_nn = np.sqrt(mean_squared_error(y, y_pred_stacking_nn))\n",
    "print(f\"Root Mean Squared Error on Entire Data (Stacking with Neural Network): {rmse_stacking_nn:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
    "    num_neurons = [trial.suggest_int(f'num_neurons_layer_{i}', 5, 200) for i in range(num_hidden_layers)]\n",
    "    num_epochs = trial.suggest_int('num_epochs', 50, 500)\n",
    "    batch_size = trial.suggest_int('batch_size', 5, 50)\n",
    "\n",
    "    # Build the model\n",
    "    model_nn_meta = Sequential()\n",
    "    model_nn_meta.add(Dense(num_neurons[0], activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "    \n",
    "    for i in range(1, num_hidden_layers):\n",
    "        model_nn_meta.add(Dense(num_neurons[i], activation='relu'))\n",
    "    \n",
    "    model_nn_meta.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model_nn_meta.fit(X_meta_train, y, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "    y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse_stacking_nn = mean_squared_error(y, y_pred_stacking_nn)\n",
    "    rmse_stacking_nn = np.sqrt(mse_stacking_nn)\n",
    "\n",
    "    return rmse_stacking_nn\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_rmse = study.best_value\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a723af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "df = pd.read_csv('rice.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build and train the first neural network (base model 1)\n",
    "model_nn_base_1 = Sequential()\n",
    "model_nn_base_1.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_1.add(Dense(20, activation='relu'))\n",
    "model_nn_base_1.add(Dense(10, activation='relu'))\n",
    "model_nn_base_1.add(Dense(1, activation='linear'))\n",
    "model_nn_base_1.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_1.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the first base neural network model\n",
    "y_pred_nn_base_1 = model_nn_base_1.predict(X)\n",
    "\n",
    "# Build and train the second neural network (base model 2)\n",
    "model_nn_base_2 = Sequential()\n",
    "model_nn_base_2.add(Dense(50, activation='relu', input_dim=len(features)))\n",
    "model_nn_base_2.add(Dense(25, activation='relu'))\n",
    "model_nn_base_2.add(Dense(10, activation='relu'))\n",
    "model_nn_base_2.add(Dense(5, activation='relu'))\n",
    "model_nn_base_2.add(Dense(1, activation='linear'))\n",
    "model_nn_base_2.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_base_2.fit(X, y, epochs=200, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions from the second base neural network model\n",
    "y_pred_nn_base_2 = model_nn_base_2.predict(X)\n",
    "\n",
    "# Combine predictions from both base models\n",
    "X_meta_train = np.concatenate((y_pred_nn_base_1, y_pred_nn_base_2), axis=1)\n",
    "\n",
    "# Build and train the meta neural network\n",
    "model_nn_meta = Sequential()\n",
    "model_nn_meta.add(Dense(200, activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "model_nn_meta.add(Dense(100, activation='relu'))\n",
    "model_nn_meta.add(Dense(50, activation='relu'))\n",
    "model_nn_meta.add(Dense(1, activation='linear'))\n",
    "model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model_nn_meta.fit(X_meta_train, y, epochs=200, batch_size=10)\n",
    "\n",
    "# Make predictions using the base models and meta-learner on the entire dataset\n",
    "X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "# Evaluate the stacking model with Neural Network as meta-learner on the entire dataset\n",
    "rmse_stacking_nn = np.sqrt(mean_squared_error(y, y_pred_stacking_nn))\n",
    "print(f\"Root Mean Squared Error on Entire Data (Stacking with Neural Network): {rmse_stacking_nn:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import optuna\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
    "    num_neurons = [trial.suggest_int(f'num_neurons_layer_{i}', 5, 200) for i in range(num_hidden_layers)]\n",
    "    num_epochs = trial.suggest_int('num_epochs', 50, 500)\n",
    "    batch_size = trial.suggest_int('batch_size', 5, 50)\n",
    "\n",
    "    # Build the model\n",
    "    model_nn_meta = Sequential()\n",
    "    model_nn_meta.add(Dense(num_neurons[0], activation='relu', input_dim=X_meta_train.shape[1]))\n",
    "    \n",
    "    for i in range(1, num_hidden_layers):\n",
    "        model_nn_meta.add(Dense(num_neurons[i], activation='relu'))\n",
    "    \n",
    "    model_nn_meta.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_nn_meta.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model_nn_meta.fit(X_meta_train, y, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    X_meta_all = np.concatenate((model_nn_base_1.predict(X), model_nn_base_2.predict(X)), axis=1)\n",
    "    y_pred_stacking_nn = model_nn_meta.predict(X_meta_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse_stacking_nn = mean_squared_error(y, y_pred_stacking_nn)\n",
    "    rmse_stacking_nn = np.sqrt(mse_stacking_nn)\n",
    "\n",
    "    return rmse_stacking_nn\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_rmse = study.best_value\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545264a8",
   "metadata": {},
   "source": [
    "# Results (with best scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acd407d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\1455932756.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13/13 [==============================] - 2s 11ms/step - loss: 1204.2975 - root_mean_squared_error: 34.7030\n",
      "Epoch 2/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1111.1985 - root_mean_squared_error: 33.3346\n",
      "Epoch 3/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 929.6438 - root_mean_squared_error: 30.4901\n",
      "Epoch 4/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 937.3442 - root_mean_squared_error: 30.6161\n",
      "Epoch 5/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1008.5477 - root_mean_squared_error: 31.7576\n",
      "Epoch 6/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 900.0615 - root_mean_squared_error: 30.0010\n",
      "Epoch 7/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 899.5583 - root_mean_squared_error: 29.9926\n",
      "Epoch 8/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 905.2249 - root_mean_squared_error: 30.0870\n",
      "Epoch 9/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 901.5046 - root_mean_squared_error: 30.0251\n",
      "Epoch 10/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 893.7571 - root_mean_squared_error: 29.8958\n",
      "Epoch 11/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 906.7507 - root_mean_squared_error: 30.1123\n",
      "Epoch 12/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 889.8196 - root_mean_squared_error: 29.8298\n",
      "Epoch 13/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 887.7422 - root_mean_squared_error: 29.7950\n",
      "Epoch 14/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 898.2660 - root_mean_squared_error: 29.9711\n",
      "Epoch 15/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 895.5628 - root_mean_squared_error: 29.9260\n",
      "Epoch 16/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 882.6128 - root_mean_squared_error: 29.7088\n",
      "Epoch 17/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 858.3340 - root_mean_squared_error: 29.2973\n",
      "Epoch 18/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 855.0983 - root_mean_squared_error: 29.2421\n",
      "Epoch 19/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 834.4029 - root_mean_squared_error: 28.8860\n",
      "Epoch 20/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 828.0521 - root_mean_squared_error: 28.7759\n",
      "Epoch 21/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 923.1219 - root_mean_squared_error: 30.3829\n",
      "Epoch 22/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 801.8636 - root_mean_squared_error: 28.3172\n",
      "Epoch 23/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 778.5480 - root_mean_squared_error: 27.9025\n",
      "Epoch 24/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 822.8722 - root_mean_squared_error: 28.6857\n",
      "Epoch 25/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 776.2850 - root_mean_squared_error: 27.8619\n",
      "Epoch 26/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 658.4959 - root_mean_squared_error: 25.6612\n",
      "Epoch 27/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 833.6606 - root_mean_squared_error: 28.8732\n",
      "Epoch 28/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 734.0486 - root_mean_squared_error: 27.0933\n",
      "Epoch 29/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 899.1624 - root_mean_squared_error: 29.9860\n",
      "Epoch 30/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 911.4160 - root_mean_squared_error: 30.1897\n",
      "Epoch 31/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 838.2590 - root_mean_squared_error: 28.9527\n",
      "Epoch 32/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 848.7502 - root_mean_squared_error: 29.1333\n",
      "Epoch 33/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 948.2902 - root_mean_squared_error: 30.7943\n",
      "Epoch 34/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 908.6826 - root_mean_squared_error: 30.1444\n",
      "Epoch 35/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 872.7197 - root_mean_squared_error: 29.5418\n",
      "Epoch 36/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 901.4843 - root_mean_squared_error: 30.0247\n",
      "Epoch 37/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 877.3610 - root_mean_squared_error: 29.6203\n",
      "Epoch 38/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 867.3320 - root_mean_squared_error: 29.4505\n",
      "Epoch 39/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 806.9016 - root_mean_squared_error: 28.4060\n",
      "Epoch 40/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 742.3162 - root_mean_squared_error: 27.2455\n",
      "Epoch 41/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 894.7603 - root_mean_squared_error: 29.9125\n",
      "Epoch 42/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 867.2211 - root_mean_squared_error: 29.4486\n",
      "Epoch 43/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 709.6013 - root_mean_squared_error: 26.6383\n",
      "Epoch 44/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 676.5223 - root_mean_squared_error: 26.0100\n",
      "Epoch 45/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 807.7048 - root_mean_squared_error: 28.4201\n",
      "Epoch 46/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 652.2502 - root_mean_squared_error: 25.5392\n",
      "Epoch 47/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 583.4484 - root_mean_squared_error: 24.1547\n",
      "Epoch 48/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 406.7727 - root_mean_squared_error: 20.1686\n",
      "Epoch 49/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 984.0490 - root_mean_squared_error: 31.3696\n",
      "Epoch 50/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 914.8290 - root_mean_squared_error: 30.2461\n",
      "Epoch 51/150\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 881.4085 - root_mean_squared_error: 29.6885\n",
      "Epoch 52/150\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 827.0731 - root_mean_squared_error: 28.7589\n",
      "Epoch 53/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 717.8870 - root_mean_squared_error: 26.7934\n",
      "Epoch 54/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 722.5349 - root_mean_squared_error: 26.8800\n",
      "Epoch 55/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 512.1014 - root_mean_squared_error: 22.6297\n",
      "Epoch 56/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 401.1534 - root_mean_squared_error: 20.0288\n",
      "Epoch 57/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 386.5500 - root_mean_squared_error: 19.6609\n",
      "Epoch 58/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 364.0851 - root_mean_squared_error: 19.0810\n",
      "Epoch 59/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 684.1174 - root_mean_squared_error: 26.1556\n",
      "Epoch 60/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 629.5111 - root_mean_squared_error: 25.0901\n",
      "Epoch 61/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 169.3893 - root_mean_squared_error: 13.0150\n",
      "Epoch 62/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 213.6301 - root_mean_squared_error: 14.6161\n",
      "Epoch 63/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 101.8828 - root_mean_squared_error: 10.0937\n",
      "Epoch 64/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 150.8965 - root_mean_squared_error: 12.2840\n",
      "Epoch 65/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 477.3487 - root_mean_squared_error: 21.8483\n",
      "Epoch 66/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 236.8494 - root_mean_squared_error: 15.3899\n",
      "Epoch 67/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 134.1064 - root_mean_squared_error: 11.5804\n",
      "Epoch 68/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 53.6883 - root_mean_squared_error: 7.3272\n",
      "Epoch 69/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 61.9675 - root_mean_squared_error: 7.8719\n",
      "Epoch 70/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 77.0296 - root_mean_squared_error: 8.7766\n",
      "Epoch 71/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 85.5763 - root_mean_squared_error: 9.2507\n",
      "Epoch 72/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 154.7703 - root_mean_squared_error: 12.4407\n",
      "Epoch 73/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 69.7926 - root_mean_squared_error: 8.3542\n",
      "Epoch 74/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 59.1010 - root_mean_squared_error: 7.6877\n",
      "Epoch 75/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 58.6826 - root_mean_squared_error: 7.6605\n",
      "Epoch 76/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 109.7872 - root_mean_squared_error: 10.4779\n",
      "Epoch 77/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 68.4093 - root_mean_squared_error: 8.2710\n",
      "Epoch 78/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 79.9919 - root_mean_squared_error: 8.9438\n",
      "Epoch 79/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 90.1923 - root_mean_squared_error: 9.4970\n",
      "Epoch 80/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 125.7592 - root_mean_squared_error: 11.2142\n",
      "Epoch 81/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 112.8647 - root_mean_squared_error: 10.6238\n",
      "Epoch 82/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 356.4332 - root_mean_squared_error: 18.8794\n",
      "Epoch 83/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 205.0943 - root_mean_squared_error: 14.3211\n",
      "Epoch 84/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 99.5153 - root_mean_squared_error: 9.9757\n",
      "Epoch 85/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 96.0502 - root_mean_squared_error: 9.8005\n",
      "Epoch 86/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 105.5243 - root_mean_squared_error: 10.2725\n",
      "Epoch 87/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 57.7263 - root_mean_squared_error: 7.5978\n",
      "Epoch 88/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 68.2647 - root_mean_squared_error: 8.2622\n",
      "Epoch 89/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 43.3961 - root_mean_squared_error: 6.5876\n",
      "Epoch 90/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 56.0027 - root_mean_squared_error: 7.4835\n",
      "Epoch 91/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 35.7120 - root_mean_squared_error: 5.9760\n",
      "Epoch 92/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 43.7395 - root_mean_squared_error: 6.6136\n",
      "Epoch 93/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 39.3418 - root_mean_squared_error: 6.2723\n",
      "Epoch 94/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 31.0058 - root_mean_squared_error: 5.5683\n",
      "Epoch 95/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 31.8660 - root_mean_squared_error: 5.6450\n",
      "Epoch 96/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 29.4590 - root_mean_squared_error: 5.4276\n",
      "Epoch 97/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 28.3160 - root_mean_squared_error: 5.3213\n",
      "Epoch 98/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 27.1124 - root_mean_squared_error: 5.2070\n",
      "Epoch 99/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 26.6809 - root_mean_squared_error: 5.1654\n",
      "Epoch 100/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 26.5253 - root_mean_squared_error: 5.1503\n",
      "Epoch 101/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 25.6039 - root_mean_squared_error: 5.0600\n",
      "Epoch 102/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 24.7206 - root_mean_squared_error: 4.9720\n",
      "Epoch 103/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 24.7961 - root_mean_squared_error: 4.9796\n",
      "Epoch 104/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 24.7977 - root_mean_squared_error: 4.9797\n",
      "Epoch 105/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 24.4051 - root_mean_squared_error: 4.9402\n",
      "Epoch 106/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 24.7354 - root_mean_squared_error: 4.9735\n",
      "Epoch 107/150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 24.5524 - root_mean_squared_error: 4.9550\n",
      "Epoch 108/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 24.2121 - root_mean_squared_error: 4.9206\n",
      "Epoch 109/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 23.5058 - root_mean_squared_error: 4.8483\n",
      "Epoch 110/150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 24.3136 - root_mean_squared_error: 4.9309\n",
      "Epoch 111/150\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 23.4582 - root_mean_squared_error: 4.8434\n",
      "Epoch 112/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 23.2736 - root_mean_squared_error: 4.8243\n",
      "Epoch 113/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 23.0788 - root_mean_squared_error: 4.8040\n",
      "Epoch 114/150\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 23.2872 - root_mean_squared_error: 4.8257\n",
      "Epoch 115/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 24.1488 - root_mean_squared_error: 4.9141\n",
      "Epoch 116/150\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 23.4509 - root_mean_squared_error: 4.8426\n",
      "Epoch 117/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 23.5296 - root_mean_squared_error: 4.8507\n",
      "Epoch 118/150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 23.3756 - root_mean_squared_error: 4.8348\n",
      "Epoch 119/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 25.5337 - root_mean_squared_error: 5.0531\n",
      "Epoch 120/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 23.8693 - root_mean_squared_error: 4.8856\n",
      "Epoch 121/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 25.2658 - root_mean_squared_error: 5.0265\n",
      "Epoch 122/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 34.2414 - root_mean_squared_error: 5.8516\n",
      "Epoch 123/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 29.6664 - root_mean_squared_error: 5.4467\n",
      "Epoch 124/150\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 43.0243 - root_mean_squared_error: 6.5593\n",
      "Epoch 125/150\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 80.9944 - root_mean_squared_error: 8.9997\n",
      "Epoch 126/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 46.2472 - root_mean_squared_error: 6.8005\n",
      "Epoch 127/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 283.6953 - root_mean_squared_error: 16.8433\n",
      "Epoch 128/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 476.2169 - root_mean_squared_error: 21.8224\n",
      "Epoch 129/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 262.9826 - root_mean_squared_error: 16.2167\n",
      "Epoch 130/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 64.9374 - root_mean_squared_error: 8.0584\n",
      "Epoch 131/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 138.7404 - root_mean_squared_error: 11.7788\n",
      "Epoch 132/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 84.2454 - root_mean_squared_error: 9.1785\n",
      "Epoch 133/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 67.2079 - root_mean_squared_error: 8.1980\n",
      "Epoch 134/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 45.2149 - root_mean_squared_error: 6.7242\n",
      "Epoch 135/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 37.6908 - root_mean_squared_error: 6.1393\n",
      "Epoch 136/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 53.4529 - root_mean_squared_error: 7.3112\n",
      "Epoch 137/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 117.4327 - root_mean_squared_error: 10.8366\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 10ms/step - loss: 176.2294 - root_mean_squared_error: 13.2751\n",
      "Epoch 139/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 50.0733 - root_mean_squared_error: 7.0762\n",
      "Epoch 140/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 43.4050 - root_mean_squared_error: 6.5882\n",
      "Epoch 141/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 30.9248 - root_mean_squared_error: 5.5610\n",
      "Epoch 142/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 34.7957 - root_mean_squared_error: 5.8988\n",
      "Epoch 143/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 37.5636 - root_mean_squared_error: 6.1289\n",
      "Epoch 144/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 29.5462 - root_mean_squared_error: 5.4356\n",
      "Epoch 145/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 24.9474 - root_mean_squared_error: 4.9947\n",
      "Epoch 146/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 23.1999 - root_mean_squared_error: 4.8166\n",
      "Epoch 147/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 24.8442 - root_mean_squared_error: 4.9844\n",
      "Epoch 148/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 22.0208 - root_mean_squared_error: 4.6926\n",
      "Epoch 149/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 22.7432 - root_mean_squared_error: 4.7690\n",
      "Epoch 150/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 21.9484 - root_mean_squared_error: 4.6849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327debbb50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "#from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(100, input_shape=(5,), activation='relu'))\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(75, activation='swish'))\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(25,activation='gelu'))\n",
    "model.add(Dense(10,activation='swish'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=20)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac0930e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\921783771.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 2s 15ms/step - loss: 1175.5151 - root_mean_squared_error: 34.2858\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1051.9890 - root_mean_squared_error: 32.4344\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 987.7980 - root_mean_squared_error: 31.4293\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 945.5988 - root_mean_squared_error: 30.7506\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 921.2784 - root_mean_squared_error: 30.3526\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 895.1857 - root_mean_squared_error: 29.9197\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 896.0562 - root_mean_squared_error: 29.9342\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 886.9800 - root_mean_squared_error: 29.7822\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 866.9118 - root_mean_squared_error: 29.4434\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 858.9633 - root_mean_squared_error: 29.3081\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 853.7286 - root_mean_squared_error: 29.2186\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 829.5658 - root_mean_squared_error: 28.8022\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 804.7023 - root_mean_squared_error: 28.3673\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 808.3301 - root_mean_squared_error: 28.4311\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 754.4373 - root_mean_squared_error: 27.4670\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 736.0355 - root_mean_squared_error: 27.1300\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 647.3487 - root_mean_squared_error: 25.4430\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 518.4991 - root_mean_squared_error: 22.7706\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 533.8088 - root_mean_squared_error: 23.1043\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 360.3160 - root_mean_squared_error: 18.9820\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 247.0599 - root_mean_squared_error: 15.7181\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 178.9249 - root_mean_squared_error: 13.3763\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 179.5125 - root_mean_squared_error: 13.3982\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 199.7689 - root_mean_squared_error: 14.1340\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 411.6876 - root_mean_squared_error: 20.2901\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 836.6649 - root_mean_squared_error: 28.9252\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 872.5571 - root_mean_squared_error: 29.5391\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 790.2589 - root_mean_squared_error: 28.1115\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 641.5206 - root_mean_squared_error: 25.3283\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 597.7563 - root_mean_squared_error: 24.4491\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 557.4380 - root_mean_squared_error: 23.6101\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 510.5524 - root_mean_squared_error: 22.5954\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 491.8669 - root_mean_squared_error: 22.1781\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 409.7375 - root_mean_squared_error: 20.2420\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 321.2503 - root_mean_squared_error: 17.9235\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 279.4961 - root_mean_squared_error: 16.7181\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 212.5418 - root_mean_squared_error: 14.5788\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 81.2245 - root_mean_squared_error: 9.0125\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 141.7683 - root_mean_squared_error: 11.9066\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 320.2645 - root_mean_squared_error: 17.8959\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 384.6549 - root_mean_squared_error: 19.6126\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 614.8524 - root_mean_squared_error: 24.7962\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 595.3543 - root_mean_squared_error: 24.3999\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 410.6479 - root_mean_squared_error: 20.2645\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 369.8866 - root_mean_squared_error: 19.2324\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 234.8279 - root_mean_squared_error: 15.3241\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 136.1226 - root_mean_squared_error: 11.6672\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 60.2306 - root_mean_squared_error: 7.7608\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 52.1088 - root_mean_squared_error: 7.2186\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 44.0984 - root_mean_squared_error: 6.6407\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 38.2280 - root_mean_squared_error: 6.1829\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 34.7795 - root_mean_squared_error: 5.8974\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 28.2995 - root_mean_squared_error: 5.3197\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 26.2515 - root_mean_squared_error: 5.1236\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 26.3876 - root_mean_squared_error: 5.1369\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 25.4994 - root_mean_squared_error: 5.0497\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 22.5180 - root_mean_squared_error: 4.7453\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 22.0360 - root_mean_squared_error: 4.6942\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 21.7059 - root_mean_squared_error: 4.6590\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 22.0082 - root_mean_squared_error: 4.6913\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 20.8258 - root_mean_squared_error: 4.5635\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.9177 - root_mean_squared_error: 4.4629\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 19.6097 - root_mean_squared_error: 4.4283\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 19.1899 - root_mean_squared_error: 4.3806\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 18.9444 - root_mean_squared_error: 4.3525\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.3315 - root_mean_squared_error: 4.2815\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 19.0351 - root_mean_squared_error: 4.3629\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.0960 - root_mean_squared_error: 4.2539\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.3001 - root_mean_squared_error: 4.2779\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.4363 - root_mean_squared_error: 4.1757\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.7072 - root_mean_squared_error: 4.2080\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.4016 - root_mean_squared_error: 4.1715\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 17.3425 - root_mean_squared_error: 4.1644\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.0051 - root_mean_squared_error: 4.3595\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 17.0300 - root_mean_squared_error: 4.1267\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 17.9252 - root_mean_squared_error: 4.2338\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 21.1770 - root_mean_squared_error: 4.6018\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 25.9474 - root_mean_squared_error: 5.0939\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 21.0602 - root_mean_squared_error: 4.5891\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 27.1675 - root_mean_squared_error: 5.2122\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 25.4658 - root_mean_squared_error: 5.0464\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 24.6672 - root_mean_squared_error: 4.9666\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 20.7502 - root_mean_squared_error: 4.5552\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 25.5085 - root_mean_squared_error: 5.0506\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 23.2425 - root_mean_squared_error: 4.8211\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 20.1507 - root_mean_squared_error: 4.4890\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 18.6386 - root_mean_squared_error: 4.3172\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.0380 - root_mean_squared_error: 4.3633\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 20.7974 - root_mean_squared_error: 4.5604\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 21.2635 - root_mean_squared_error: 4.6112\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 16.7359 - root_mean_squared_error: 4.0910\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.1633 - root_mean_squared_error: 4.1429\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 18.6199 - root_mean_squared_error: 4.3151\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 16.6628 - root_mean_squared_error: 4.0820\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 16.8892 - root_mean_squared_error: 4.1096\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.1126 - root_mean_squared_error: 4.2559\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 28.7434 - root_mean_squared_error: 5.3613\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 32.7143 - root_mean_squared_error: 5.7196\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 174.2101 - root_mean_squared_error: 13.1989\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 286.4841 - root_mean_squared_error: 16.9258\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 274.6124 - root_mean_squared_error: 16.5714\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 242.2267 - root_mean_squared_error: 15.5636\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 126.1688 - root_mean_squared_error: 11.2325\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 147.9698 - root_mean_squared_error: 12.1643\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 134.8096 - root_mean_squared_error: 11.6108\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 120.1524 - root_mean_squared_error: 10.9614\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 105.3568 - root_mean_squared_error: 10.2643\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 74.2984 - root_mean_squared_error: 8.6196\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 74.6207 - root_mean_squared_error: 8.6383\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 50.3864 - root_mean_squared_error: 7.0983\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 35.7085 - root_mean_squared_error: 5.9757\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 24.4899 - root_mean_squared_error: 4.9487\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 20.3249 - root_mean_squared_error: 4.5083\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 17.5928 - root_mean_squared_error: 4.1944\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 17.0217 - root_mean_squared_error: 4.1257\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 15.2615 - root_mean_squared_error: 3.9066\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 14.5668 - root_mean_squared_error: 3.8166\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 14.1867 - root_mean_squared_error: 3.7665\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 14.3795 - root_mean_squared_error: 3.7920\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 14.1737 - root_mean_squared_error: 3.7648\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 13.6382 - root_mean_squared_error: 3.6930\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.7872 - root_mean_squared_error: 3.5759\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 13.0571 - root_mean_squared_error: 3.6135\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.2585 - root_mean_squared_error: 3.5012\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.1305 - root_mean_squared_error: 3.4829\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.0228 - root_mean_squared_error: 3.4674\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.2169 - root_mean_squared_error: 3.4953\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.3927 - root_mean_squared_error: 3.5203\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 11.6915 - root_mean_squared_error: 3.4193\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 11.3394 - root_mean_squared_error: 3.3674\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.1230 - root_mean_squared_error: 3.4818\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.7174 - root_mean_squared_error: 3.5661\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 16.3376 - root_mean_squared_error: 4.0420\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 15.1105 - root_mean_squared_error: 3.8872\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 14.7026 - root_mean_squared_error: 3.8344\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 14.3001 - root_mean_squared_error: 3.7816\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 11.7098 - root_mean_squared_error: 3.4220\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 15.1051 - root_mean_squared_error: 3.8865\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 31.7859 - root_mean_squared_error: 5.6379\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 44.5016 - root_mean_squared_error: 6.6710\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 127.7076 - root_mean_squared_error: 11.3008\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 378.7706 - root_mean_squared_error: 19.4620\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 78.2149 - root_mean_squared_error: 8.8439\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 64.6741 - root_mean_squared_error: 8.0420\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 44.3278 - root_mean_squared_error: 6.6579\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 32.5100 - root_mean_squared_error: 5.7018\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 24.0020 - root_mean_squared_error: 4.8992\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 122.6535 - root_mean_squared_error: 11.0749\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 226.8068 - root_mean_squared_error: 15.0601\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 362.0877 - root_mean_squared_error: 19.0286\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 108.9683 - root_mean_squared_error: 10.4388\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 132.2995 - root_mean_squared_error: 11.5022\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 109.1290 - root_mean_squared_error: 10.4465\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 109.5355 - root_mean_squared_error: 10.4659\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 113.9180 - root_mean_squared_error: 10.6732\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 58.0131 - root_mean_squared_error: 7.6166\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 40.8156 - root_mean_squared_error: 6.3887\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 27.0026 - root_mean_squared_error: 5.1964\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 21.3432 - root_mean_squared_error: 4.6199\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.8964 - root_mean_squared_error: 4.2304\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 16.4918 - root_mean_squared_error: 4.0610\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 16.1444 - root_mean_squared_error: 4.0180\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 14.3538 - root_mean_squared_error: 3.7886\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 13.9592 - root_mean_squared_error: 3.7362\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 12.9070 - root_mean_squared_error: 3.5926\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 13.0342 - root_mean_squared_error: 3.6103\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.8522 - root_mean_squared_error: 3.5850\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 12.4467 - root_mean_squared_error: 3.5280\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.1177 - root_mean_squared_error: 3.4811\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.0024 - root_mean_squared_error: 3.4645\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 11.1893 - root_mean_squared_error: 3.3450\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 11.3504 - root_mean_squared_error: 3.3690\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.9701 - root_mean_squared_error: 3.3121\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 11.1348 - root_mean_squared_error: 3.3369\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.0658 - root_mean_squared_error: 3.4736\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 11.3450 - root_mean_squared_error: 3.3682\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.4348 - root_mean_squared_error: 3.2303\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 10.1796 - root_mean_squared_error: 3.1905\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 11.6593 - root_mean_squared_error: 3.4146\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.7710 - root_mean_squared_error: 3.2819\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 11.0803 - root_mean_squared_error: 3.3287\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.4477 - root_mean_squared_error: 3.2323\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.5884 - root_mean_squared_error: 3.2540\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 9.9013 - root_mean_squared_error: 3.1466\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.7501 - root_mean_squared_error: 3.2787\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.0235 - root_mean_squared_error: 3.1660\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 8.6566 - root_mean_squared_error: 2.9422\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.5549 - root_mean_squared_error: 2.9249\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 8.6229 - root_mean_squared_error: 2.9365\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 8.5466 - root_mean_squared_error: 2.9234\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.2617 - root_mean_squared_error: 2.8743\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.4339 - root_mean_squared_error: 2.9041\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.8707 - root_mean_squared_error: 2.8055\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.8581 - root_mean_squared_error: 2.8032\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.2837 - root_mean_squared_error: 2.8781\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.9799 - root_mean_squared_error: 2.9966\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.6400 - root_mean_squared_error: 2.9394\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.5118 - root_mean_squared_error: 2.7408\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.6728 - root_mean_squared_error: 2.7700\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.3925 - root_mean_squared_error: 2.8970\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.0080 - root_mean_squared_error: 2.6473\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.7864 - root_mean_squared_error: 2.7904\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 8.5429 - root_mean_squared_error: 2.9228\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.3413 - root_mean_squared_error: 2.7095\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.0334 - root_mean_squared_error: 3.0056\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.8748 - root_mean_squared_error: 2.8062\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.5169 - root_mean_squared_error: 2.7417\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.7481 - root_mean_squared_error: 2.9577\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.7024 - root_mean_squared_error: 3.1149\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.3957 - root_mean_squared_error: 2.8975\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.9079 - root_mean_squared_error: 2.8121\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.5955 - root_mean_squared_error: 2.7560\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.4002 - root_mean_squared_error: 2.5299\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.1206 - root_mean_squared_error: 2.4740\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.6146 - root_mean_squared_error: 2.5719\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.0150 - root_mean_squared_error: 2.4525\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.7160 - root_mean_squared_error: 2.5915\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.2425 - root_mean_squared_error: 2.6912\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.4181 - root_mean_squared_error: 2.5334\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 6.6572 - root_mean_squared_error: 2.5802\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.5027 - root_mean_squared_error: 2.7391\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.7816 - root_mean_squared_error: 2.9634\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.5393 - root_mean_squared_error: 2.9222\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.2930 - root_mean_squared_error: 3.0484\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.4452 - root_mean_squared_error: 3.0733\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.6882 - root_mean_squared_error: 2.9476\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.4473 - root_mean_squared_error: 2.9064\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.2847 - root_mean_squared_error: 2.6990\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 5.9227 - root_mean_squared_error: 2.4337\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 6.4392 - root_mean_squared_error: 2.5376\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.2984 - root_mean_squared_error: 2.7016\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.9557 - root_mean_squared_error: 2.8206\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 15.0169 - root_mean_squared_error: 3.8752\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.0354 - root_mean_squared_error: 4.1274\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 23.3790 - root_mean_squared_error: 4.8352\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 22.5939 - root_mean_squared_error: 4.7533\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 86.6727 - root_mean_squared_error: 9.3098\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 114.9514 - root_mean_squared_error: 10.7215\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 50.1887 - root_mean_squared_error: 7.0844\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 33.2645 - root_mean_squared_error: 5.7675\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 133.4404 - root_mean_squared_error: 11.5516\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 124.4229 - root_mean_squared_error: 11.1545\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 150.2960 - root_mean_squared_error: 12.2595\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 151.5434 - root_mean_squared_error: 12.3103\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 87.9422 - root_mean_squared_error: 9.3778\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 101.6267 - root_mean_squared_error: 10.0810\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 93.2873 - root_mean_squared_error: 9.6585\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 91.5777 - root_mean_squared_error: 9.5696\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 84.5965 - root_mean_squared_error: 9.1976\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 29.7926 - root_mean_squared_error: 5.4583\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 34.2836 - root_mean_squared_error: 5.8552\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 44.4015 - root_mean_squared_error: 6.6634\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 47.8610 - root_mean_squared_error: 6.9182\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 16.5052 - root_mean_squared_error: 4.0627\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 24.0025 - root_mean_squared_error: 4.8992\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 34.8757 - root_mean_squared_error: 5.9056\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 49.5087 - root_mean_squared_error: 7.0362\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.0793 - root_mean_squared_error: 4.1327\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 19.1571 - root_mean_squared_error: 4.3769\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.3594 - root_mean_squared_error: 3.5156\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 14.3993 - root_mean_squared_error: 3.7946\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.5686 - root_mean_squared_error: 4.1915\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 13.3993 - root_mean_squared_error: 3.6605\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 11.1762 - root_mean_squared_error: 3.3431\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.0314 - root_mean_squared_error: 3.1672\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.3334 - root_mean_squared_error: 3.0551\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.1590 - root_mean_squared_error: 2.8564\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 7.9030 - root_mean_squared_error: 2.8112\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.5205 - root_mean_squared_error: 2.9190\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.5798 - root_mean_squared_error: 2.7531\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 7.3693 - root_mean_squared_error: 2.7146\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.2982 - root_mean_squared_error: 2.7015\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.0152 - root_mean_squared_error: 2.6486\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.4961 - root_mean_squared_error: 2.5487\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.3661 - root_mean_squared_error: 2.5231\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.9428 - root_mean_squared_error: 2.6349\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.0304 - root_mean_squared_error: 4.1268\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 20.9924 - root_mean_squared_error: 4.5817\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 30.7378 - root_mean_squared_error: 5.5442\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 24.9473 - root_mean_squared_error: 4.9947\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 14ms/step - loss: 13.3201 - root_mean_squared_error: 3.6497\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 25.9318 - root_mean_squared_error: 5.0923\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 29.9380 - root_mean_squared_error: 5.4716\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 13.3005 - root_mean_squared_error: 3.6470\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 17.1777 - root_mean_squared_error: 4.1446\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.8180 - root_mean_squared_error: 4.4517\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 18.8925 - root_mean_squared_error: 4.3465\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.2901 - root_mean_squared_error: 2.8793\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 17.7403 - root_mean_squared_error: 4.2119\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 17.6191 - root_mean_squared_error: 4.1975\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.9746 - root_mean_squared_error: 3.1583\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.9220 - root_mean_squared_error: 2.9870\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 9.1650 - root_mean_squared_error: 3.0274\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7.4423 - root_mean_squared_error: 2.7281\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.3973 - root_mean_squared_error: 2.3232\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.9666 - root_mean_squared_error: 2.2286\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 5.1733 - root_mean_squared_error: 2.2745\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.5264 - root_mean_squared_error: 2.1275\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.3668 - root_mean_squared_error: 2.0897\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 4.8704 - root_mean_squared_error: 2.2069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327b430220>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Onion.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1b3635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.617738970235589\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for onion \n",
    "df = pd.read_csv('Onion.csv')\n",
    "y = df['Yield']\n",
    "rmse = 2.2069 \n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbb9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9442595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\92057892.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "18/18 [==============================] - 3s 16ms/step - loss: 2.2664 - root_mean_squared_error: 1.5054\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6189 - root_mean_squared_error: 0.7867\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5658 - root_mean_squared_error: 0.7522\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4557 - root_mean_squared_error: 0.6750\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4273 - root_mean_squared_error: 0.6537\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3884 - root_mean_squared_error: 0.6232\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3845 - root_mean_squared_error: 0.6201\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3632 - root_mean_squared_error: 0.6027\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3476 - root_mean_squared_error: 0.5896\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3163 - root_mean_squared_error: 0.5624\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3174 - root_mean_squared_error: 0.5634\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3134 - root_mean_squared_error: 0.5598\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3136 - root_mean_squared_error: 0.5600\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3134 - root_mean_squared_error: 0.5599\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.2863 - root_mean_squared_error: 0.5350\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2811 - root_mean_squared_error: 0.5302\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2752 - root_mean_squared_error: 0.5246\n",
      "Epoch 18/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3151 - root_mean_squared_error: 0.5613\n",
      "Epoch 19/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3159 - root_mean_squared_error: 0.5620\n",
      "Epoch 20/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3769 - root_mean_squared_error: 0.6139\n",
      "Epoch 21/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2937 - root_mean_squared_error: 0.5420\n",
      "Epoch 22/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2759 - root_mean_squared_error: 0.5252\n",
      "Epoch 23/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2669 - root_mean_squared_error: 0.5166\n",
      "Epoch 24/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2454 - root_mean_squared_error: 0.4954\n",
      "Epoch 25/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2273 - root_mean_squared_error: 0.4767\n",
      "Epoch 26/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2649 - root_mean_squared_error: 0.5147\n",
      "Epoch 27/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2908 - root_mean_squared_error: 0.5393\n",
      "Epoch 28/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2987 - root_mean_squared_error: 0.5465\n",
      "Epoch 29/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2340 - root_mean_squared_error: 0.4838\n",
      "Epoch 30/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2318 - root_mean_squared_error: 0.4815\n",
      "Epoch 31/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.1970 - root_mean_squared_error: 0.4438\n",
      "Epoch 32/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1928 - root_mean_squared_error: 0.4390\n",
      "Epoch 33/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2354 - root_mean_squared_error: 0.4851\n",
      "Epoch 34/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1973 - root_mean_squared_error: 0.4442\n",
      "Epoch 35/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2004 - root_mean_squared_error: 0.4477\n",
      "Epoch 36/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2075 - root_mean_squared_error: 0.4555\n",
      "Epoch 37/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.1906 - root_mean_squared_error: 0.4365\n",
      "Epoch 38/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2053 - root_mean_squared_error: 0.4531\n",
      "Epoch 39/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2424 - root_mean_squared_error: 0.4923\n",
      "Epoch 40/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2083 - root_mean_squared_error: 0.4564\n",
      "Epoch 41/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1793 - root_mean_squared_error: 0.4235\n",
      "Epoch 42/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1749 - root_mean_squared_error: 0.4182\n",
      "Epoch 43/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1724 - root_mean_squared_error: 0.4152\n",
      "Epoch 44/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1650 - root_mean_squared_error: 0.4062\n",
      "Epoch 45/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1639 - root_mean_squared_error: 0.4049\n",
      "Epoch 46/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1583 - root_mean_squared_error: 0.3979\n",
      "Epoch 47/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1574 - root_mean_squared_error: 0.3967\n",
      "Epoch 48/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1517 - root_mean_squared_error: 0.3895\n",
      "Epoch 49/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1856 - root_mean_squared_error: 0.4308\n",
      "Epoch 50/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1974 - root_mean_squared_error: 0.4442\n",
      "Epoch 51/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2254 - root_mean_squared_error: 0.4747\n",
      "Epoch 52/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.2018 - root_mean_squared_error: 0.4493\n",
      "Epoch 53/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2324 - root_mean_squared_error: 0.4821\n",
      "Epoch 54/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2260 - root_mean_squared_error: 0.4754\n",
      "Epoch 55/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1649 - root_mean_squared_error: 0.4061\n",
      "Epoch 56/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1486 - root_mean_squared_error: 0.3855\n",
      "Epoch 57/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1548 - root_mean_squared_error: 0.3934\n",
      "Epoch 58/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1352 - root_mean_squared_error: 0.3678\n",
      "Epoch 59/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1380 - root_mean_squared_error: 0.3715\n",
      "Epoch 60/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1369 - root_mean_squared_error: 0.3700\n",
      "Epoch 61/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1256 - root_mean_squared_error: 0.3543\n",
      "Epoch 62/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1277 - root_mean_squared_error: 0.3574\n",
      "Epoch 63/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1265 - root_mean_squared_error: 0.3557\n",
      "Epoch 64/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1344 - root_mean_squared_error: 0.3665\n",
      "Epoch 65/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1381 - root_mean_squared_error: 0.3716\n",
      "Epoch 66/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1196 - root_mean_squared_error: 0.3459\n",
      "Epoch 67/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1149 - root_mean_squared_error: 0.3390\n",
      "Epoch 68/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1082 - root_mean_squared_error: 0.3289\n",
      "Epoch 69/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1055 - root_mean_squared_error: 0.3248\n",
      "Epoch 70/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1220 - root_mean_squared_error: 0.3493\n",
      "Epoch 71/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1144 - root_mean_squared_error: 0.3383\n",
      "Epoch 72/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1133 - root_mean_squared_error: 0.3366\n",
      "Epoch 73/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1087 - root_mean_squared_error: 0.3297\n",
      "Epoch 74/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0940 - root_mean_squared_error: 0.3066\n",
      "Epoch 75/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1043 - root_mean_squared_error: 0.3230\n",
      "Epoch 76/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1057 - root_mean_squared_error: 0.3252\n",
      "Epoch 77/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1152 - root_mean_squared_error: 0.3395\n",
      "Epoch 78/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1168 - root_mean_squared_error: 0.3418\n",
      "Epoch 79/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1549 - root_mean_squared_error: 0.3936\n",
      "Epoch 80/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1481 - root_mean_squared_error: 0.3849\n",
      "Epoch 81/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1401 - root_mean_squared_error: 0.3744\n",
      "Epoch 82/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1286 - root_mean_squared_error: 0.3586\n",
      "Epoch 83/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1050 - root_mean_squared_error: 0.3241\n",
      "Epoch 84/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1091 - root_mean_squared_error: 0.3303\n",
      "Epoch 85/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1104 - root_mean_squared_error: 0.3323\n",
      "Epoch 86/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1087 - root_mean_squared_error: 0.3298\n",
      "Epoch 87/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1024 - root_mean_squared_error: 0.3201\n",
      "Epoch 88/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0983 - root_mean_squared_error: 0.3136\n",
      "Epoch 89/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1154 - root_mean_squared_error: 0.3397\n",
      "Epoch 90/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0994 - root_mean_squared_error: 0.3153\n",
      "Epoch 91/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0944 - root_mean_squared_error: 0.3072\n",
      "Epoch 92/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0921 - root_mean_squared_error: 0.3035\n",
      "Epoch 93/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0896 - root_mean_squared_error: 0.2994\n",
      "Epoch 94/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0869 - root_mean_squared_error: 0.2949\n",
      "Epoch 95/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0834 - root_mean_squared_error: 0.2888\n",
      "Epoch 96/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0914 - root_mean_squared_error: 0.3023\n",
      "Epoch 97/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0899 - root_mean_squared_error: 0.2999\n",
      "Epoch 98/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1159 - root_mean_squared_error: 0.3405\n",
      "Epoch 99/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1252 - root_mean_squared_error: 0.3539\n",
      "Epoch 100/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1005 - root_mean_squared_error: 0.3170\n",
      "Epoch 101/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1184 - root_mean_squared_error: 0.3441\n",
      "Epoch 102/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1097 - root_mean_squared_error: 0.3313\n",
      "Epoch 103/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0938 - root_mean_squared_error: 0.3063\n",
      "Epoch 104/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1049 - root_mean_squared_error: 0.3239\n",
      "Epoch 105/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1110 - root_mean_squared_error: 0.3331\n",
      "Epoch 106/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1218 - root_mean_squared_error: 0.3490\n",
      "Epoch 107/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1035 - root_mean_squared_error: 0.3217\n",
      "Epoch 108/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0928 - root_mean_squared_error: 0.3046\n",
      "Epoch 109/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0910 - root_mean_squared_error: 0.3017\n",
      "Epoch 110/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0881 - root_mean_squared_error: 0.2969\n",
      "Epoch 111/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737\n",
      "Epoch 112/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0769 - root_mean_squared_error: 0.2773\n",
      "Epoch 113/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0762 - root_mean_squared_error: 0.2760\n",
      "Epoch 114/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0778 - root_mean_squared_error: 0.2789\n",
      "Epoch 115/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0662 - root_mean_squared_error: 0.2573\n",
      "Epoch 116/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0751 - root_mean_squared_error: 0.2741\n",
      "Epoch 117/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0789 - root_mean_squared_error: 0.2809\n",
      "Epoch 118/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0770 - root_mean_squared_error: 0.2774\n",
      "Epoch 119/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0791 - root_mean_squared_error: 0.2813\n",
      "Epoch 120/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0825 - root_mean_squared_error: 0.2873\n",
      "Epoch 121/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0784 - root_mean_squared_error: 0.2800\n",
      "Epoch 122/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0880 - root_mean_squared_error: 0.2966\n",
      "Epoch 123/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0708 - root_mean_squared_error: 0.2661\n",
      "Epoch 124/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0761 - root_mean_squared_error: 0.2758\n",
      "Epoch 125/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0810 - root_mean_squared_error: 0.2847\n",
      "Epoch 126/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0675 - root_mean_squared_error: 0.2598\n",
      "Epoch 127/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0714 - root_mean_squared_error: 0.2673\n",
      "Epoch 128/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650\n",
      "Epoch 129/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0684 - root_mean_squared_error: 0.2616\n",
      "Epoch 130/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0633 - root_mean_squared_error: 0.2516\n",
      "Epoch 131/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0666 - root_mean_squared_error: 0.2581\n",
      "Epoch 132/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0630 - root_mean_squared_error: 0.2509\n",
      "Epoch 133/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0752 - root_mean_squared_error: 0.2743\n",
      "Epoch 134/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0738 - root_mean_squared_error: 0.2717\n",
      "Epoch 135/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0834 - root_mean_squared_error: 0.2887\n",
      "Epoch 136/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0751 - root_mean_squared_error: 0.2740\n",
      "Epoch 137/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0626 - root_mean_squared_error: 0.2502\n",
      "Epoch 138/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0726 - root_mean_squared_error: 0.2694\n",
      "Epoch 139/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0608 - root_mean_squared_error: 0.2465\n",
      "Epoch 140/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0627 - root_mean_squared_error: 0.2504\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0677 - root_mean_squared_error: 0.2602\n",
      "Epoch 142/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0857 - root_mean_squared_error: 0.2928\n",
      "Epoch 143/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0795 - root_mean_squared_error: 0.2819\n",
      "Epoch 144/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0808 - root_mean_squared_error: 0.2843\n",
      "Epoch 145/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0807 - root_mean_squared_error: 0.2840\n",
      "Epoch 146/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0908 - root_mean_squared_error: 0.3013\n",
      "Epoch 147/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0857 - root_mean_squared_error: 0.2928\n",
      "Epoch 148/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0705 - root_mean_squared_error: 0.2656\n",
      "Epoch 149/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0748 - root_mean_squared_error: 0.2736\n",
      "Epoch 150/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0664 - root_mean_squared_error: 0.2578\n",
      "Epoch 151/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0768 - root_mean_squared_error: 0.2772\n",
      "Epoch 152/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0751 - root_mean_squared_error: 0.2740\n",
      "Epoch 153/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0659 - root_mean_squared_error: 0.2567\n",
      "Epoch 154/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0621 - root_mean_squared_error: 0.2491\n",
      "Epoch 155/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0659 - root_mean_squared_error: 0.2567\n",
      "Epoch 156/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0636 - root_mean_squared_error: 0.2521\n",
      "Epoch 157/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650\n",
      "Epoch 158/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1035 - root_mean_squared_error: 0.3217\n",
      "Epoch 159/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0863 - root_mean_squared_error: 0.2937\n",
      "Epoch 160/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0831 - root_mean_squared_error: 0.2882\n",
      "Epoch 161/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0978 - root_mean_squared_error: 0.3127\n",
      "Epoch 162/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0968 - root_mean_squared_error: 0.3111\n",
      "Epoch 163/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0917 - root_mean_squared_error: 0.3029\n",
      "Epoch 164/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0853 - root_mean_squared_error: 0.2920\n",
      "Epoch 165/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0727 - root_mean_squared_error: 0.2696\n",
      "Epoch 166/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0720 - root_mean_squared_error: 0.2684\n",
      "Epoch 167/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0632 - root_mean_squared_error: 0.2514\n",
      "Epoch 168/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0682 - root_mean_squared_error: 0.2611\n",
      "Epoch 169/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0711 - root_mean_squared_error: 0.2666\n",
      "Epoch 170/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0722 - root_mean_squared_error: 0.2686\n",
      "Epoch 171/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0649 - root_mean_squared_error: 0.2547\n",
      "Epoch 172/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0594 - root_mean_squared_error: 0.2436\n",
      "Epoch 173/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0651 - root_mean_squared_error: 0.2552\n",
      "Epoch 174/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0675 - root_mean_squared_error: 0.2599\n",
      "Epoch 175/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0668 - root_mean_squared_error: 0.2585\n",
      "Epoch 176/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0606 - root_mean_squared_error: 0.2463\n",
      "Epoch 177/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0571 - root_mean_squared_error: 0.2390\n",
      "Epoch 178/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1221 - root_mean_squared_error: 0.3494\n",
      "Epoch 179/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1427 - root_mean_squared_error: 0.3777\n",
      "Epoch 180/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1300 - root_mean_squared_error: 0.3605\n",
      "Epoch 181/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0976 - root_mean_squared_error: 0.3124\n",
      "Epoch 182/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0951 - root_mean_squared_error: 0.3084\n",
      "Epoch 183/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0781 - root_mean_squared_error: 0.2795\n",
      "Epoch 184/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1073 - root_mean_squared_error: 0.3276\n",
      "Epoch 185/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.2449 - root_mean_squared_error: 0.4949\n",
      "Epoch 186/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1931 - root_mean_squared_error: 0.4395\n",
      "Epoch 187/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1545 - root_mean_squared_error: 0.3931\n",
      "Epoch 188/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1377 - root_mean_squared_error: 0.3711\n",
      "Epoch 189/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1064 - root_mean_squared_error: 0.3262\n",
      "Epoch 190/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0983 - root_mean_squared_error: 0.3136\n",
      "Epoch 191/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0921 - root_mean_squared_error: 0.3035\n",
      "Epoch 192/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0915 - root_mean_squared_error: 0.3025\n",
      "Epoch 193/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0908 - root_mean_squared_error: 0.3013\n",
      "Epoch 194/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0857 - root_mean_squared_error: 0.2927\n",
      "Epoch 195/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0931 - root_mean_squared_error: 0.3052\n",
      "Epoch 196/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1218 - root_mean_squared_error: 0.3490\n",
      "Epoch 197/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1024 - root_mean_squared_error: 0.3200\n",
      "Epoch 198/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0955 - root_mean_squared_error: 0.3090\n",
      "Epoch 199/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0914 - root_mean_squared_error: 0.3024\n",
      "Epoch 200/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0963 - root_mean_squared_error: 0.3103\n",
      "Epoch 201/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0741 - root_mean_squared_error: 0.2721\n",
      "Epoch 202/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0770 - root_mean_squared_error: 0.2774\n",
      "Epoch 203/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0881 - root_mean_squared_error: 0.2969\n",
      "Epoch 204/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0988 - root_mean_squared_error: 0.3144\n",
      "Epoch 205/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1014 - root_mean_squared_error: 0.3185\n",
      "Epoch 206/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0980 - root_mean_squared_error: 0.3130\n",
      "Epoch 207/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0806 - root_mean_squared_error: 0.2839\n",
      "Epoch 208/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0780 - root_mean_squared_error: 0.2793\n",
      "Epoch 209/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0892 - root_mean_squared_error: 0.2987\n",
      "Epoch 210/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0723 - root_mean_squared_error: 0.2689\n",
      "Epoch 211/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0638 - root_mean_squared_error: 0.2527\n",
      "Epoch 212/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0578 - root_mean_squared_error: 0.2403\n",
      "Epoch 213/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0685 - root_mean_squared_error: 0.2618\n",
      "Epoch 214/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0637 - root_mean_squared_error: 0.2524\n",
      "Epoch 215/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0948 - root_mean_squared_error: 0.3079\n",
      "Epoch 216/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0878 - root_mean_squared_error: 0.2963\n",
      "Epoch 217/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0815 - root_mean_squared_error: 0.2854\n",
      "Epoch 218/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0670 - root_mean_squared_error: 0.2588\n",
      "Epoch 219/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0626 - root_mean_squared_error: 0.2501\n",
      "Epoch 220/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0661 - root_mean_squared_error: 0.2570\n",
      "Epoch 221/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0557 - root_mean_squared_error: 0.2360\n",
      "Epoch 222/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0548 - root_mean_squared_error: 0.2342\n",
      "Epoch 223/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0484 - root_mean_squared_error: 0.2199\n",
      "Epoch 224/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0490 - root_mean_squared_error: 0.2214\n",
      "Epoch 225/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0579 - root_mean_squared_error: 0.2405\n",
      "Epoch 226/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0552 - root_mean_squared_error: 0.2349\n",
      "Epoch 227/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379\n",
      "Epoch 228/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0506 - root_mean_squared_error: 0.2248\n",
      "Epoch 229/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0469 - root_mean_squared_error: 0.2166\n",
      "Epoch 230/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0438 - root_mean_squared_error: 0.2094\n",
      "Epoch 231/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0534 - root_mean_squared_error: 0.2310\n",
      "Epoch 232/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0463 - root_mean_squared_error: 0.2151\n",
      "Epoch 233/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0450 - root_mean_squared_error: 0.2120\n",
      "Epoch 234/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0634 - root_mean_squared_error: 0.2518\n",
      "Epoch 235/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0557 - root_mean_squared_error: 0.2361\n",
      "Epoch 236/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0551 - root_mean_squared_error: 0.2348\n",
      "Epoch 237/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158\n",
      "Epoch 238/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0420 - root_mean_squared_error: 0.2049\n",
      "Epoch 239/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051\n",
      "Epoch 240/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0433 - root_mean_squared_error: 0.2082\n",
      "Epoch 241/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0429 - root_mean_squared_error: 0.2072\n",
      "Epoch 242/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0430 - root_mean_squared_error: 0.2073\n",
      "Epoch 243/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0443 - root_mean_squared_error: 0.2105\n",
      "Epoch 244/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0509 - root_mean_squared_error: 0.2255\n",
      "Epoch 245/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0473 - root_mean_squared_error: 0.2176\n",
      "Epoch 246/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0451 - root_mean_squared_error: 0.2124\n",
      "Epoch 247/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0439 - root_mean_squared_error: 0.2094\n",
      "Epoch 248/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0447 - root_mean_squared_error: 0.2114\n",
      "Epoch 249/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0521 - root_mean_squared_error: 0.2282\n",
      "Epoch 250/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088\n",
      "Epoch 251/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0423 - root_mean_squared_error: 0.2057\n",
      "Epoch 252/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0427 - root_mean_squared_error: 0.2066\n",
      "Epoch 253/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089\n",
      "Epoch 254/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0449 - root_mean_squared_error: 0.2119\n",
      "Epoch 255/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0454 - root_mean_squared_error: 0.2130\n",
      "Epoch 256/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0440 - root_mean_squared_error: 0.2099\n",
      "Epoch 257/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0449 - root_mean_squared_error: 0.2119\n",
      "Epoch 258/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0421 - root_mean_squared_error: 0.2052\n",
      "Epoch 259/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0463 - root_mean_squared_error: 0.2151\n",
      "Epoch 260/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0462 - root_mean_squared_error: 0.2148\n",
      "Epoch 261/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089\n",
      "Epoch 262/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0446 - root_mean_squared_error: 0.2112\n",
      "Epoch 263/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0454 - root_mean_squared_error: 0.2131\n",
      "Epoch 264/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0457 - root_mean_squared_error: 0.2138\n",
      "Epoch 265/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0509 - root_mean_squared_error: 0.2257\n",
      "Epoch 266/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0618 - root_mean_squared_error: 0.2486\n",
      "Epoch 267/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0620 - root_mean_squared_error: 0.2490\n",
      "Epoch 268/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1063 - root_mean_squared_error: 0.3261\n",
      "Epoch 269/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1162 - root_mean_squared_error: 0.3409\n",
      "Epoch 270/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1407 - root_mean_squared_error: 0.3751\n",
      "Epoch 271/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1149 - root_mean_squared_error: 0.3389\n",
      "Epoch 272/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1190 - root_mean_squared_error: 0.3449\n",
      "Epoch 273/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0900 - root_mean_squared_error: 0.3000\n",
      "Epoch 274/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1112 - root_mean_squared_error: 0.3335\n",
      "Epoch 275/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1164 - root_mean_squared_error: 0.3411\n",
      "Epoch 276/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1463 - root_mean_squared_error: 0.3825\n",
      "Epoch 277/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.1015 - root_mean_squared_error: 0.3186\n",
      "Epoch 278/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1494 - root_mean_squared_error: 0.3865\n",
      "Epoch 279/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1288 - root_mean_squared_error: 0.3588\n",
      "Epoch 280/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1116 - root_mean_squared_error: 0.3341\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0842 - root_mean_squared_error: 0.2902\n",
      "Epoch 282/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0990 - root_mean_squared_error: 0.3146\n",
      "Epoch 283/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0979 - root_mean_squared_error: 0.3129\n",
      "Epoch 284/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.1100 - root_mean_squared_error: 0.3317\n",
      "Epoch 285/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0792 - root_mean_squared_error: 0.2814\n",
      "Epoch 286/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0695 - root_mean_squared_error: 0.2637\n",
      "Epoch 287/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0658 - root_mean_squared_error: 0.2565\n",
      "Epoch 288/300\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0687 - root_mean_squared_error: 0.2622\n",
      "Epoch 289/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481\n",
      "Epoch 290/300\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0570 - root_mean_squared_error: 0.2387\n",
      "Epoch 291/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0551 - root_mean_squared_error: 0.2347\n",
      "Epoch 292/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0499 - root_mean_squared_error: 0.2235\n",
      "Epoch 293/300\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0507 - root_mean_squared_error: 0.2251\n",
      "Epoch 294/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0478 - root_mean_squared_error: 0.2187\n",
      "Epoch 295/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0489 - root_mean_squared_error: 0.2212\n",
      "Epoch 296/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0534 - root_mean_squared_error: 0.2310\n",
      "Epoch 297/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0522 - root_mean_squared_error: 0.2284\n",
      "Epoch 298/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0473 - root_mean_squared_error: 0.2176\n",
      "Epoch 299/300\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0441 - root_mean_squared_error: 0.2099\n",
      "Epoch 300/300\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0487 - root_mean_squared_error: 0.2208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327c52ceb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('rice.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e00f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.384105001158986\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for Rice\n",
    "df = pd.read_csv('Rice.csv')\n",
    "y = df['Yield']\n",
    "\n",
    "rmse = 0.2208 \n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f564fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\4196747734.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "11/11 [==============================] - 2s 20ms/step - loss: 119.8524 - root_mean_squared_error: 10.9477\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 55.3023 - root_mean_squared_error: 7.4366\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 29.7906 - root_mean_squared_error: 5.4581\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 26.0992 - root_mean_squared_error: 5.1087\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 23.2521 - root_mean_squared_error: 4.8220\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 19.7363 - root_mean_squared_error: 4.4426\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 16.1506 - root_mean_squared_error: 4.0188\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.8516 - root_mean_squared_error: 3.8538\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 13.7472 - root_mean_squared_error: 3.7077\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.4435 - root_mean_squared_error: 3.6665\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 14.0523 - root_mean_squared_error: 3.7486\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.3915 - root_mean_squared_error: 3.6594\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.7692 - root_mean_squared_error: 3.4306\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.5271 - root_mean_squared_error: 3.3952\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.2298 - root_mean_squared_error: 3.3511\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 11.2513 - root_mean_squared_error: 3.3543\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 11.9913 - root_mean_squared_error: 3.4628\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.8859 - root_mean_squared_error: 3.1442\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.0548 - root_mean_squared_error: 3.3249\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.5244 - root_mean_squared_error: 3.5390\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 10.2310 - root_mean_squared_error: 3.1986\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 10.3674 - root_mean_squared_error: 3.2198\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.4855 - root_mean_squared_error: 3.0798\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1345 - root_mean_squared_error: 3.0223\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.7694 - root_mean_squared_error: 2.9613\n",
      "Epoch 26/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.2155 - root_mean_squared_error: 3.0357\n",
      "Epoch 27/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.8936 - root_mean_squared_error: 2.9822\n",
      "Epoch 28/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.9740 - root_mean_squared_error: 2.9957\n",
      "Epoch 29/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1731 - root_mean_squared_error: 3.0287\n",
      "Epoch 30/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 8.1307 - root_mean_squared_error: 2.8514\n",
      "Epoch 31/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.6632 - root_mean_squared_error: 2.9433\n",
      "Epoch 32/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.9625 - root_mean_squared_error: 2.8218\n",
      "Epoch 33/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.8094 - root_mean_squared_error: 3.1320\n",
      "Epoch 34/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.5998 - root_mean_squared_error: 3.0984\n",
      "Epoch 35/300\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 8.8771 - root_mean_squared_error: 2.9794\n",
      "Epoch 36/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.9411 - root_mean_squared_error: 2.8180\n",
      "Epoch 37/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.1913 - root_mean_squared_error: 2.6817\n",
      "Epoch 38/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 7.1809 - root_mean_squared_error: 2.6797\n",
      "Epoch 39/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.5110 - root_mean_squared_error: 2.7406\n",
      "Epoch 40/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.0037 - root_mean_squared_error: 2.8291\n",
      "Epoch 41/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 8.7816 - root_mean_squared_error: 2.9634\n",
      "Epoch 42/300\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 7.7024 - root_mean_squared_error: 2.7753\n",
      "Epoch 43/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.6716 - root_mean_squared_error: 3.1099\n",
      "Epoch 44/300\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 10.0833 - root_mean_squared_error: 3.1754\n",
      "Epoch 45/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 8.7266 - root_mean_squared_error: 2.9541\n",
      "Epoch 46/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 7.8102 - root_mean_squared_error: 2.7947\n",
      "Epoch 47/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.3262 - root_mean_squared_error: 2.7067\n",
      "Epoch 48/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.1836 - root_mean_squared_error: 2.8607\n",
      "Epoch 49/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.7134 - root_mean_squared_error: 2.5910\n",
      "Epoch 50/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.0325 - root_mean_squared_error: 2.4561\n",
      "Epoch 51/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.0018 - root_mean_squared_error: 2.4499\n",
      "Epoch 52/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.5720 - root_mean_squared_error: 2.5636\n",
      "Epoch 53/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.1398 - root_mean_squared_error: 2.6720\n",
      "Epoch 54/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.2450 - root_mean_squared_error: 2.4990\n",
      "Epoch 55/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.4179 - root_mean_squared_error: 2.5334\n",
      "Epoch 56/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.9020 - root_mean_squared_error: 2.6272\n",
      "Epoch 57/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 7.2471 - root_mean_squared_error: 2.6920\n",
      "Epoch 58/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.1001 - root_mean_squared_error: 2.8461\n",
      "Epoch 59/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.5918 - root_mean_squared_error: 2.3647\n",
      "Epoch 60/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.8261 - root_mean_squared_error: 2.4137\n",
      "Epoch 61/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.1899 - root_mean_squared_error: 2.2781\n",
      "Epoch 62/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 5.6888 - root_mean_squared_error: 2.3851\n",
      "Epoch 63/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.3773 - root_mean_squared_error: 2.3189\n",
      "Epoch 64/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.7396 - root_mean_squared_error: 2.1771\n",
      "Epoch 65/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.7817 - root_mean_squared_error: 2.1867\n",
      "Epoch 66/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.5880 - root_mean_squared_error: 2.1420\n",
      "Epoch 67/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 4.9517 - root_mean_squared_error: 2.2252\n",
      "Epoch 68/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.1513 - root_mean_squared_error: 2.4802\n",
      "Epoch 69/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.2277 - root_mean_squared_error: 2.2864\n",
      "Epoch 70/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.0438 - root_mean_squared_error: 2.2458\n",
      "Epoch 71/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 5.1246 - root_mean_squared_error: 2.2638\n",
      "Epoch 72/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.3112 - root_mean_squared_error: 2.3046\n",
      "Epoch 73/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.2774 - root_mean_squared_error: 2.2973\n",
      "Epoch 74/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.4109 - root_mean_squared_error: 2.3261\n",
      "Epoch 75/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.2954 - root_mean_squared_error: 2.3012\n",
      "Epoch 76/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 6.2707 - root_mean_squared_error: 2.5041\n",
      "Epoch 77/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.0220 - root_mean_squared_error: 2.4540\n",
      "Epoch 78/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.5225 - root_mean_squared_error: 2.3500\n",
      "Epoch 79/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.8207 - root_mean_squared_error: 2.4126\n",
      "Epoch 80/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.8482 - root_mean_squared_error: 2.2019\n",
      "Epoch 81/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.7067 - root_mean_squared_error: 2.1695\n",
      "Epoch 82/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.4448 - root_mean_squared_error: 2.1083\n",
      "Epoch 83/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.7411 - root_mean_squared_error: 2.1774\n",
      "Epoch 84/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.8038 - root_mean_squared_error: 2.1918\n",
      "Epoch 85/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.2444 - root_mean_squared_error: 2.0602\n",
      "Epoch 86/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.9564 - root_mean_squared_error: 1.9891\n",
      "Epoch 87/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 4.0769 - root_mean_squared_error: 2.0191\n",
      "Epoch 88/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.2231 - root_mean_squared_error: 2.0550\n",
      "Epoch 89/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.1626 - root_mean_squared_error: 2.0402\n",
      "Epoch 90/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.7029 - root_mean_squared_error: 2.1686\n",
      "Epoch 91/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.3810 - root_mean_squared_error: 2.0931\n",
      "Epoch 92/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.4649 - root_mean_squared_error: 2.1130\n",
      "Epoch 93/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.4381 - root_mean_squared_error: 2.1067\n",
      "Epoch 94/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.4185 - root_mean_squared_error: 2.3278\n",
      "Epoch 95/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.1421 - root_mean_squared_error: 2.2676\n",
      "Epoch 96/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.7594 - root_mean_squared_error: 2.1816\n",
      "Epoch 97/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.0146 - root_mean_squared_error: 2.4525\n",
      "Epoch 98/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.2433 - root_mean_squared_error: 2.2898\n",
      "Epoch 99/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.6587 - root_mean_squared_error: 2.1584\n",
      "Epoch 100/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.6377 - root_mean_squared_error: 2.1535\n",
      "Epoch 101/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.2502 - root_mean_squared_error: 2.2913\n",
      "Epoch 102/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.3712 - root_mean_squared_error: 2.3176\n",
      "Epoch 103/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.4929 - root_mean_squared_error: 2.1197\n",
      "Epoch 104/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.0903 - root_mean_squared_error: 2.2562\n",
      "Epoch 105/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.8400 - root_mean_squared_error: 2.2000\n",
      "Epoch 106/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.0147 - root_mean_squared_error: 2.0037\n",
      "Epoch 107/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.7943 - root_mean_squared_error: 1.9479\n",
      "Epoch 108/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.4044 - root_mean_squared_error: 2.0987\n",
      "Epoch 109/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.0788 - root_mean_squared_error: 2.0196\n",
      "Epoch 110/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8205 - root_mean_squared_error: 1.9546\n",
      "Epoch 111/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.8067 - root_mean_squared_error: 1.9511\n",
      "Epoch 112/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9922 - root_mean_squared_error: 1.9980\n",
      "Epoch 113/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.3851 - root_mean_squared_error: 2.0941\n",
      "Epoch 114/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.6688 - root_mean_squared_error: 2.1607\n",
      "Epoch 115/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.4439 - root_mean_squared_error: 2.1081\n",
      "Epoch 116/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.1674 - root_mean_squared_error: 2.2732\n",
      "Epoch 117/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.0576 - root_mean_squared_error: 2.2489\n",
      "Epoch 118/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.3193 - root_mean_squared_error: 2.0783\n",
      "Epoch 119/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.8858 - root_mean_squared_error: 2.2104\n",
      "Epoch 120/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.1197 - root_mean_squared_error: 2.0297\n",
      "Epoch 121/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.7068 - root_mean_squared_error: 1.9253\n",
      "Epoch 122/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.7501 - root_mean_squared_error: 1.9365\n",
      "Epoch 123/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.6910 - root_mean_squared_error: 1.9212\n",
      "Epoch 124/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.3443 - root_mean_squared_error: 2.0843\n",
      "Epoch 125/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.5923 - root_mean_squared_error: 2.1430\n",
      "Epoch 126/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.5225 - root_mean_squared_error: 1.8768\n",
      "Epoch 127/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.1941 - root_mean_squared_error: 1.7872\n",
      "Epoch 128/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.1677 - root_mean_squared_error: 1.7798\n",
      "Epoch 129/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.1043 - root_mean_squared_error: 1.7619\n",
      "Epoch 130/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1323 - root_mean_squared_error: 1.7698\n",
      "Epoch 131/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.3573 - root_mean_squared_error: 1.8323\n",
      "Epoch 132/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1300 - root_mean_squared_error: 1.7692\n",
      "Epoch 133/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8168 - root_mean_squared_error: 1.9537\n",
      "Epoch 134/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.9340 - root_mean_squared_error: 2.2213\n",
      "Epoch 135/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.3120 - root_mean_squared_error: 2.0765\n",
      "Epoch 136/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.3133 - root_mean_squared_error: 2.0768\n",
      "Epoch 137/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.3414 - root_mean_squared_error: 2.0836\n",
      "Epoch 138/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.8413 - root_mean_squared_error: 1.9599\n",
      "Epoch 139/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.7970 - root_mean_squared_error: 1.9486\n",
      "Epoch 140/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.8103 - root_mean_squared_error: 1.9520\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 4.1572 - root_mean_squared_error: 2.0389\n",
      "Epoch 142/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.4408 - root_mean_squared_error: 2.3326\n",
      "Epoch 143/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.0101 - root_mean_squared_error: 2.0025\n",
      "Epoch 144/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8091 - root_mean_squared_error: 1.9517\n",
      "Epoch 145/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.7445 - root_mean_squared_error: 2.1782\n",
      "Epoch 146/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.6543 - root_mean_squared_error: 2.5796\n",
      "Epoch 147/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.4641 - root_mean_squared_error: 2.3375\n",
      "Epoch 148/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.4050 - root_mean_squared_error: 2.0988\n",
      "Epoch 149/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.3428 - root_mean_squared_error: 2.0839\n",
      "Epoch 150/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.5115 - root_mean_squared_error: 1.8739\n",
      "Epoch 151/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.3706 - root_mean_squared_error: 1.8359\n",
      "Epoch 152/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.0707 - root_mean_squared_error: 1.7523\n",
      "Epoch 153/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.8932 - root_mean_squared_error: 1.7010\n",
      "Epoch 154/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.9984 - root_mean_squared_error: 1.7316\n",
      "Epoch 155/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.6355 - root_mean_squared_error: 1.9067\n",
      "Epoch 156/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.8732 - root_mean_squared_error: 2.2075\n",
      "Epoch 157/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8892 - root_mean_squared_error: 1.9721\n",
      "Epoch 158/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9500 - root_mean_squared_error: 1.9875\n",
      "Epoch 159/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4860 - root_mean_squared_error: 1.8671\n",
      "Epoch 160/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.1229 - root_mean_squared_error: 1.7672\n",
      "Epoch 161/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1374 - root_mean_squared_error: 1.7713\n",
      "Epoch 162/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.2267 - root_mean_squared_error: 1.7963\n",
      "Epoch 163/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9067 - root_mean_squared_error: 1.9765\n",
      "Epoch 164/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9828 - root_mean_squared_error: 1.9957\n",
      "Epoch 165/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.3797 - root_mean_squared_error: 2.3194\n",
      "Epoch 166/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.3174 - root_mean_squared_error: 2.3059\n",
      "Epoch 167/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.6595 - root_mean_squared_error: 2.3790\n",
      "Epoch 168/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.0265 - root_mean_squared_error: 2.4549\n",
      "Epoch 169/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.2413 - root_mean_squared_error: 2.2894\n",
      "Epoch 170/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.1907 - root_mean_squared_error: 2.0471\n",
      "Epoch 171/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4518 - root_mean_squared_error: 1.8579\n",
      "Epoch 172/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.2933 - root_mean_squared_error: 1.8148\n",
      "Epoch 173/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1800 - root_mean_squared_error: 1.7833\n",
      "Epoch 174/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1854 - root_mean_squared_error: 1.7848\n",
      "Epoch 175/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.1488 - root_mean_squared_error: 1.7745\n",
      "Epoch 176/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.9762 - root_mean_squared_error: 1.7252\n",
      "Epoch 177/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.8439 - root_mean_squared_error: 1.6864\n",
      "Epoch 178/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.9019 - root_mean_squared_error: 1.7035\n",
      "Epoch 179/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.9142 - root_mean_squared_error: 1.7071\n",
      "Epoch 180/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.0455 - root_mean_squared_error: 1.7451\n",
      "Epoch 181/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.7915 - root_mean_squared_error: 1.6708\n",
      "Epoch 182/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6893 - root_mean_squared_error: 1.6399\n",
      "Epoch 183/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.9720 - root_mean_squared_error: 1.7239\n",
      "Epoch 184/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.8377 - root_mean_squared_error: 1.6846\n",
      "Epoch 185/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.7493 - root_mean_squared_error: 1.6581\n",
      "Epoch 186/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.7885 - root_mean_squared_error: 1.6699\n",
      "Epoch 187/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.7660 - root_mean_squared_error: 1.9406\n",
      "Epoch 188/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9330 - root_mean_squared_error: 1.9832\n",
      "Epoch 189/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.7615 - root_mean_squared_error: 1.9395\n",
      "Epoch 190/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.2588 - root_mean_squared_error: 1.8052\n",
      "Epoch 191/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8878 - root_mean_squared_error: 1.9718\n",
      "Epoch 192/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.0663 - root_mean_squared_error: 2.0165\n",
      "Epoch 193/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.5846 - root_mean_squared_error: 1.8933\n",
      "Epoch 194/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8201 - root_mean_squared_error: 1.9545\n",
      "Epoch 195/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 3.9072 - root_mean_squared_error: 1.9767\n",
      "Epoch 196/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.6040 - root_mean_squared_error: 1.8984\n",
      "Epoch 197/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8503 - root_mean_squared_error: 1.9622\n",
      "Epoch 198/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.4736 - root_mean_squared_error: 1.8638\n",
      "Epoch 199/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.8498 - root_mean_squared_error: 1.9621\n",
      "Epoch 200/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.3294 - root_mean_squared_error: 1.8247\n",
      "Epoch 201/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.8524 - root_mean_squared_error: 1.9627\n",
      "Epoch 202/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.0219 - root_mean_squared_error: 1.7384\n",
      "Epoch 203/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.9179 - root_mean_squared_error: 1.7082\n",
      "Epoch 204/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.8393 - root_mean_squared_error: 1.6850\n",
      "Epoch 205/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4403 - root_mean_squared_error: 1.5621\n",
      "Epoch 206/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6508 - root_mean_squared_error: 1.6281\n",
      "Epoch 207/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4769 - root_mean_squared_error: 1.5738\n",
      "Epoch 208/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.5815 - root_mean_squared_error: 1.6067\n",
      "Epoch 209/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.5560 - root_mean_squared_error: 1.5987\n",
      "Epoch 210/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.5779 - root_mean_squared_error: 1.6056\n",
      "Epoch 211/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.0975 - root_mean_squared_error: 1.7600\n",
      "Epoch 212/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4004 - root_mean_squared_error: 1.8440\n",
      "Epoch 213/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 3.0446 - root_mean_squared_error: 1.7449\n",
      "Epoch 214/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1637 - root_mean_squared_error: 1.7787\n",
      "Epoch 215/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.3325 - root_mean_squared_error: 1.8255\n",
      "Epoch 216/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.6081 - root_mean_squared_error: 1.8995\n",
      "Epoch 217/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.4995 - root_mean_squared_error: 1.8707\n",
      "Epoch 218/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.0412 - root_mean_squared_error: 1.7439\n",
      "Epoch 219/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.7738 - root_mean_squared_error: 1.6655\n",
      "Epoch 220/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6095 - root_mean_squared_error: 1.6154\n",
      "Epoch 221/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.7525 - root_mean_squared_error: 1.6591\n",
      "Epoch 222/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.4635 - root_mean_squared_error: 1.5695\n",
      "Epoch 223/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.6296 - root_mean_squared_error: 1.6216\n",
      "Epoch 224/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.2169 - root_mean_squared_error: 1.7936\n",
      "Epoch 225/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 4.0735 - root_mean_squared_error: 2.0183\n",
      "Epoch 226/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.1410 - root_mean_squared_error: 1.7723\n",
      "Epoch 227/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 3.1996 - root_mean_squared_error: 1.7888\n",
      "Epoch 228/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4067 - root_mean_squared_error: 1.8457\n",
      "Epoch 229/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.7142 - root_mean_squared_error: 1.9272\n",
      "Epoch 230/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.2216 - root_mean_squared_error: 1.7949\n",
      "Epoch 231/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.5849 - root_mean_squared_error: 1.8934\n",
      "Epoch 232/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1613 - root_mean_squared_error: 1.7780\n",
      "Epoch 233/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.1014 - root_mean_squared_error: 1.7611\n",
      "Epoch 234/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1458 - root_mean_squared_error: 1.7736\n",
      "Epoch 235/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.1799 - root_mean_squared_error: 1.7832\n",
      "Epoch 236/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.0488 - root_mean_squared_error: 2.0122\n",
      "Epoch 237/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.1747 - root_mean_squared_error: 2.0432\n",
      "Epoch 238/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.8115 - root_mean_squared_error: 1.9523\n",
      "Epoch 239/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.9487 - root_mean_squared_error: 1.7172\n",
      "Epoch 240/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6978 - root_mean_squared_error: 1.6425\n",
      "Epoch 241/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4245 - root_mean_squared_error: 1.5571\n",
      "Epoch 242/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4956 - root_mean_squared_error: 1.5797\n",
      "Epoch 243/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4568 - root_mean_squared_error: 1.5674\n",
      "Epoch 244/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5522 - root_mean_squared_error: 1.5976\n",
      "Epoch 245/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.9178 - root_mean_squared_error: 1.7081\n",
      "Epoch 246/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.9006 - root_mean_squared_error: 1.7031\n",
      "Epoch 247/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4032 - root_mean_squared_error: 1.5502\n",
      "Epoch 248/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.4863 - root_mean_squared_error: 1.5768\n",
      "Epoch 249/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4457 - root_mean_squared_error: 1.5639\n",
      "Epoch 250/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.7539 - root_mean_squared_error: 1.6595\n",
      "Epoch 251/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.9006 - root_mean_squared_error: 1.7031\n",
      "Epoch 252/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6936 - root_mean_squared_error: 1.6412\n",
      "Epoch 253/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.3228 - root_mean_squared_error: 1.8228\n",
      "Epoch 254/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.6173 - root_mean_squared_error: 1.9019\n",
      "Epoch 255/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.7788 - root_mean_squared_error: 1.9439\n",
      "Epoch 256/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.1437 - root_mean_squared_error: 2.0356\n",
      "Epoch 257/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.3644 - root_mean_squared_error: 2.0891\n",
      "Epoch 258/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.4604 - root_mean_squared_error: 1.8602\n",
      "Epoch 259/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.2168 - root_mean_squared_error: 1.7935\n",
      "Epoch 260/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.1971 - root_mean_squared_error: 1.7880\n",
      "Epoch 261/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.8790 - root_mean_squared_error: 1.6968\n",
      "Epoch 262/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.6245 - root_mean_squared_error: 1.6200\n",
      "Epoch 263/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.5524 - root_mean_squared_error: 1.5976\n",
      "Epoch 264/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.3651 - root_mean_squared_error: 1.5379\n",
      "Epoch 265/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5985 - root_mean_squared_error: 1.6120\n",
      "Epoch 266/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4905 - root_mean_squared_error: 1.5781\n",
      "Epoch 267/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3636 - root_mean_squared_error: 1.5374\n",
      "Epoch 268/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4961 - root_mean_squared_error: 1.5799\n",
      "Epoch 269/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.2861 - root_mean_squared_error: 1.5120\n",
      "Epoch 270/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4637 - root_mean_squared_error: 1.5696\n",
      "Epoch 271/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3025 - root_mean_squared_error: 1.5174\n",
      "Epoch 272/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4611 - root_mean_squared_error: 1.5688\n",
      "Epoch 273/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.6409 - root_mean_squared_error: 1.6251\n",
      "Epoch 274/300\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2996 - root_mean_squared_error: 1.5165\n",
      "Epoch 275/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4148 - root_mean_squared_error: 1.5540\n",
      "Epoch 276/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3087 - root_mean_squared_error: 1.5194\n",
      "Epoch 277/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5895 - root_mean_squared_error: 1.6092\n",
      "Epoch 278/300\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.9371 - root_mean_squared_error: 1.7138\n",
      "Epoch 279/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4374 - root_mean_squared_error: 1.5612\n",
      "Epoch 280/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.5790 - root_mean_squared_error: 1.6059\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6923 - root_mean_squared_error: 1.6408\n",
      "Epoch 282/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.3460 - root_mean_squared_error: 1.5317\n",
      "Epoch 283/300\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.3072 - root_mean_squared_error: 1.5189\n",
      "Epoch 284/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5262 - root_mean_squared_error: 1.5894\n",
      "Epoch 285/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6514 - root_mean_squared_error: 1.6283\n",
      "Epoch 286/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5479 - root_mean_squared_error: 1.5962\n",
      "Epoch 287/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4158 - root_mean_squared_error: 1.5543\n",
      "Epoch 288/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4755 - root_mean_squared_error: 1.5734\n",
      "Epoch 289/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3830 - root_mean_squared_error: 1.5437\n",
      "Epoch 290/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4372 - root_mean_squared_error: 1.5612\n",
      "Epoch 291/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6381 - root_mean_squared_error: 1.6242\n",
      "Epoch 292/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.5980 - root_mean_squared_error: 1.6118\n",
      "Epoch 293/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4448 - root_mean_squared_error: 1.5636\n",
      "Epoch 294/300\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.4792 - root_mean_squared_error: 1.5745\n",
      "Epoch 295/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4625 - root_mean_squared_error: 1.5692\n",
      "Epoch 296/300\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.4192 - root_mean_squared_error: 1.5554\n",
      "Epoch 297/300\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.5071 - root_mean_squared_error: 1.5834\n",
      "Epoch 298/300\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.3194 - root_mean_squared_error: 1.5230\n",
      "Epoch 299/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.3590 - root_mean_squared_error: 1.5359\n",
      "Epoch 300/300\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4930 - root_mean_squared_error: 1.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327f262190>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Potato.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc46ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.877266054337413\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for Potato\n",
    "df = pd.read_csv('Potato.csv')\n",
    "y = df['Yield']\n",
    "\n",
    "rmse = 1.5789\n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0b27c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\1517975518.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 4s 16ms/step - loss: 1.3959 - root_mean_squared_error: 1.1815\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3897 - root_mean_squared_error: 0.6243\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2066 - root_mean_squared_error: 0.4546\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1517 - root_mean_squared_error: 0.3894\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1247 - root_mean_squared_error: 0.3531\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1203 - root_mean_squared_error: 0.3468\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1226 - root_mean_squared_error: 0.3502\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1062 - root_mean_squared_error: 0.3258\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0934 - root_mean_squared_error: 0.3057\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1037 - root_mean_squared_error: 0.3221\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1017 - root_mean_squared_error: 0.3190\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1031 - root_mean_squared_error: 0.3211\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0958 - root_mean_squared_error: 0.3094\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0906 - root_mean_squared_error: 0.3009\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1011 - root_mean_squared_error: 0.3179\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0844 - root_mean_squared_error: 0.2905\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0870 - root_mean_squared_error: 0.2950\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0810 - root_mean_squared_error: 0.2846\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0858 - root_mean_squared_error: 0.2928\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0836 - root_mean_squared_error: 0.2892\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0878 - root_mean_squared_error: 0.2963\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0881 - root_mean_squared_error: 0.2967\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0711 - root_mean_squared_error: 0.2667\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0742 - root_mean_squared_error: 0.2724\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0793 - root_mean_squared_error: 0.2816\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0705 - root_mean_squared_error: 0.2654\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0944 - root_mean_squared_error: 0.3072\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0848 - root_mean_squared_error: 0.2913\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0710 - root_mean_squared_error: 0.2665\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0629 - root_mean_squared_error: 0.2508\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0659 - root_mean_squared_error: 0.2567\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0595 - root_mean_squared_error: 0.2439\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0682 - root_mean_squared_error: 0.2612\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0613 - root_mean_squared_error: 0.2476\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0763 - root_mean_squared_error: 0.2762\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0651 - root_mean_squared_error: 0.2551\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0655 - root_mean_squared_error: 0.2560\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0800 - root_mean_squared_error: 0.2828\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0671 - root_mean_squared_error: 0.2591\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0648 - root_mean_squared_error: 0.2545\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0656 - root_mean_squared_error: 0.2562\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0655 - root_mean_squared_error: 0.2560\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0560 - root_mean_squared_error: 0.2367\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0543 - root_mean_squared_error: 0.2331\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0521 - root_mean_squared_error: 0.2282\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0577 - root_mean_squared_error: 0.2402\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0551 - root_mean_squared_error: 0.2347\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0519 - root_mean_squared_error: 0.2278\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0493 - root_mean_squared_error: 0.2221\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0529 - root_mean_squared_error: 0.2300\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0510 - root_mean_squared_error: 0.2258\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0449 - root_mean_squared_error: 0.2119\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0508 - root_mean_squared_error: 0.2254\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0493 - root_mean_squared_error: 0.2220\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0484 - root_mean_squared_error: 0.2200\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0512 - root_mean_squared_error: 0.2263\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0425 - root_mean_squared_error: 0.2060\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0364 - root_mean_squared_error: 0.1909\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0348 - root_mean_squared_error: 0.1866\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0461 - root_mean_squared_error: 0.2147\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0418 - root_mean_squared_error: 0.2043\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0583 - root_mean_squared_error: 0.2416\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0509 - root_mean_squared_error: 0.2255\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0729 - root_mean_squared_error: 0.2700\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0648 - root_mean_squared_error: 0.2547\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0536 - root_mean_squared_error: 0.2315\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0581 - root_mean_squared_error: 0.2411\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0437 - root_mean_squared_error: 0.2090\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0456 - root_mean_squared_error: 0.2136\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0586 - root_mean_squared_error: 0.2420\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0505 - root_mean_squared_error: 0.2246\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0479 - root_mean_squared_error: 0.2190\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0458 - root_mean_squared_error: 0.2141\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0381 - root_mean_squared_error: 0.1952\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0434 - root_mean_squared_error: 0.2082\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0435 - root_mean_squared_error: 0.2086\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0401 - root_mean_squared_error: 0.2002\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0360 - root_mean_squared_error: 0.1897\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0329 - root_mean_squared_error: 0.1814\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0350 - root_mean_squared_error: 0.1872\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0294 - root_mean_squared_error: 0.1715\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0386 - root_mean_squared_error: 0.1966\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0490 - root_mean_squared_error: 0.2213\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0455 - root_mean_squared_error: 0.2134\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0478 - root_mean_squared_error: 0.2186\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0532 - root_mean_squared_error: 0.2305\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0378 - root_mean_squared_error: 0.1943\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0416 - root_mean_squared_error: 0.2041\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0360 - root_mean_squared_error: 0.1897\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0303 - root_mean_squared_error: 0.1740\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0302 - root_mean_squared_error: 0.1737\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0296 - root_mean_squared_error: 0.1720\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0305 - root_mean_squared_error: 0.1747\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0286 - root_mean_squared_error: 0.1690\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0284 - root_mean_squared_error: 0.1684\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0288 - root_mean_squared_error: 0.1698\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0235 - root_mean_squared_error: 0.1533\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0267 - root_mean_squared_error: 0.1634\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0430 - root_mean_squared_error: 0.2073\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0310 - root_mean_squared_error: 0.1759\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0325 - root_mean_squared_error: 0.1803\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0263 - root_mean_squared_error: 0.1623\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0318 - root_mean_squared_error: 0.1784\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0238 - root_mean_squared_error: 0.1543\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0257 - root_mean_squared_error: 0.1603\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0199 - root_mean_squared_error: 0.1411\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0204 - root_mean_squared_error: 0.1429\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0295 - root_mean_squared_error: 0.1719\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0258 - root_mean_squared_error: 0.1606\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0270 - root_mean_squared_error: 0.1645\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0306 - root_mean_squared_error: 0.1750\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0297 - root_mean_squared_error: 0.1723\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0294 - root_mean_squared_error: 0.1714\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0422 - root_mean_squared_error: 0.2053\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0523 - root_mean_squared_error: 0.2288\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0514 - root_mean_squared_error: 0.2267\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0549 - root_mean_squared_error: 0.2343\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0426 - root_mean_squared_error: 0.2064\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0423 - root_mean_squared_error: 0.2056\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0376 - root_mean_squared_error: 0.1938\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0327 - root_mean_squared_error: 0.1808\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0237 - root_mean_squared_error: 0.1538\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0216 - root_mean_squared_error: 0.1470\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0213 - root_mean_squared_error: 0.1459\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0213 - root_mean_squared_error: 0.1460\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0217 - root_mean_squared_error: 0.1472\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0299 - root_mean_squared_error: 0.1729\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0304 - root_mean_squared_error: 0.1742\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0228 - root_mean_squared_error: 0.1508\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0245 - root_mean_squared_error: 0.1564\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0436 - root_mean_squared_error: 0.2087\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0510 - root_mean_squared_error: 0.2259\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0469 - root_mean_squared_error: 0.2166\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0422 - root_mean_squared_error: 0.2054\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0368 - root_mean_squared_error: 0.1919\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0419 - root_mean_squared_error: 0.2047\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0475 - root_mean_squared_error: 0.2178\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0400 - root_mean_squared_error: 0.1999\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0327 - root_mean_squared_error: 0.1808\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0309 - root_mean_squared_error: 0.1758\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0264 - root_mean_squared_error: 0.1625\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0212 - root_mean_squared_error: 0.1458\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0201 - root_mean_squared_error: 0.1419\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0158 - root_mean_squared_error: 0.1259\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0145 - root_mean_squared_error: 0.1206\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0225 - root_mean_squared_error: 0.1501\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0211 - root_mean_squared_error: 0.1454\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0211 - root_mean_squared_error: 0.1451\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0164 - root_mean_squared_error: 0.1283\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0152 - root_mean_squared_error: 0.1234\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0155 - root_mean_squared_error: 0.1244\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0236 - root_mean_squared_error: 0.1537\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0225 - root_mean_squared_error: 0.1498\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0301 - root_mean_squared_error: 0.1734\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0332 - root_mean_squared_error: 0.1822\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0410 - root_mean_squared_error: 0.2026\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0287 - root_mean_squared_error: 0.1693\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0194 - root_mean_squared_error: 0.1392\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0126 - root_mean_squared_error: 0.1124\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0114 - root_mean_squared_error: 0.1066\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0126 - root_mean_squared_error: 0.1122\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0203 - root_mean_squared_error: 0.1424\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0171 - root_mean_squared_error: 0.1306\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0256 - root_mean_squared_error: 0.1599\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0260 - root_mean_squared_error: 0.1611\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0214 - root_mean_squared_error: 0.1464\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0230 - root_mean_squared_error: 0.1515\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0193 - root_mean_squared_error: 0.1391\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0154 - root_mean_squared_error: 0.1240\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0146 - root_mean_squared_error: 0.1207\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - root_mean_squared_error: 0.1193\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0153 - root_mean_squared_error: 0.1237\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0145 - root_mean_squared_error: 0.1204\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0133 - root_mean_squared_error: 0.1151\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0326 - root_mean_squared_error: 0.1807\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0516 - root_mean_squared_error: 0.2271\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0247 - root_mean_squared_error: 0.1571\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0245 - root_mean_squared_error: 0.1564\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0193 - root_mean_squared_error: 0.1389\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0153 - root_mean_squared_error: 0.1236\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0120 - root_mean_squared_error: 0.1093\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0110 - root_mean_squared_error: 0.1047\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0115 - root_mean_squared_error: 0.1072\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0180 - root_mean_squared_error: 0.1342\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0104 - root_mean_squared_error: 0.1020\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0107 - root_mean_squared_error: 0.1033\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0143 - root_mean_squared_error: 0.1194\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0363 - root_mean_squared_error: 0.1905\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0216 - root_mean_squared_error: 0.1469\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0149 - root_mean_squared_error: 0.1219\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0137 - root_mean_squared_error: 0.1170\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0103 - root_mean_squared_error: 0.1015\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0095 - root_mean_squared_error: 0.0974\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0100 - root_mean_squared_error: 0.1002\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0096 - root_mean_squared_error: 0.0978\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0072 - root_mean_squared_error: 0.0848\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0080 - root_mean_squared_error: 0.0894\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0074 - root_mean_squared_error: 0.0858\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0072 - root_mean_squared_error: 0.0847\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0150 - root_mean_squared_error: 0.1224\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0115 - root_mean_squared_error: 0.1070\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0098 - root_mean_squared_error: 0.0992\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0121 - root_mean_squared_error: 0.1099\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0269 - root_mean_squared_error: 0.1640\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0259 - root_mean_squared_error: 0.1610\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0238 - root_mean_squared_error: 0.1544\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0245 - root_mean_squared_error: 0.1565\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0220 - root_mean_squared_error: 0.1485\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0219 - root_mean_squared_error: 0.1480\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0189 - root_mean_squared_error: 0.1375\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0252 - root_mean_squared_error: 0.1588\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0176 - root_mean_squared_error: 0.1326\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0128 - root_mean_squared_error: 0.1129\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327f7c7eb0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Soyabean.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afbfa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.279302265831683\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for Soybean \n",
    "df = pd.read_csv('Soyabean.csv')\n",
    "y = df['Yield']\n",
    "\n",
    "rmse = 0.0945\n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecd58007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\2934155627.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 2s 20ms/step - loss: 1.7669 - root_mean_squared_error: 1.3293\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9661 - root_mean_squared_error: 0.9829\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6570 - root_mean_squared_error: 0.8106\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4547 - root_mean_squared_error: 0.6743\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3895 - root_mean_squared_error: 0.6241\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3894 - root_mean_squared_error: 0.6240\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3667 - root_mean_squared_error: 0.6055\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3762 - root_mean_squared_error: 0.6134\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3209 - root_mean_squared_error: 0.5665\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2617 - root_mean_squared_error: 0.5116\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2493 - root_mean_squared_error: 0.4993\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2569 - root_mean_squared_error: 0.5069\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2935 - root_mean_squared_error: 0.5417\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2658 - root_mean_squared_error: 0.5156\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2316 - root_mean_squared_error: 0.4812\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1935 - root_mean_squared_error: 0.4399\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1809 - root_mean_squared_error: 0.4253\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1605 - root_mean_squared_error: 0.4006\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1651 - root_mean_squared_error: 0.4064\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1851 - root_mean_squared_error: 0.4302\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1437 - root_mean_squared_error: 0.3791\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1268 - root_mean_squared_error: 0.3561\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1573 - root_mean_squared_error: 0.3967\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1210 - root_mean_squared_error: 0.3478\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0988 - root_mean_squared_error: 0.3143\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0958 - root_mean_squared_error: 0.3095\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0716 - root_mean_squared_error: 0.2676\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1392 - root_mean_squared_error: 0.3732\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1415 - root_mean_squared_error: 0.3762\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1293 - root_mean_squared_error: 0.3595\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0978 - root_mean_squared_error: 0.3128\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1091 - root_mean_squared_error: 0.3302\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1115 - root_mean_squared_error: 0.3339\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0974 - root_mean_squared_error: 0.3120\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0693 - root_mean_squared_error: 0.2632\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0592 - root_mean_squared_error: 0.2434\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0533 - root_mean_squared_error: 0.2310\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0536 - root_mean_squared_error: 0.2315\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0435 - root_mean_squared_error: 0.2087\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0330 - root_mean_squared_error: 0.1815\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0298 - root_mean_squared_error: 0.1727\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0464 - root_mean_squared_error: 0.2155\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0502 - root_mean_squared_error: 0.2241\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0849 - root_mean_squared_error: 0.2915\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0843 - root_mean_squared_error: 0.2904\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0631 - root_mean_squared_error: 0.2513\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0478 - root_mean_squared_error: 0.2186\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0424 - root_mean_squared_error: 0.2059\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0331 - root_mean_squared_error: 0.1819\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0298 - root_mean_squared_error: 0.1727\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0310 - root_mean_squared_error: 0.1761\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0284 - root_mean_squared_error: 0.1686\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0247 - root_mean_squared_error: 0.1571\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0240 - root_mean_squared_error: 0.1548\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0238 - root_mean_squared_error: 0.1544\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0237 - root_mean_squared_error: 0.1539\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0318 - root_mean_squared_error: 0.1784\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0313 - root_mean_squared_error: 0.1770\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0347 - root_mean_squared_error: 0.1863\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0291 - root_mean_squared_error: 0.1707\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0348 - root_mean_squared_error: 0.1864\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0271 - root_mean_squared_error: 0.1647\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0284 - root_mean_squared_error: 0.1686\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0310 - root_mean_squared_error: 0.1760\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0435 - root_mean_squared_error: 0.2086\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0406 - root_mean_squared_error: 0.2014\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0430 - root_mean_squared_error: 0.2074\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0330 - root_mean_squared_error: 0.1817\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0279 - root_mean_squared_error: 0.1670\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0249 - root_mean_squared_error: 0.1579\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0228 - root_mean_squared_error: 0.1509\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0226 - root_mean_squared_error: 0.1503\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - root_mean_squared_error: 0.1406\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0205 - root_mean_squared_error: 0.1431\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0234 - root_mean_squared_error: 0.1528\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0189 - root_mean_squared_error: 0.1374\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0193 - root_mean_squared_error: 0.1388\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0296 - root_mean_squared_error: 0.1722\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0202 - root_mean_squared_error: 0.1420\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0250 - root_mean_squared_error: 0.1582\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0257 - root_mean_squared_error: 0.1605\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0194 - root_mean_squared_error: 0.1392\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0161 - root_mean_squared_error: 0.1271\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0228 - root_mean_squared_error: 0.1508\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0215 - root_mean_squared_error: 0.1468\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - root_mean_squared_error: 0.1406\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - root_mean_squared_error: 0.1436\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0221 - root_mean_squared_error: 0.1487\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0272 - root_mean_squared_error: 0.1649\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0238 - root_mean_squared_error: 0.1544\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0251 - root_mean_squared_error: 0.1586\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0272 - root_mean_squared_error: 0.1648\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0450 - root_mean_squared_error: 0.2122\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0386 - root_mean_squared_error: 0.1964\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0329 - root_mean_squared_error: 0.1813\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0273 - root_mean_squared_error: 0.1651\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0402 - root_mean_squared_error: 0.2006\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0243 - root_mean_squared_error: 0.1559\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0236 - root_mean_squared_error: 0.1537\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0416 - root_mean_squared_error: 0.2039\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0278 - root_mean_squared_error: 0.1666\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0279 - root_mean_squared_error: 0.1671\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - root_mean_squared_error: 0.1595\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0218 - root_mean_squared_error: 0.1477\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0299 - root_mean_squared_error: 0.1730\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0325 - root_mean_squared_error: 0.1804\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0418 - root_mean_squared_error: 0.2045\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0297 - root_mean_squared_error: 0.1722\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0258 - root_mean_squared_error: 0.1606\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0179 - root_mean_squared_error: 0.1336\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0181 - root_mean_squared_error: 0.1344\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0215 - root_mean_squared_error: 0.1466\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0220 - root_mean_squared_error: 0.1484\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0225 - root_mean_squared_error: 0.1502\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0200 - root_mean_squared_error: 0.1415\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0164 - root_mean_squared_error: 0.1279\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0177 - root_mean_squared_error: 0.1330\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0161 - root_mean_squared_error: 0.1269\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0155 - root_mean_squared_error: 0.1245\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0227 - root_mean_squared_error: 0.1506\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0173 - root_mean_squared_error: 0.1314\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0180 - root_mean_squared_error: 0.1343\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0172 - root_mean_squared_error: 0.1311\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0155 - root_mean_squared_error: 0.1246\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - root_mean_squared_error: 0.1277\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0148 - root_mean_squared_error: 0.1218\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0153 - root_mean_squared_error: 0.1238\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0277 - root_mean_squared_error: 0.1666\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0290 - root_mean_squared_error: 0.1704\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0356 - root_mean_squared_error: 0.1888\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0333 - root_mean_squared_error: 0.1826\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0387 - root_mean_squared_error: 0.1967\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0346 - root_mean_squared_error: 0.1860\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0418 - root_mean_squared_error: 0.2045\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0497 - root_mean_squared_error: 0.2228\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0329 - root_mean_squared_error: 0.1815\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0241 - root_mean_squared_error: 0.1553\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0227 - root_mean_squared_error: 0.1506\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - root_mean_squared_error: 0.1465\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0155 - root_mean_squared_error: 0.1244\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0152 - root_mean_squared_error: 0.1233\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0145 - root_mean_squared_error: 0.1205\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0163 - root_mean_squared_error: 0.1278\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0167 - root_mean_squared_error: 0.1294\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0164 - root_mean_squared_error: 0.1282\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0214 - root_mean_squared_error: 0.1462\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0165 - root_mean_squared_error: 0.1283\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0154 - root_mean_squared_error: 0.1243\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0152 - root_mean_squared_error: 0.1231\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0146 - root_mean_squared_error: 0.1207\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - root_mean_squared_error: 0.1226\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0160 - root_mean_squared_error: 0.1266\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0141 - root_mean_squared_error: 0.1187\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0133 - root_mean_squared_error: 0.1154\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0121 - root_mean_squared_error: 0.1100\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0135 - root_mean_squared_error: 0.1162\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0134 - root_mean_squared_error: 0.1158\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - root_mean_squared_error: 0.1168\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0253 - root_mean_squared_error: 0.1589\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0254 - root_mean_squared_error: 0.1592\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0255 - root_mean_squared_error: 0.1598\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - root_mean_squared_error: 0.1436\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0231 - root_mean_squared_error: 0.1521\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0191 - root_mean_squared_error: 0.1383\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0149 - root_mean_squared_error: 0.1221\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - root_mean_squared_error: 0.1227\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0140 - root_mean_squared_error: 0.1185\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0135 - root_mean_squared_error: 0.1164\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0138 - root_mean_squared_error: 0.1177\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0145 - root_mean_squared_error: 0.1203\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0161 - root_mean_squared_error: 0.1271\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0141 - root_mean_squared_error: 0.1189\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0150 - root_mean_squared_error: 0.1225\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - root_mean_squared_error: 0.1202\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0204 - root_mean_squared_error: 0.1429\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0159 - root_mean_squared_error: 0.1260\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0163 - root_mean_squared_error: 0.1275\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0152 - root_mean_squared_error: 0.1234\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0142 - root_mean_squared_error: 0.1190\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0131 - root_mean_squared_error: 0.1146\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0140 - root_mean_squared_error: 0.1183\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0149 - root_mean_squared_error: 0.1221\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0146 - root_mean_squared_error: 0.1207\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0140 - root_mean_squared_error: 0.1183\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0150 - root_mean_squared_error: 0.1226\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - root_mean_squared_error: 0.1454\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0177 - root_mean_squared_error: 0.1330\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0178 - root_mean_squared_error: 0.1333\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0180 - root_mean_squared_error: 0.1342\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - root_mean_squared_error: 0.1408\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0189 - root_mean_squared_error: 0.1377\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0163 - root_mean_squared_error: 0.1276\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0151 - root_mean_squared_error: 0.1230\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0160 - root_mean_squared_error: 0.1266\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0222 - root_mean_squared_error: 0.1491\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0624 - root_mean_squared_error: 0.2499\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0539 - root_mean_squared_error: 0.2321\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1175 - root_mean_squared_error: 0.3428\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0955 - root_mean_squared_error: 0.3090\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0806 - root_mean_squared_error: 0.2838\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1187 - root_mean_squared_error: 0.3446\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1118 - root_mean_squared_error: 0.3344\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1639 - root_mean_squared_error: 0.4049\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0993 - root_mean_squared_error: 0.3152\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0769 - root_mean_squared_error: 0.2773\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0716 - root_mean_squared_error: 0.2675\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0582 - root_mean_squared_error: 0.2413\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0840 - root_mean_squared_error: 0.2898\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0682 - root_mean_squared_error: 0.2612\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0407 - root_mean_squared_error: 0.2017\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0344 - root_mean_squared_error: 0.1855\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0300 - root_mean_squared_error: 0.1733\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2327fa2b370>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('ragi.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69a6b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.718759583700772\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for Ragi\n",
    "df = pd.read_csv('Soyabean.csv')\n",
    "y = df['Yield']\n",
    "\n",
    "rmse = 0.1680\n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a1fcc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp\\ipykernel_28920\\2287612951.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[features] = scaler.fit_transform(X[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 16ms/step - loss: 385.5228 - root_mean_squared_error: 19.6347\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 264.8471 - root_mean_squared_error: 16.2741\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 164.6393 - root_mean_squared_error: 12.8312\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 109.0442 - root_mean_squared_error: 10.4424\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 67.9978 - root_mean_squared_error: 8.2461\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 49.9590 - root_mean_squared_error: 7.0682\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 36.8803 - root_mean_squared_error: 6.0729\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 27.0591 - root_mean_squared_error: 5.2018\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 23.9115 - root_mean_squared_error: 4.8899\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 18.7768 - root_mean_squared_error: 4.3332\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18.1861 - root_mean_squared_error: 4.2645\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 17.9519 - root_mean_squared_error: 4.2370\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14.5921 - root_mean_squared_error: 3.8200\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 15.2957 - root_mean_squared_error: 3.9110\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 13.4894 - root_mean_squared_error: 3.6728\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 13.9047 - root_mean_squared_error: 3.7289\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 13.1483 - root_mean_squared_error: 3.6261\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 12.5652 - root_mean_squared_error: 3.5447\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 12.6084 - root_mean_squared_error: 3.5508\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.5692 - root_mean_squared_error: 3.4014\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.9474 - root_mean_squared_error: 3.4565\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 10.8898 - root_mean_squared_error: 3.3000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11.0684 - root_mean_squared_error: 3.3269\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.7675 - root_mean_squared_error: 3.2814\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 14.6615 - root_mean_squared_error: 3.8290\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 11.5218 - root_mean_squared_error: 3.3944\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.7963 - root_mean_squared_error: 3.1299\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.8984 - root_mean_squared_error: 3.1462\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 10.0788 - root_mean_squared_error: 3.1747\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 11.2007 - root_mean_squared_error: 3.3467\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 13.3587 - root_mean_squared_error: 3.6550\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 12.3234 - root_mean_squared_error: 3.5105\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.5305 - root_mean_squared_error: 4.3047\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 11.0671 - root_mean_squared_error: 3.3267\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 10.0512 - root_mean_squared_error: 3.1704\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 11.4119 - root_mean_squared_error: 3.3782\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 8.5467 - root_mean_squared_error: 2.9235\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 11.1600 - root_mean_squared_error: 3.3407\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.7128 - root_mean_squared_error: 2.9517\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 10.6864 - root_mean_squared_error: 3.2690\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 10.4773 - root_mean_squared_error: 3.2369\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.9076 - root_mean_squared_error: 3.1476\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.5703 - root_mean_squared_error: 2.9275\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.0851 - root_mean_squared_error: 2.8434\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.2038 - root_mean_squared_error: 2.8642\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.0364 - root_mean_squared_error: 2.8349\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.0025 - root_mean_squared_error: 2.6462\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.3516 - root_mean_squared_error: 3.0580\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.2779 - root_mean_squared_error: 2.8771\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.9882 - root_mean_squared_error: 2.8263\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.9579 - root_mean_squared_error: 2.6378\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.1433 - root_mean_squared_error: 2.6727\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1402 - root_mean_squared_error: 2.6721\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.4865 - root_mean_squared_error: 2.7362\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4822 - root_mean_squared_error: 2.7354\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.7195 - root_mean_squared_error: 2.5922\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.3180 - root_mean_squared_error: 2.7052\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.1507 - root_mean_squared_error: 2.4801\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7024 - root_mean_squared_error: 2.3880\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8404 - root_mean_squared_error: 2.4167\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.6386 - root_mean_squared_error: 2.3746\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.5840 - root_mean_squared_error: 2.3630\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0309 - root_mean_squared_error: 2.4558\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.8845 - root_mean_squared_error: 2.6238\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.3763 - root_mean_squared_error: 2.5251\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1334 - root_mean_squared_error: 2.4766\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.5105 - root_mean_squared_error: 2.3474\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.0253 - root_mean_squared_error: 2.4546\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.3457 - root_mean_squared_error: 2.5191\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.4495 - root_mean_squared_error: 2.3344\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.3051 - root_mean_squared_error: 2.5110\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.1321 - root_mean_squared_error: 2.2654\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.7587 - root_mean_squared_error: 2.3997\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.9729 - root_mean_squared_error: 2.4440\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.4600 - root_mean_squared_error: 2.3367\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.8023 - root_mean_squared_error: 2.6081\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.9461 - root_mean_squared_error: 2.4385\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.4820 - root_mean_squared_error: 2.7353\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.3334 - root_mean_squared_error: 2.5166\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.9897 - root_mean_squared_error: 2.8266\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.9483 - root_mean_squared_error: 2.4389\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.2682 - root_mean_squared_error: 2.6960\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.9939 - root_mean_squared_error: 2.2347\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5322 - root_mean_squared_error: 2.3521\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.7409 - root_mean_squared_error: 2.3960\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.6386 - root_mean_squared_error: 2.3746\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.5468 - root_mean_squared_error: 2.3552\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.3105 - root_mean_squared_error: 2.3044\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.7236 - root_mean_squared_error: 2.1734\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.7094 - root_mean_squared_error: 2.1701\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.4640 - root_mean_squared_error: 2.3375\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.5359 - root_mean_squared_error: 2.1298\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.5761 - root_mean_squared_error: 2.1392\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.4563 - root_mean_squared_error: 2.1110\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.5453 - root_mean_squared_error: 2.1320\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.4334 - root_mean_squared_error: 2.1056\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.6393 - root_mean_squared_error: 2.1539\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.8405 - root_mean_squared_error: 2.2001\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.1428 - root_mean_squared_error: 2.0354\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.2017 - root_mean_squared_error: 2.0498\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.8847 - root_mean_squared_error: 1.9710\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.7628 - root_mean_squared_error: 1.9398\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.7875 - root_mean_squared_error: 1.9461\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.1058 - root_mean_squared_error: 2.0263\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.7576 - root_mean_squared_error: 2.1812\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.6008 - root_mean_squared_error: 2.3666\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8475 - root_mean_squared_error: 2.6168\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.1934 - root_mean_squared_error: 2.2789\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 11.4128 - root_mean_squared_error: 3.3783\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.9525 - root_mean_squared_error: 2.9921\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11.7276 - root_mean_squared_error: 3.4246\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.4007 - root_mean_squared_error: 2.7204\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 11.1874 - root_mean_squared_error: 3.3448\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.6702 - root_mean_squared_error: 2.5827\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.6591 - root_mean_squared_error: 2.3789\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.2300 - root_mean_squared_error: 2.2869\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.1715 - root_mean_squared_error: 2.0424\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.9547 - root_mean_squared_error: 1.9886\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.1596 - root_mean_squared_error: 2.0395\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.6980 - root_mean_squared_error: 1.9230\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.8326 - root_mean_squared_error: 1.9577\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.4870 - root_mean_squared_error: 1.8673\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.6069 - root_mean_squared_error: 1.8992\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.6526 - root_mean_squared_error: 1.9112\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.7293 - root_mean_squared_error: 1.9311\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.3753 - root_mean_squared_error: 1.8372\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.5350 - root_mean_squared_error: 1.8801\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.9697 - root_mean_squared_error: 1.9924\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.9233 - root_mean_squared_error: 2.2189\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.0793 - root_mean_squared_error: 2.0197\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.5105 - root_mean_squared_error: 1.8736\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.6615 - root_mean_squared_error: 2.3794\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.2531 - root_mean_squared_error: 2.2920\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.8525 - root_mean_squared_error: 2.2028\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.9013 - root_mean_squared_error: 1.9752\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.7791 - root_mean_squared_error: 1.9440\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.5356 - root_mean_squared_error: 1.8803\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9024 - root_mean_squared_error: 1.9755\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.2816 - root_mean_squared_error: 2.0692\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.4423 - root_mean_squared_error: 2.1077\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.4079 - root_mean_squared_error: 2.3255\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.0024 - root_mean_squared_error: 2.2366\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 4.6811 - root_mean_squared_error: 2.1636\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.6418 - root_mean_squared_error: 2.7644\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.5113 - root_mean_squared_error: 2.9174\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11.1952 - root_mean_squared_error: 3.3459\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.5435 - root_mean_squared_error: 2.9229\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.7511 - root_mean_squared_error: 2.9582\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.8700 - root_mean_squared_error: 3.1417\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.8120 - root_mean_squared_error: 2.9685\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.0134 - root_mean_squared_error: 2.8308\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.4036 - root_mean_squared_error: 3.0665\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.8391 - root_mean_squared_error: 2.9731\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.8476 - root_mean_squared_error: 2.6168\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.0280 - root_mean_squared_error: 2.4552\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.7526 - root_mean_squared_error: 2.3985\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.7740 - root_mean_squared_error: 2.1849\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.7819 - root_mean_squared_error: 2.1868\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2419 - root_mean_squared_error: 2.4984\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.2794 - root_mean_squared_error: 2.0687\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.3852 - root_mean_squared_error: 2.0941\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.6367 - root_mean_squared_error: 2.1533\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9665 - root_mean_squared_error: 1.9916\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.4263 - root_mean_squared_error: 1.8510\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.7901 - root_mean_squared_error: 1.9468\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.4230 - root_mean_squared_error: 1.8501\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.6181 - root_mean_squared_error: 1.9021\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.2523 - root_mean_squared_error: 1.8034\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.9664 - root_mean_squared_error: 1.7223\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.2693 - root_mean_squared_error: 1.8081\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.4217 - root_mean_squared_error: 1.8498\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1490 - root_mean_squared_error: 1.7745\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0077 - root_mean_squared_error: 1.7343\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.7553 - root_mean_squared_error: 1.9379\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8109 - root_mean_squared_error: 1.6766\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.3953 - root_mean_squared_error: 1.8426\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.8030 - root_mean_squared_error: 1.9501\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.1558 - root_mean_squared_error: 2.0386\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.5000 - root_mean_squared_error: 1.8708\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.2542 - root_mean_squared_error: 1.8040\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9039 - root_mean_squared_error: 1.7041\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7851 - root_mean_squared_error: 1.6689\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6032 - root_mean_squared_error: 1.6134\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7236 - root_mean_squared_error: 1.6503\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7813 - root_mean_squared_error: 1.6677\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5428 - root_mean_squared_error: 1.5946\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7037 - root_mean_squared_error: 1.6443\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9854 - root_mean_squared_error: 1.7278\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7186 - root_mean_squared_error: 1.6488\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7574 - root_mean_squared_error: 1.6605\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7931 - root_mean_squared_error: 1.6713\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5920 - root_mean_squared_error: 1.6100\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7352 - root_mean_squared_error: 1.6538\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7733 - root_mean_squared_error: 1.6653\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8417 - root_mean_squared_error: 1.6857\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.1963 - root_mean_squared_error: 2.0485\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.2136 - root_mean_squared_error: 2.4927\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.4480 - root_mean_squared_error: 2.3341\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.1274 - root_mean_squared_error: 2.0316\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.8402 - root_mean_squared_error: 1.9596\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.8590 - root_mean_squared_error: 1.9644\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.3812 - root_mean_squared_error: 1.8388\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.6273 - root_mean_squared_error: 1.9046\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1995 - root_mean_squared_error: 1.7887\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.3159 - root_mean_squared_error: 1.8210\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9048 - root_mean_squared_error: 1.7044\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7416 - root_mean_squared_error: 1.6558\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6774 - root_mean_squared_error: 1.6363\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.8619 - root_mean_squared_error: 1.6917\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.0337 - root_mean_squared_error: 1.7418\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.1697 - root_mean_squared_error: 2.0420\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.6745 - root_mean_squared_error: 1.9169\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.3400 - root_mean_squared_error: 2.3108\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8964 - root_mean_squared_error: 2.6261\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.7989 - root_mean_squared_error: 2.6075\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.8067 - root_mean_squared_error: 2.4097\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.1010 - root_mean_squared_error: 2.2585\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.1911 - root_mean_squared_error: 1.7864\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0960 - root_mean_squared_error: 1.7596\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.5055 - root_mean_squared_error: 1.8723\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0832 - root_mean_squared_error: 1.7559\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0705 - root_mean_squared_error: 1.7523\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0827 - root_mean_squared_error: 1.7558\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.5942 - root_mean_squared_error: 1.8958\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9719 - root_mean_squared_error: 1.7239\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8855 - root_mean_squared_error: 1.6987\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.5869 - root_mean_squared_error: 1.6084\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.8625 - root_mean_squared_error: 1.6919\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7221 - root_mean_squared_error: 1.6499\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.0156 - root_mean_squared_error: 1.7366\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6100 - root_mean_squared_error: 1.6156\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5736 - root_mean_squared_error: 1.6042\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.6237 - root_mean_squared_error: 1.6198\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6908 - root_mean_squared_error: 1.6404\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6395 - root_mean_squared_error: 1.6246\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7449 - root_mean_squared_error: 1.6568\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5784 - root_mean_squared_error: 1.6058\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8122 - root_mean_squared_error: 1.6770\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.6793 - root_mean_squared_error: 1.9182\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.8718 - root_mean_squared_error: 1.9677\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1387 - root_mean_squared_error: 1.7716\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0629 - root_mean_squared_error: 1.7501\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7196 - root_mean_squared_error: 1.6491\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9883 - root_mean_squared_error: 1.7287\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.7335 - root_mean_squared_error: 1.9322\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.9545 - root_mean_squared_error: 1.7189\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.1658 - root_mean_squared_error: 1.7793\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.6772 - root_mean_squared_error: 1.9176\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.4621 - root_mean_squared_error: 1.8607\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1797 - root_mean_squared_error: 1.7832\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1189 - root_mean_squared_error: 1.7660\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8247 - root_mean_squared_error: 1.6807\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7385 - root_mean_squared_error: 1.6548\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5381 - root_mean_squared_error: 1.5932\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.7022 - root_mean_squared_error: 1.6438\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0220 - root_mean_squared_error: 1.7384\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0936 - root_mean_squared_error: 1.7589\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.6493 - root_mean_squared_error: 1.9103\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9105 - root_mean_squared_error: 1.7060\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.5866 - root_mean_squared_error: 1.6083\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.5869 - root_mean_squared_error: 1.6084\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.5104 - root_mean_squared_error: 1.5844\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6629 - root_mean_squared_error: 1.6318\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5704 - root_mean_squared_error: 1.6032\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6305 - root_mean_squared_error: 1.6219\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6953 - root_mean_squared_error: 1.6417\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6158 - root_mean_squared_error: 1.6173\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.4343 - root_mean_squared_error: 1.5602\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5793 - root_mean_squared_error: 1.6060\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.4612 - root_mean_squared_error: 1.5688\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.4596 - root_mean_squared_error: 1.5683\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7706 - root_mean_squared_error: 1.6645\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4153 - root_mean_squared_error: 1.5541\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6787 - root_mean_squared_error: 1.6367\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.9482 - root_mean_squared_error: 1.7170\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.8870 - root_mean_squared_error: 1.6991\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6272 - root_mean_squared_error: 1.6209\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9534 - root_mean_squared_error: 1.7185\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5722 - root_mean_squared_error: 1.6038\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8606 - root_mean_squared_error: 1.6913\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0795 - root_mean_squared_error: 1.7549\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.0979 - root_mean_squared_error: 1.7601\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9051 - root_mean_squared_error: 1.7044\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.5020 - root_mean_squared_error: 1.8714\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9593 - root_mean_squared_error: 1.7203\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8422 - root_mean_squared_error: 1.6859\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.6253 - root_mean_squared_error: 1.6203\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.5825 - root_mean_squared_error: 1.6070\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.4480 - root_mean_squared_error: 1.5646\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4709 - root_mean_squared_error: 1.5719\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9601 - root_mean_squared_error: 1.7205\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.1590 - root_mean_squared_error: 1.7774\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.4314 - root_mean_squared_error: 1.8524\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.4955 - root_mean_squared_error: 1.5797\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.7421 - root_mean_squared_error: 1.6559\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.3800 - root_mean_squared_error: 1.8385\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.3237 - root_mean_squared_error: 1.8231\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2172 - root_mean_squared_error: 1.7937\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1316 - root_mean_squared_error: 1.7696\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7677 - root_mean_squared_error: 1.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23282341430>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "#from keras.losses import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Tapioca.csv')\n",
    "# Select relevant features for training\n",
    "features = ['AvgTemp', 'AvgHumidity', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[features] = scaler.fit_transform(X[features])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(50, input_shape=(5,), activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(50, activation='relu',kernel_initializer='he_uniform'))\n",
    "\n",
    "#odel.add(Dropout(0.3))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "# compile the keras model\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=30)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "# evaluate the keras model\n",
    "#_, accuracy = model.evaluate(X, y)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da68bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.59695911139917\n"
     ]
    }
   ],
   "source": [
    "#Percentage Yield for Tapioca\n",
    "df = pd.read_csv('Tapioca.csv')\n",
    "y = df['Yield']\n",
    "\n",
    "rmse = 1.6637\n",
    "p = (rmse / np.mean(y)) * 100 \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cdfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064c4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
